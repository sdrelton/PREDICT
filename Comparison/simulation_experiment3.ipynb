{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77812989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTENSOR_FLAGS=exception_verbosity=high,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from PREDICT import PREDICT\n",
    "from PREDICT.Models import *\n",
    "from PREDICT.Metrics import *\n",
    "from PREDICT.Triggers import *\n",
    "from PREDICT.Plots import *\n",
    "from Comparison.Detect_Functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import datetime as dt\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import bambi as bmb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%env PYTENSOR_FLAGS=exception_verbosity=high,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e894b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalthreshold = 0.851 # Paper has AUROC of 0.889, with lower CI at 0.851\n",
    "\n",
    "prev_increases = np.arange(1.005, 1.05, 0.005).tolist() #[1.0001] \n",
    "#prev_increases = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\": 0, \"SPC7\": 0, \"Bayesian\": 0})\n",
    "bayes_dict = {\"BayesianCoefficients\":{}}\n",
    "\n",
    "mean_TGFB, std_TGFB = 13.23, 5.18\n",
    "mean_ADMA, std_ADMA= 101.1, 64.8\n",
    "mean_BUN, std_BUN = 5.45, 1.11\n",
    "mean_age, std_age = 63.27, 10.09 \n",
    "\n",
    "TGFB_coef = 1.84\n",
    "ADMA_coef = 1.137\n",
    "DM_coef = 0.84\n",
    "BUN_coef = 0.497\n",
    "elderly_coef = 0.603\n",
    "\n",
    "perc_dm = 0.05 # 5.5%\n",
    "\n",
    "\n",
    "startDate = pd.to_datetime('01-06-2019', dayfirst=True) # 01-06-2019\n",
    "endDate = pd.to_datetime('31-12-2021', dayfirst=True) # 31-12-2021\n",
    "numdays = (endDate - startDate).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain on fake data\n",
    "num_patients = 500\n",
    "numdays_pretrain = 1000\n",
    "\n",
    "mydict = {\n",
    "    'date': list(),\n",
    "    'outcome': list(),\n",
    "    'prediction': list(),\n",
    "    'TGFB': list(),\n",
    "    'ADMA':list(),\n",
    "    'DM': list(),\n",
    "    'BUN': list(),\n",
    "    'elderly': list()\n",
    "}\n",
    "\n",
    "for i in range(numdays_pretrain):\n",
    "    curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "    TGFB = get_binom_from_normal(mean_TGFB, std_TGFB, num_patients, 1.011)\n",
    "    ADMA = get_binom_from_normal(mean_ADMA, std_ADMA, num_patients, 0.019)\n",
    "    DM = np.random.binomial(1, perc_dm, num_patients)\n",
    "    BUN = get_binom_from_normal(mean_BUN, std_BUN, num_patients, 5.9)\n",
    "    elderly = get_binom_from_normal(mean_age, std_age, num_patients, 60)\n",
    "    epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "\n",
    "    # Calculate baseline log-odds\n",
    "    # non_genetic_risk_score_model from paper\n",
    "    lp = TGFB_coef * TGFB + ADMA_coef * ADMA + DM_coef * DM + BUN_coef * BUN + elderly_coef * elderly\n",
    "\n",
    "    curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "    mod_prob = 1/(1+np.exp(-(lp + epsilon)))\n",
    "    curoutcomes = np.random.binomial(1, mod_prob)           \n",
    "    \n",
    "    # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "    mydict['date'].extend([curday] * num_patients)\n",
    "    mydict['outcome'].extend(curoutcomes)\n",
    "    mydict['prediction'].extend(curpredictions)\n",
    "    mydict['TGFB'].extend(TGFB)\n",
    "    mydict['ADMA'].extend(ADMA)\n",
    "    mydict['DM'].extend(DM)\n",
    "    mydict['BUN'].extend(BUN)\n",
    "    mydict['elderly'].extend(elderly)\n",
    "\n",
    "pretrain_data = pd.DataFrame(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7c36650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that outcome==1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, TGFB, ADMA, DM, BUN, elderly]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82aa3948276b41c98302896e2033f8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 15_000 draw iterations (8_000 + 60_000 draws total) took 302 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>79486.0</td>\n",
       "      <td>49266.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGFB</th>\n",
       "      <td>2.012</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1.851</td>\n",
       "      <td>2.171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>80931.0</td>\n",
       "      <td>46674.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADMA</th>\n",
       "      <td>1.074</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>80355.0</td>\n",
       "      <td>47475.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.758</td>\n",
       "      <td>1.219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>76601.0</td>\n",
       "      <td>43040.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUN</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>78541.0</td>\n",
       "      <td>48091.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elderly</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>77872.0</td>\n",
       "      <td>47769.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "Intercept -0.170  0.098  -0.354    0.014        0.0    0.000   79486.0   \n",
       "TGFB       2.012  0.085   1.851    2.171        0.0    0.000   80931.0   \n",
       "ADMA       1.074  0.051   0.980    1.171        0.0    0.000   80355.0   \n",
       "DM         0.990  0.123   0.758    1.219        0.0    0.001   76601.0   \n",
       "BUN        0.490  0.040   0.415    0.565        0.0    0.000   78541.0   \n",
       "elderly    0.660  0.035   0.595    0.726        0.0    0.000   77872.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "Intercept   49266.0    1.0  \n",
       "TGFB        46674.0    1.0  \n",
       "ADMA        47475.0    1.0  \n",
       "DM          43040.0    1.0  \n",
       "BUN         48091.0    1.0  \n",
       "elderly     47769.0    1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefit_model = bmb.Model(\"outcome ~ TGFB + ADMA + DM + BUN + elderly\", pretrain_data, family=\"bernoulli\")\n",
    "prefit_fitted = prefit_model.fit(\n",
    "    tune=2000, draws=15000, cores=8, chains=4, target_accept=0.9)\n",
    "\n",
    "az.summary(prefit_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44cafb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_priors = {\n",
    "    \"Intercept\": (-0.170, 0.098),\n",
    "    \"TGFB\": (2.012, 0.085),\n",
    "    \"ADMA\": (1.074, 0.051),\n",
    "    \"DM\": (0.990, 0.123),\n",
    "    \"BUN\": (0.490, 0.04),\n",
    "    \"elderly\": (0.660, 0.035)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a902ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain OE: 1.0000043910390126 with std: 0.0006133405921358241 and 95% CI: 0.9988624196578121 - 1.001185395447341\n"
     ]
    }
   ],
   "source": [
    "# Get bootstrap OE with CI\n",
    "preds = -0.170 + 2.012 * pretrain_data['TGFB'].values + 1.074 * pretrain_data['ADMA'].values +\\\n",
    "    0.990 * pretrain_data['DM'].values + 0.490 * pretrain_data['BUN'].values + 0.660 * pretrain_data['elderly'].values\n",
    "preds = 1 / (1 + np.exp(-preds))\n",
    "outcome = pretrain_data['outcome'].values\n",
    "for i in range(1000):\n",
    "    boot_indices = np.random.choice(range(len(outcome)), size=len(outcome), replace=True)\n",
    "    boot_outcome = outcome[boot_indices]\n",
    "    boot_preds = preds[boot_indices]\n",
    "    boot_oe = boot_outcome.mean() / boot_preds.mean()\n",
    "    if i == 0:\n",
    "        oe_values = [boot_oe]\n",
    "    else:\n",
    "        oe_values.append(boot_oe)\n",
    "        \n",
    "print(f\"Pretrain OE: {np.mean(oe_values)} with std: {np.std(oe_values)} and 95% CI: {np.percentile(oe_values, 2.5)} - {np.percentile(oe_values, 97.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsloc = \"./Results/simulation/slow_change\"\n",
    "os.makedirs(resultsloc, exist_ok=True)\n",
    "if not os.path.exists(os.path.join(resultsloc, 'performance_metrics.csv')):\n",
    "    header = pd.DataFrame(columns=['Time', 'Accuracy', 'AUROC', 'Precision', 'CalibrationSlope', 'CITL',\n",
    "    'OE', 'AUPRC', 'F1Score', 'impact_or_prev', 'Method', 'Data_Type'])\n",
    "    header.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ba9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prev_increase in prev_increases:\n",
    "    regular_ttd = []\n",
    "    static_ttd = []\n",
    "    spc_ttd3 = []\n",
    "    spc_ttd5 = []\n",
    "    spc_ttd7 = []\n",
    "    bayesian_ttd = []\n",
    "    mydict = {\n",
    "        'date': list(),\n",
    "        'outcome': list(),\n",
    "        'prediction': list(),\n",
    "        'TGFB': list(),\n",
    "        'ADMA':list(),\n",
    "        'DM': list(),\n",
    "        'BUN': list(),\n",
    "        'elderly': list()\n",
    "    }\n",
    "    \n",
    "    for i in range(numdays):\n",
    "        curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "        TGFB = get_binom_from_normal(mean_TGFB, std_TGFB, num_patients, 1.011)\n",
    "        ADMA = get_binom_from_normal(mean_ADMA, std_ADMA, num_patients, 0.019)\n",
    "        DM = np.random.binomial(1, min(perc_dm * np.floor(i/30)*prev_increase, 0.99), num_patients)\n",
    "        BUN = get_binom_from_normal(mean_BUN, std_BUN, num_patients, 5.9)\n",
    "        elderly = get_binom_from_normal(mean_age, std_age, num_patients, 60)\n",
    "        epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "\n",
    "        # Calculate baseline log-odds\n",
    "        # non_genetic_risk_score_model from paper\n",
    "        lp = TGFB_coef * TGFB + ADMA_coef * ADMA + DM_coef * DM + BUN_coef * BUN + elderly_coef * elderly\n",
    "\n",
    "        curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "        mod_prob = 1/(1+np.exp(-(lp + epsilon)))\n",
    "        curoutcomes = np.random.binomial(1, mod_prob)           \n",
    "        \n",
    "        # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "        mydict['date'].extend([curday] * num_patients)\n",
    "        mydict['outcome'].extend(curoutcomes)\n",
    "        mydict['prediction'].extend(curpredictions)\n",
    "        mydict['TGFB'].extend(TGFB)\n",
    "        mydict['ADMA'].extend(ADMA)\n",
    "        mydict['DM'].extend(DM)\n",
    "        mydict['BUN'].extend(BUN)\n",
    "        mydict['elderly'].extend(elderly)\n",
    "           \n",
    "\n",
    "    df = pd.DataFrame(mydict)\n",
    "    df = prevent_constant_variable(df, startDate, endDate)\n",
    "    ########################################### Baseline Testing #######################################\n",
    "    model = EvaluatePredictions()\n",
    "    mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "    mytest.addLogHook(Accuracy(model))\n",
    "    mytest.addLogHook(AUROC(model))\n",
    "    mytest.addLogHook(Precision(model))\n",
    "    mytest.addLogHook(CalibrationSlope(model))\n",
    "    mytest.addLogHook(CITL(model))\n",
    "    mytest.addLogHook(OE(model))\n",
    "    mytest.addLogHook(AUPRC(model))\n",
    "    mytest.run()\n",
    "    log = mytest.getLog()\n",
    "\n",
    "\n",
    "    baseline_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'impact_or_prev': list([str(prev_increase)] * len(log[\"Accuracy\"])), 'Method':list(['Baseline'] * len(log[\"Accuracy\"]))})\n",
    "    ########################################### Save Metrics #######################################\n",
    "    baseline_metrics[\"Data_Type\"] = \"Slow Change Simulation\"\n",
    "    baseline_metrics.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), mode='a', header=False, index=False)\n",
    "    # Get OE thresholds for static recal from original model\n",
    "    recalthreshold_lower = 0.9998998140365868 -3*0.0006133405921358241\n",
    "    recalthreshold_upper = 0.9998998140365868 + 3*0.0006133405921358241\n",
    "    print(f\"Using OE Threshold of {recalthreshold_lower} - {recalthreshold_upper}\")\n",
    "    \n",
    "    \n",
    "    ############################################ Recalibration Testing #######################################\n",
    "    slow_change_metrics_df = get_metrics_recal_methods(df, perc_dm, recalthreshold_lower, recalthreshold_upper, model_name='slow_change_datasim')\n",
    "    undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7 = run_recalibration_tests(df, startDate, undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, recalthreshold_lower, recalthreshold_upper)    \n",
    "\n",
    "    ########################################### Bayesian Testing #######################################\n",
    "    bayes_coef_ci = {\n",
    "        key: (bayesian_priors[key][0] - 3 * bayesian_priors[key][1], bayesian_priors[key][0] + 3 * bayesian_priors[key][1])\n",
    "        for key in bayesian_priors\n",
    "    }\n",
    "    bay_model = BayesianModel(input_data=df, \n",
    "                            model_formula = \"outcome ~ TGFB + ADMA + DM + BUN + elderly\", \n",
    "                            priors = bayesian_priors, \n",
    "                            verbose=False, draws=10000, tune=2000, chains=4, cores=8, target_accept=0.9)\n",
    "    bay_model.trigger = AlwaysTrigger(model=bay_model)\n",
    "    mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month')\n",
    "    mytest.addLogHook(Accuracy(bay_model))\n",
    "    mytest.addLogHook(AUROC(bay_model))\n",
    "    mytest.addLogHook(Precision(bay_model))\n",
    "    mytest.addLogHook(CalibrationSlope(bay_model))\n",
    "    mytest.addLogHook(CITL(bay_model))\n",
    "    mytest.addLogHook(OE(bay_model))\n",
    "    mytest.addLogHook(AUPRC(bay_model))\n",
    "    mytest.addLogHook(TrackBayesianCoefs(bay_model))\n",
    "    mytest.run()\n",
    "    log = mytest.getLog()\n",
    "\n",
    "    if \"BayesianCoefficients\" in log:\n",
    "        bayes_dict[\"BayesianCoefficients\"].update(log[\"BayesianCoefficients\"])\n",
    "    \n",
    "    ttd = find_bayes_coef_change(bayes_dict[\"BayesianCoefficients\"], detectDate=startDate, undetected=undetected, thresholds=bayes_coef_ci)\n",
    "    bayesian_ttd.append(ttd)\n",
    "\n",
    "    bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'impact_or_prev': list([str(perc_dm)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "    \n",
    "    ########################################### Save Metrics #######################################\n",
    "\n",
    "    # concatenate all the dataframes into one\n",
    "    slow_change_metrics_df = pd.concat([slow_change_metrics_df, bayes_metrics], ignore_index=True)\n",
    "    slow_change_metrics_df[\"Data_Type\"] = \"Slow Change Simulation\"\n",
    "\n",
    "    slow_change_metrics_df.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), mode='a', header=False, index=False)\n",
    "    update_ttd_table(regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, prev_increase, os.path.join(resultsloc, 'input_prev_ttd_tbl.csv'))\n",
    "    \n",
    "    # Generate plots\n",
    "    plot_incidence_over_time(df, None, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, 'slow_change_'+str(prev_increase), fileloc=resultsloc)\n",
    "    BayesianCoefsPlot(bayes_dict, 'slow_change_'+str(prev_increase), fileloc=resultsloc)\n",
    "    pd.DataFrame(bayes_dict[\"BayesianCoefficients\"]).to_csv(os.path.join(resultsloc, f'bayesian_coefficients_impact_{prev_increase}.csv'), index=False)\n",
    "\n",
    "plot_time_to_detect(os.path.join(resultsloc, 'input_prev_ttd_tbl.csv'), 'slow_change')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff751458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
