{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8fc410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTENSOR_FLAGS=exception_verbosity=high#,optimizer=fast_compile\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from PREDICT import PREDICT\n",
    "from PREDICT.Models import *\n",
    "from PREDICT.Metrics import *\n",
    "from PREDICT.Triggers import *\n",
    "from PREDICT.Plots import *\n",
    "from Comparison.Detect_Functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%env PYTENSOR_FLAGS=exception_verbosity=high#,optimizer=fast_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51ae8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsloc = \"./Results/simulation/fast_change\"\n",
    "os.makedirs(resultsloc, exist_ok=True)\n",
    "if not os.path.exists(os.path.join(resultsloc, 'performance_metrics.csv')):\n",
    "    header = pd.DataFrame(columns=['Time', 'Accuracy', 'AUROC', 'Precision', 'CalibrationSlope', 'CITL',\n",
    "    'OE', 'AUPRC', 'F1Score', 'impact_or_prev', 'Method', 'Data_Type'])\n",
    "    header.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5051ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = pd.to_datetime('01-06-2019', dayfirst=True) # 01-06-2019\n",
    "endDate = pd.to_datetime('31-12-2021', dayfirst=True) # 31-12-2021\n",
    "num_patients = 100 # number of patients per each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140ce2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'days'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m curpredictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mlp))  \u001b[38;5;66;03m# Convert to probability\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Simulate COVID effects\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m daystopeak \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43m(\u001b[49m\u001b[43mswitch2Days\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mswitchDays\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdays\u001b[49m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m switchDays \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m<\u001b[39m switch2Days:\n\u001b[0;32m     61\u001b[0m     lp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m custom_impact \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m((i \u001b[38;5;241m-\u001b[39m switchDays)\u001b[38;5;241m.\u001b[39mdays) \u001b[38;5;241m/\u001b[39m daystopeak  \u001b[38;5;66;03m# Initial impact of COVID ramping up\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'days'"
     ]
    }
   ],
   "source": [
    "#recalthreshold = 0.86 # Paper has AUROC of 0.91, with lower CI at 0.86\n",
    "\n",
    "#custom_impacts = [0.04, 0.06, 0.08, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "custom_impacts = [0.5]\n",
    "switchDateStrings = ['01-04-2020'] # Keep this as just one switchDate as other methods only look at one startDate/deployment date\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\":0, \"SPC7\":0, \"Bayesian\": 0})\n",
    "\n",
    "or_age = 1.05\n",
    "or_ldh = 2.5\n",
    "or_comorbidity = 3.9\n",
    "\n",
    "log_age = np.log(or_age)\n",
    "log_ldh = np.log(or_ldh)\n",
    "log_comorbidity = np.log(or_comorbidity)\n",
    "bayes_dict = {\"BayesianCoefficients\":{}}\n",
    "\n",
    "for switchDateidx, switchDateString in enumerate(switchDateStrings):\n",
    "    for custom_impact in custom_impacts:\n",
    "        regular_ttd = []\n",
    "        static_ttd = []\n",
    "        spc_ttd3 = []\n",
    "        spc_ttd5 = []\n",
    "        spc_ttd7 = []\n",
    "        bayesian_ttd = []\n",
    "        mydict = {\n",
    "                'date': list(),\n",
    "                'outcome': list(),\n",
    "                'prediction': list(),\n",
    "                'age': list(),\n",
    "                'sex': list(),\n",
    "                'comorbidity': list(),\n",
    "                'ldh_high': list()\n",
    "            }\n",
    "\n",
    "        # Define date range and COVID shock periods\n",
    "        switchDate = pd.to_datetime(switchDateString, dayfirst=True)  # COVID starts spreading\n",
    "        switchDate2 = pd.to_datetime('01-06-2020', dayfirst=True)  # Peak of the pandemic\n",
    "        recoveryDate = pd.to_datetime('01-06-2021', dayfirst=True)  # Start of recovery phase\n",
    "        numdays = (endDate - startDate).days\n",
    "        switchDays = (switchDate - startDate).days\n",
    "        switch2Days = (switchDate2 - startDate).days\n",
    "        recoveryDays = (recoveryDate - startDate).days\n",
    "\n",
    "        for i in range(numdays):\n",
    "            curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "            age = (np.random.normal(44, 16.3, num_patients)).astype(int)  # Mean age 44, SD 16.3\n",
    "            sex = np.random.binomial(1, 0.562, num_patients) # 56.2% are male\n",
    "            comorbidity = np.random.binomial(1, 0.3, num_patients)  # 30% have comorbidities\n",
    "            ldh_high = np.random.binomial(1, 0.15, num_patients)  # 15% have LDH >500 U/L\n",
    "            epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "\n",
    "            # Calculate baseline log-odds\n",
    "            # sex influence 1.2 due to not being provided in the paper\n",
    "            lp = -1.5 + log_age * age +  log_ldh * ldh_high + log_comorbidity * comorbidity + 1.2 * sex  + epsilon\n",
    "            curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "            # Simulate COVID effects\n",
    "            daystopeak = switch2Days - switchDays\n",
    "            if switchDays <= i < switch2Days:\n",
    "                lp += custom_impact * (i - switchDays) / daystopeak  # Initial impact of COVID ramping up\n",
    "            elif switch2Days <= i < recoveryDays:\n",
    "                lp += custom_impact  # Peak of the pandemic\n",
    "            elif i >= recoveryDays:\n",
    "                lp -= 1.0  # Recovery periodâ€”improved health outcomes\n",
    "\n",
    "            # Generate outcomes\n",
    "            curoutcomes = np.random.binomial(1, 1 / (1 + np.exp(-lp)))  # Simulate COVID events\n",
    "\n",
    "            # Append to dictionary\n",
    "            mydict['date'].extend([curday] * num_patients)\n",
    "            mydict['outcome'].extend(curoutcomes)\n",
    "            mydict['prediction'].extend(curpredictions)\n",
    "            mydict['age'].extend(age)\n",
    "            mydict['sex'].extend(sex)\n",
    "            mydict['comorbidity'].extend(comorbidity)\n",
    "            mydict['ldh_high'].extend(ldh_high)\n",
    "\n",
    "        df = pd.DataFrame(mydict)\n",
    "\n",
    "        ########################################### Baseline Testing #######################################\n",
    "        model_name='COVID_datasim'\n",
    "        model = EvaluatePredictions()\n",
    "        mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "        mytest.addLogHook(Accuracy(model))\n",
    "        mytest.addLogHook(AUROC(model))\n",
    "        mytest.addLogHook(Precision(model))\n",
    "        mytest.addLogHook(CalibrationSlope(model))\n",
    "        mytest.addLogHook(CITL(model))\n",
    "        mytest.addLogHook(OE(model))\n",
    "        mytest.addLogHook(AUPRC(model))\n",
    "        mytest.addLogHook(F1Score(model))\n",
    "        mytest.run()\n",
    "        log = mytest.getLog()\n",
    "\n",
    "        baseline_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'F1Score': list(log[\"F1score\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['Baseline'] * len(log[\"Accuracy\"]))})\n",
    "        # Use baseline measure of OE score in time before switchDate to get CI\n",
    "        recalthreshold_lower = float(baseline_metrics[baseline_metrics['Time'] < switchDate]['OE'].quantile(0.025))\n",
    "        recalthreshold_upper = float(baseline_metrics[baseline_metrics['Time'] < switchDate]['OE'].quantile(0.975))\n",
    "        print(f\"Using OE Threshold of {recalthreshold_lower} - {recalthreshold_upper} for impact {custom_impact}, mean was {baseline_metrics[baseline_metrics['Time'] < switchDate]['OE'].mean()}\")\n",
    "        \n",
    "        ########################################### Save Metrics #######################################\n",
    "        baseline_metrics[\"Data_Type\"] = \"COVID Simulation\"\n",
    "        baseline_metrics.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), mode='a', header=False, index=False)\n",
    "        \n",
    "        ########################################### Test models ##########################################\n",
    "        \n",
    "        covid_metrics_df = get_metrics_recal_methods(df, custom_impact, recalthreshold_lower, recalthreshold_upper, model_name='COVID_datasim')\n",
    "        undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7 = run_recalibration_tests(df, switchDate, undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, recalthreshold_lower, recalthreshold_upper)\n",
    "        ########################################### Bayesian Testing #######################################\n",
    "        bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (-1.5, 0.1), \"age\": (log_age, 0.01), \"sex\": (1.2, 0.1), \"comorbidity\": (log_comorbidity, 0.5), \"ldh_high\": (log_ldh, 0.5)}, cores=2, verbose=False, draws=1000, tune=250, chains=4)\n",
    "        bay_model.trigger = TimeframeTrigger(model=bay_model, updateTimestep='month', dataStart=startDate, dataEnd=endDate)\n",
    "        mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month')\n",
    "        mytest.addLogHook(Accuracy(bay_model))\n",
    "        mytest.addLogHook(AUROC(bay_model))\n",
    "        mytest.addLogHook(Precision(bay_model))\n",
    "        mytest.addLogHook(CalibrationSlope(bay_model))\n",
    "        mytest.addLogHook(CITL(bay_model))\n",
    "        mytest.addLogHook(OE(bay_model))\n",
    "        mytest.addLogHook(AUPRC(bay_model))\n",
    "        mytest.addLogHook(F1Score(model))\n",
    "        mytest.addLogHook(TrackBayesianCoefs(bay_model))\n",
    "        mytest.run()\n",
    "        log = mytest.getLog()\n",
    "\n",
    "        if \"BayesianCoefficients\" in log:\n",
    "            bayes_dict[\"BayesianCoefficients\"].update(log[\"BayesianCoefficients\"])\n",
    "            print(log[\"BayesianCoefficients\"])\n",
    "        \n",
    "        ttd = find_bayes_coef_change(bayes_dict[\"BayesianCoefficients\"], detectDate=switchDate, undetected=undetected, threshold=0.1)\n",
    "        print(ttd)\n",
    "        bayesian_ttd.append(ttd)\n",
    "\n",
    "        bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'F1Score': list(log[\"F1score\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "        \n",
    "        ########################################### Save Metrics #######################################\n",
    "\n",
    "        # concatenate all the dataframes into one\n",
    "        covid_metrics_df = pd.concat([covid_metrics_df, bayes_metrics], ignore_index=True)\n",
    "        covid_metrics_df[\"Data_Type\"] = \"COVID Simulation\"\n",
    "\n",
    "        covid_metrics_df.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), mode='a', header=False, index=False)\n",
    "\n",
    "        update_ttd_table(regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, custom_impact, os.path.join(resultsloc, 'covid_ttd_tbl.csv'))\n",
    "\n",
    "        # these two just do the final impact value:\n",
    "        BayesianCoefsPlot(bayes_dict, model_name = f\"fast_change_impact_{custom_impact}\", fileloc=resultsloc) \n",
    "        plot_incidence_over_time(df, switchDateStrings, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, f\"fast_change_impact_{custom_impact}\", fileloc=resultsloc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce37195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweak plot outputs\n",
    "BayesianCoefsPlot(bayes_dict, model_name = f\"fast_change_impact_{custom_impact}\", fileloc=resultsloc) \n",
    "plot_incidence_over_time(df, switchDateStrings, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, f\"fast_change_impact_{custom_impact}\", fileloc=resultsloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d85ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_incidence_over_time(df, switchDateStrings, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, sim_data=None, fileloc='./'):\n",
    "    \"\"\"Plot the incidence of an outcome over time, with vertical lines indicating model update times.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the simulation data with 'date' and 'outcome' columns.\n",
    "        switchDateStrings (list or None): List of switch dates as strings, or None if not applicable.\n",
    "        regular_ttd (list): List of time to detect (ttd) for regular testing model updates.\n",
    "        static_ttd (list): List of time to detect (ttd) for static threshold model updates.\n",
    "        spc_ttd3 (list): List of time to detect (ttd) for SPC 3 months model updates.\n",
    "        spc_ttd5 (list): List of time to detect (ttd) for SPC 5 months model updates.\n",
    "        spc_ttd7 (list): List of time to detect (ttd) for SPC 7 months model updates.\n",
    "        bayesian_ttd (list): List of time to detect (ttd) for Bayesian model updates.\n",
    "        sim_data (str or None): Identifier for the simulation data, used in the filename. Defaults to None.\n",
    "        fileloc (str): Directory to save the plot image. Defaults to current directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # If we want to plot a different simulated data incidence:\n",
    "    # save times and grouped incidence in a df to plot at the end? - another column to say which number run it is for new lines\n",
    "    plt.figure(figsize=(10, 5)) # plot incidence over time for each switchTime - start with just the final one first\n",
    "\n",
    "    # groupby the date and get the sum of the outcome\n",
    "    groupby_df = df.groupby('date').agg({'outcome': 'sum'}).reset_index()\n",
    "\n",
    "    plt.plot(groupby_df['date'], groupby_df['outcome'], label='Incidence', color='blue')\n",
    "\n",
    "    if switchDateStrings is not None:\n",
    "        switch_time = pd.to_datetime(switchDateStrings[-1], dayfirst=True)\n",
    "        plt.vlines(x=switch_time, ymin=0, ymax=groupby_df['outcome'].max(), color='orange', linestyle='-', label='Shock Time')\n",
    "    else:\n",
    "        switch_time = df['date'].min()  # Use the minimum date in the DataFrame if no switch date is provided\n",
    "\n",
    "    if len(regular_ttd) > 0 and regular_ttd[-1] is not None:\n",
    "        regular_update = switch_time + timedelta(days=regular_ttd[-1])\n",
    "        plt.vlines(x=regular_update, ymin=0, ymax=groupby_df['outcome'].max(), color='black', linestyle='dashed', label='Regular Testing Model Update Time', alpha=0.6)\n",
    "    if len(static_ttd) > 0 and static_ttd[-1] is not None:\n",
    "        static_update = switch_time + timedelta(days=static_ttd[-1])\n",
    "        plt.vlines(x=static_update, ymin=0, ymax=groupby_df['outcome'].max(), color='purple', linestyle='dashdot', label='Static Threshold Model Update Time', alpha=0.6)\n",
    "    if len(spc_ttd3) > 0 and spc_ttd3[-1] is not None: \n",
    "        spc_update3 = switch_time + timedelta(days=spc_ttd3[-1])\n",
    "        plt.vlines(x=spc_update3, ymin=0, ymax=groupby_df['outcome'].max(), color='green', linestyle='dotted', label='SPC 3 months Model Update Time', alpha=0.6)\n",
    "    if len(spc_ttd5) > 0 and spc_ttd5[-1] is not None:\n",
    "        spc_update5 = switch_time + timedelta(days=spc_ttd5[-1])\n",
    "        plt.vlines(x=spc_update5, ymin=0, ymax=groupby_df['outcome'].max(), color='pink',  linestyle='dotted', label='SPC 5 months Model Update Time', alpha=0.6)\n",
    "    if len(spc_ttd7) > 0 and spc_ttd7[-1] is not None:\n",
    "        spc_update7 = switch_time + timedelta(days=spc_ttd7[-1])\n",
    "        plt.vlines(x=spc_update7, ymin=0, ymax=groupby_df['outcome'].max(), color='grey', linestyle='dotted', label='SPC 7 months Model Update Time', alpha=0.6)\n",
    "    if len(bayesian_ttd) > 0 and bayesian_ttd[-1] is not None:\n",
    "        bayesian_update = switch_time + timedelta(days=bayesian_ttd[-1])\n",
    "        plt.vlines(x=bayesian_update, ymin=0, ymax=groupby_df['outcome'].max(), linestyle='-', label='Bayesian Model Sig. Change')\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Incidence\")\n",
    "    plt.legend()\n",
    "    # save figure\n",
    "    plt.savefig(os.path.join(fileloc, f\"incidence_over_time_{sim_data}.png\"), dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064172d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
