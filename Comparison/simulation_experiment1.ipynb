{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8fc410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTENSOR_FLAGS=exception_verbosity=high,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from PREDICT import PREDICT\n",
    "from PREDICT.Models import *\n",
    "from PREDICT.Metrics import *\n",
    "from PREDICT.Triggers import *\n",
    "from PREDICT.Plots import *\n",
    "from Comparison.Detect_Functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import bambi as bmb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%env PYTENSOR_FLAGS=exception_verbosity=high,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalthreshold = 0.86 # Paper has AUROC of 0.91, with lower CI at 0.86\n",
    "\n",
    "custom_impacts = [0.05, 0.75, 0.1, 0.25, 0.33, 0.5, 0.66, 0.75, 0.9, 1.0]\n",
    "#custom_impacts = [0.5]#, 0.6, 0.7, 0.8, 0.9, 1.0]  # Faster testing with fewer impact levels\n",
    "switchDateStrings = ['01-04-2020'] # Keep this as just one switchDate as other methods only look at one startDate/deployment date\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\":0, \"SPC7\":0, \"Bayesian\": 0})\n",
    "\n",
    "or_age = 1.05\n",
    "or_ldh = 2.5\n",
    "or_comorbidity = 3.9\n",
    "\n",
    "log_age = np.log(or_age)\n",
    "log_ldh = np.log(or_ldh)\n",
    "log_comorbidity = np.log(or_comorbidity)\n",
    "bayes_dict = {\"BayesianCoefficients\":{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d1e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_samples = 8000\n",
    "\n",
    "age = (np.random.normal(44, 16.3, pretrain_samples)).astype(int)  # Mean age 44, SD 16.3\n",
    "sex = np.random.binomial(1, 0.562, pretrain_samples) # 56.2% are male\n",
    "comorbidity = np.random.binomial(1, 0.3, pretrain_samples)  # 30% have comorbidities\n",
    "ldh_high = np.random.binomial(1, 0.15, pretrain_samples)  # 15% have LDH >500 U/L\n",
    "epsilon = np.random.normal(0, 0.08, pretrain_samples) # Simulate error term (mean=0, std=0.08)\n",
    "# Calculate baseline log-odds\n",
    "# sex influence 1.2 due to not being provided in the paper\n",
    "lp = -1.5 + log_age * age +  log_ldh * ldh_high + log_comorbidity * comorbidity + 1.2 * sex\n",
    "curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "# Generate outcomes\n",
    "curoutcomes = np.random.binomial(1, 1 / (1 + np.exp(-(lp  + epsilon))))  # Simulate COVID events\n",
    "\n",
    "pretrain_data = pd.DataFrame({'date': [pd.to_datetime('01-01-1999')] * pretrain_samples,\n",
    "                            'outcome': curoutcomes,\n",
    "                            'prediction': curpredictions,\n",
    "                            'age': age,\n",
    "                            'sex': sex,\n",
    "                            'comorbidity': comorbidity,\n",
    "                            'ldh_high': ldh_high})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef10b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that outcome==1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5aa5e07a6204822a368618acfc3fc17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prefit_model = bmb.Model(\"outcome ~ age + sex + comorbidity + ldh_high\", pretrain_data, family=\"bernoulli\")\n",
    "prefit_fitted = prefit_model.fit(\n",
    "    tune=2000, draws=15000, cores=8, chains=4, target_accept=0.9)\n",
    "\n",
    "az.summary(prefit_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ae8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsloc = \"./Results/simulation/fast_change\"\n",
    "os.makedirs(resultsloc, exist_ok=True)\n",
    "if not os.path.exists(os.path.join(resultsloc, 'performance_metrics.csv')):\n",
    "    header = pd.DataFrame(columns=['Time', 'Accuracy', 'AUROC', 'Precision', 'CalibrationSlope', 'CITL',\n",
    "    'OE', 'AUPRC', 'F1Score', 'impact_or_prev', 'Method', 'Data_Type'])\n",
    "    header.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = pd.to_datetime('01-06-2019', dayfirst=True) # 01-06-2019\n",
    "endDate = pd.to_datetime('31-12-2021', dayfirst=True) # 31-12-2021\n",
    "num_patients = 200 # number of patients per each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OE Threshold of 0.9871497341194047 - 1.0136757259035873 for impact 0.5, mean was 1.000412730011496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model formula is set to:  outcome ~ age + sex + comorbidity + ldh_high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9735ec5fb8d0419aa282d376847259ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 25_000 draw iterations (8_000 + 100_000 draws total) took 26 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81f20443ef84a7a8aab17f93ebde413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 25_000 draw iterations (8_000 + 100_000 draws total) took 26 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123553043b184cc6bba1e5b91656b106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 25_000 draw iterations (8_000 + 100_000 draws total) took 28 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c6e8cd44c94d3298f9ff7cb4a01a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 25_000 draw iterations (8_000 + 100_000 draws total) took 27 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9d240c1763408caefdd68c42255bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 25_000 draw iterations (8_000 + 100_000 draws total) took 25 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918ce51480904177a59765cb1112aebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 25_000 draw iterations (8_000 + 100_000 draws total) took 27 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3483f47f78f4207a01504acf6d69727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 25_000 draw iterations (8_000 + 100_000 draws total) took 26 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcbe36fb45944c9afead8cf5d238910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 25_000 draw iterations (8_000 + 100_000 draws total) took 26 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [Intercept, age, sex, comorbidity, ldh_high]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6326190957204b998a6683a2b503c636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for switchDateidx, switchDateString in enumerate(switchDateStrings):\n",
    "    for custom_impact in custom_impacts:\n",
    "        regular_ttd = []\n",
    "        static_ttd = []\n",
    "        spc_ttd3 = []\n",
    "        spc_ttd5 = []\n",
    "        spc_ttd7 = []\n",
    "        bayesian_ttd = []\n",
    "        mydict = {\n",
    "                'date': list(),\n",
    "                'outcome': list(),\n",
    "                'prediction': list(),\n",
    "                'age': list(),\n",
    "                'sex': list(),\n",
    "                'comorbidity': list(),\n",
    "                'ldh_high': list()\n",
    "            }\n",
    "\n",
    "        # Define date range and COVID shock periods\n",
    "        switchDate = pd.to_datetime(switchDateString, dayfirst=True)  # COVID starts spreading\n",
    "        switchDate2 = pd.to_datetime('01-06-2020', dayfirst=True)  # Peak of the pandemic\n",
    "        recoveryDate = pd.to_datetime('01-06-2021', dayfirst=True)  # Start of recovery phase\n",
    "        numdays = (endDate - startDate).days\n",
    "        switchDays = (switchDate - startDate).days\n",
    "        switch2Days = (switchDate2 - startDate).days\n",
    "        recoveryDays = (recoveryDate - startDate).days\n",
    "\n",
    "        for i in range(numdays):\n",
    "            curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "            age = (np.random.normal(44, 16.3, num_patients)).astype(int)  # Mean age 44, SD 16.3\n",
    "            sex = np.random.binomial(1, 0.562, num_patients) # 56.2% are male\n",
    "            comorbidity = np.random.binomial(1, 0.3, num_patients)  # 30% have comorbidities\n",
    "            ldh_high = np.random.binomial(1, 0.15, num_patients)  # 15% have LDH >500 U/L\n",
    "            epsilon = np.random.normal(0, 0.08, num_patients) # Simulate error term (mean=0, std=0.08)\n",
    "\n",
    "            # Calculate baseline log-odds\n",
    "            # sex influence 1.2 due to not being provided in the paper\n",
    "            lp = -1.5 + log_age * age +  log_ldh * ldh_high + log_comorbidity * comorbidity + 1.2 * sex\n",
    "            curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "            # Simulate COVID effects\n",
    "            daystopeak = switch2Days - switchDays\n",
    "            if switchDays <= i < switch2Days:\n",
    "                lp += custom_impact * (i - switchDays) / daystopeak  # Initial impact of COVID ramping up\n",
    "            elif switch2Days <= i < recoveryDays:\n",
    "                lp += custom_impact  # Peak of the pandemic\n",
    "\n",
    "            # Generate outcomes\n",
    "            curoutcomes = np.random.binomial(1, 1 / (1 + np.exp(-(lp + epsilon))))  # Simulate COVID events\n",
    "\n",
    "            # Append to dictionary\n",
    "            mydict['date'].extend([curday] * num_patients)\n",
    "            mydict['outcome'].extend(curoutcomes)\n",
    "            mydict['prediction'].extend(curpredictions)\n",
    "            mydict['age'].extend(age)\n",
    "            mydict['sex'].extend(sex)\n",
    "            mydict['comorbidity'].extend(comorbidity)\n",
    "            mydict['ldh_high'].extend(ldh_high)\n",
    "\n",
    "        df = pd.DataFrame(mydict)\n",
    "\n",
    "        ########################################### Baseline Testing #######################################\n",
    "        model_name='COVID_datasim'\n",
    "        model = EvaluatePredictions()\n",
    "        mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "        mytest.addLogHook(Accuracy(model))\n",
    "        mytest.addLogHook(AUROC(model))\n",
    "        mytest.addLogHook(Precision(model))\n",
    "        mytest.addLogHook(CalibrationSlope(model))\n",
    "        mytest.addLogHook(CITL(model))\n",
    "        mytest.addLogHook(OE(model))\n",
    "        mytest.addLogHook(AUPRC(model))\n",
    "        mytest.addLogHook(F1Score(model))\n",
    "        mytest.run()\n",
    "        log = mytest.getLog()\n",
    "\n",
    "        baseline_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'F1Score': list(log[\"F1score\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['Baseline'] * len(log[\"Accuracy\"]))})\n",
    "        # Use baseline measure of OE score in time before switchDate to get CI\n",
    "        oe_std = baseline_metrics[baseline_metrics['Time'] < switchDate]['OE'].std()\n",
    "        recalthreshold_lower = float(baseline_metrics[baseline_metrics['Time'] < switchDate]['OE'].mean() - 3*oe_std)\n",
    "        recalthreshold_upper = float(baseline_metrics[baseline_metrics['Time'] < switchDate]['OE'].mean() + 3*oe_std)\n",
    "        print(f\"Using OE Threshold of {recalthreshold_lower} - {recalthreshold_upper} for impact {custom_impact}, mean was {baseline_metrics[baseline_metrics['Time'] < switchDate]['OE'].mean()}\")\n",
    "        \n",
    "        ########################################### Save Metrics #######################################\n",
    "        baseline_metrics[\"Data_Type\"] = \"COVID Simulation\"\n",
    "        baseline_metrics.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), mode='a', header=False, index=False)\n",
    "        \n",
    "        ########################################### Test models ##########################################\n",
    "        \n",
    "        covid_metrics_df = get_metrics_recal_methods(df, custom_impact, recalthreshold_lower, recalthreshold_upper, model_name='COVID_datasim')\n",
    "        undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7 = run_recalibration_tests(df, switchDate, undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, recalthreshold_lower, recalthreshold_upper)\n",
    "        ########################################### Bayesian Testing #######################################\n",
    "        #bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (-1.5, 0.05), \"age\": (log_age, 0.01), \"sex\": (1.2, 0.1), \"comorbidity\": (log_comorbidity, 0.1), \"ldh_high\": (log_ldh, 0.1)}, cores=2, verbose=False, draws=1000, tune=250, chains=4)\n",
    "        bayes_coef_ci = {\n",
    "            'Intercept': (-1.550 - 3*0.095, -1.550 + 3*0.095),\n",
    "            'age': (0.049 - 3*0.002, 0.049 + 3*0.002),\n",
    "            'sex': (1.191 - 3*0.063, 1.191 + 3*0.063),\n",
    "            'comorbidity': (1.287 - 3*0.082, 1.287 + 3*0.082),\n",
    "            'ldh_high': (0.984 - 3*0.104, 0.984 + 3*0.104),\n",
    "        }\n",
    "        bay_model = BayesianModel(input_data=df, \n",
    "                                model_formula = \"outcome ~ age + sex + comorbidity + ldh_high\", \n",
    "                                priors={\n",
    "                                    \"Intercept\": (-1.550, 0.095), \n",
    "                                    \"age\": (0.049, 0.002), \n",
    "                                    \"sex\": (1.191, 0.063),\n",
    "                                    \"comorbidity\": (1.287, 0.082), \n",
    "                                    \"ldh_high\": (0.984, 0.104)}\n",
    "                                , verbose=False, draws=10000, tune=2000, chains=4, cores=8)\n",
    "        bay_model.trigger = AlwaysTrigger(bay_model)\n",
    "        mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month')\n",
    "        mytest.addLogHook(Accuracy(bay_model))\n",
    "        mytest.addLogHook(AUROC(bay_model))\n",
    "        mytest.addLogHook(Precision(bay_model))\n",
    "        mytest.addLogHook(CalibrationSlope(bay_model))\n",
    "        mytest.addLogHook(CITL(bay_model))\n",
    "        mytest.addLogHook(OE(bay_model))\n",
    "        mytest.addLogHook(AUPRC(bay_model))\n",
    "        mytest.addLogHook(F1Score(model))\n",
    "        mytest.addLogHook(TrackBayesianCoefs(bay_model))\n",
    "        mytest.run()\n",
    "        log = mytest.getLog()\n",
    "\n",
    "        if \"BayesianCoefficients\" in log:\n",
    "            bayes_dict[\"BayesianCoefficients\"].update(log[\"BayesianCoefficients\"])\n",
    "            print(log[\"BayesianCoefficients\"])\n",
    "        \n",
    "        ttd = find_bayes_coef_change(bayes_dict[\"BayesianCoefficients\"], detectDate=startDate, undetected=undetected, thresholds=bayes_coef_ci)\n",
    "        bayesian_ttd.append(ttd)\n",
    "\n",
    "        bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'F1Score': list(log[\"F1score\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "        \n",
    "        ########################################### Save Metrics #######################################\n",
    "\n",
    "        # concatenate all the dataframes into one\n",
    "        covid_metrics_df = pd.concat([covid_metrics_df, bayes_metrics], ignore_index=True)\n",
    "        covid_metrics_df[\"Data_Type\"] = \"COVID Simulation\"\n",
    "\n",
    "        covid_metrics_df.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), mode='a', header=False, index=False)\n",
    "\n",
    "        update_ttd_table(regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, custom_impact, os.path.join(resultsloc, 'covid_ttd_tbl.csv'))\n",
    "\n",
    "        # these two just do the final impact value:\n",
    "        BayesianCoefsPlot(bayes_dict, model_name = f\"fast_change_impact_{custom_impact}\", fileloc=resultsloc) \n",
    "        pd.DataFrame(bayes_dict[\"BayesianCoefficients\"]).to_csv(os.path.join(resultsloc, f'bayesian_coefficients_impact_{custom_impact}.csv'), index=False)\n",
    "        plot_incidence_over_time(df, switchDateStrings, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, f\"fast_change_impact_{custom_impact}\", fileloc=resultsloc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212af92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
