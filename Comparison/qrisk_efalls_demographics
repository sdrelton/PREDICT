import pyodbc
import sys
import numpy as np
import pandas as pd
from datetime import timedelta
import datetime
from dateutil.relativedelta import relativedelta
import warnings
warnings.filterwarnings('ignore')
import json
import os
import tableone

#############################
# EFALLS
#############################
# Establish connection to SQL Server
conn = pyodbc.connect(
    "DRIVER={SQL Server};"
    "SERVER=BHTS-CONNECTYO3;"
    "DATABASE=CB_2151;"
    "Trusted_Connection=yes;"
)

# Query data from a table
query = f"SELECT * FROM tbl_final_efalls_deduped WHERE DateOnly <= '2019-01-01'"

# Store query result in a dataframe
df = pd.read_sql(query, conn)

# Close the connection
conn.close()

df['unique_bnf_last_3_months'] = df['unique_bnf_last_3_months'].astype(float)

df["Polypharmacy"] = np.log(df["unique_bnf_last_3_months"] + 1) / 10 

predictors = ["Age", "Female", "Polypharmacy", "Underweight", "Normal", "Obese", "BMI_missing", "Current_Smoker", "Harmful_drinking",
                "Higher_risk_drinking", "Previous_harmful_drinking", "Zero_Alcohol", "Alcohol_missing", "Abdominal_pain", "Activity_limitation", 
                "Anaemia_and_haematinic_deficiency", "Asthma", "Atrial_fibrillation", "Back_pain", "Bone_disease", "Cancer", "Cognitive_impairment",
                "COPD", "Dementia", "Depression", "Diabetes_mellitus", "Dizziness", "Dressing_and_grooming_problems", "Faecal_incontinence",
                "Falls", "Fatigue", "Foot_problems", "Fracture", "Fragility_fracture", "General_mental_health", "Headache",
                "Hearing_impairment", "Heart_failure", "Housebound", "Hypertension", "Hypotension_or_syncope", "Inflammatory_arthritis", 
                "Inflammatory_bowel_disease", "Liver_problems", "Meal_preparation_problems", "Medication_management",
                "Memory_concerns", "Mobility_problems", "Mono_or_hemiparesis", "Motor_neurone_disease", "Musculoskeletal_problems", "Osteoarthritis", 
                "Osteoporosis", "Palliative_care", "Parkinsonism_and_tremor", "Peptic_ulcer_disease", "Peripheral_neuropathy", "Peripheral_vascular_disease",
                "Requirement_for_care", "Respiratory_disease", "Seizures", "Self_harm", "Severe_mental_illness", "Skin_ulcer", "Sleep_problems",
                "Social_vulnerability", "Stress", "Stroke", "Thyroid_problems", "Urinary_incontinence", "Urinary_system_disease", "Visual_impairment",
                "Washing_and_bathing", "Weakness", "Weight_loss"]#, "Intercept"]
# select specific columns
df = df[["Fall_Outcome", "DateOnly"]+predictors]
# change some of the column names
df.rename(columns={"DateOnly": "date", "Fall_Outcome":"outcome"}, inplace=True)
# convert the date column to datetime
df['date'] = pd.to_datetime(df['date'])
# define analysis window
startDate = pd.to_datetime('01-01-2019', dayfirst=True)
# restrict to endDate if present - refit efalls uses records before 2019-01-01 so ensure we filter
# select prior twelve months used to fit scalers
prior_twelve_months = df[(df['date'] >= startDate - relativedelta(months=12)) & (df['date'] < startDate)]

# Use tableone to describe the prior_twelve_months dataframe
columns = predictors + ["outcome"] # Including a subset of predictors for brevity
categorical = columns.copy()
categorical.remove("Age")
categorical.remove("Polypharmacy")
groupby = "outcome"
table_one = tableone.TableOne(prior_twelve_months, columns=columns, categorical=categorical, groupby=groupby, pval=True)
print(table_one.tabulate(tablefmt="github"))
# Save the table to CSV
table_one.to_csv(os.path.join('results/efalls', 'efalls_pretrain_demographics_table.csv'))



conn = pyodbc.connect(
    "DRIVER={SQL Server};"
    "SERVER=BHTS-CONNECTYO3;"
    "DATABASE=CB_2151;"
    "Trusted_Connection=yes;"
)

resultsloc = f'results/efalls'
os.makedirs(resultsloc, exist_ok=True)
os.makedirs(os.path.join(resultsloc, 'probs_and_outcomes'), exist_ok=True)
os.makedirs(os.path.join(resultsloc, 'predictor_distributions'), exist_ok=True)

# Query data from a table
query = f"SELECT * FROM tbl_final_efalls_deduped WHERE DateOnly >= '2019-01-01'"

# Store query result in a dataframe
df = pd.read_sql(query, conn)

# Close the connection
conn.close()

# apply transformation to polypharmacy column
df['unique_bnf_last_3_months'] = df['unique_bnf_last_3_months'].astype(float)
df["Polypharmacy"] = np.log(df["unique_bnf_last_3_months"] + 1) / 10 

predictors = ["Age", "Female", "Polypharmacy", "Underweight", "Normal", "Obese", "BMI_missing", "Current_Smoker", "Harmful_drinking",
                "Higher_risk_drinking", "Previous_harmful_drinking", "Zero_Alcohol", "Alcohol_missing", "Abdominal_pain", "Activity_limitation", 
                "Anaemia_and_haematinic_deficiency", "Asthma", "Atrial_fibrillation", "Back_pain", "Bone_disease", "Cancer", "Cognitive_impairment",
                "COPD", "Dementia", "Depression", "Diabetes_mellitus", "Dizziness", "Dressing_and_grooming_problems", "Faecal_incontinence",
                "Falls", "Fatigue", "Foot_problems", "Fracture", "Fragility_fracture", "General_mental_health", "Headache",
                "Hearing_impairment", "Heart_failure", "Housebound", "Hypertension", "Hypotension_or_syncope", "Inflammatory_arthritis", 
                "Inflammatory_bowel_disease", "Liver_problems", "Meal_preparation_problems", "Medication_management",
                "Memory_concerns", "Mobility_problems", "Mono_or_hemiparesis", "Motor_neurone_disease", "Musculoskeletal_problems", "Osteoarthritis", 
                "Osteoporosis", "Palliative_care", "Parkinsonism_and_tremor", "Peptic_ulcer_disease", "Peripheral_neuropathy", "Peripheral_vascular_disease",
                "Requirement_for_care", "Respiratory_disease", "Seizures", "Self_harm", "Severe_mental_illness", "Skin_ulcer", "Sleep_problems",
                "Social_vulnerability", "Stress", "Stroke", "Thyroid_problems", "Urinary_incontinence", "Urinary_system_disease", "Visual_impairment",
                "Washing_and_bathing", "Weakness", "Weight_loss"]


df = df[["Fall_Outcome", "DateOnly"]+predictors]

df.rename(columns={"DateOnly": "date", "Fall_Outcome":"outcome"}, inplace=True)
df['date'] = pd.to_datetime(df['date'])

# Use tableone to describe the prior_twelve_months dataframe
columns = predictors + ["outcome"] # Including a subset of predictors for brevity
categorical = columns.copy()
categorical.remove("Age")
categorical.remove("Polypharmacy")
groupby = "outcome"
table_one = tableone.TableOne(prior_twelve_months, columns=columns, categorical=categorical, groupby=groupby, pval=True)
print(table_one.tabulate(tablefmt="github"))
# Save the table to CSV
table_one.to_csv(os.path.join('results/efalls', 'efalls_demographics_table.csv'))



#############################################
# QRISK - FEMALE
#############################################
conn = pyodbc.connect(
    "DRIVER={SQL Server};"
    "SERVER=BHTS-CONNECTYO3;"
    "DATABASE=CB_2151;"
    "Trusted_Connection=yes;"
)

gender = "female"

resultsloc = f'results/qrisk2_{gender}'
os.makedirs(resultsloc, exist_ok=True)

# Query data from a table
query = f"SELECT * FROM qrisk_{gender}s"

# Store query result in a dataframe
df = pd.read_sql(query, conn)

# Close the connection
conn.close()


predictors = ["age", "chol_hdl_ratio", "current_smoker", "bmi", "townsend_score", "sbp", "fh_chd", "treated_htn", "diabetes", "ra", "af", "ckd", "bangladeshi", "chinese", "indian", "other_asian", "pakistani", "black_african", "black_caribbean", "other_ethnicity", "white"]
interactions = ["age_bmi", "age_townsend", "age_sbp", "age_fh_chd", "age_smoking", "age_treated_htn", "age_diabetes", "age_af"]

# select specific columns
df = df[["outcome", "DateOnly", "Age", "chol_hdl_ratio", "smoker_status", "bmi", "townsend_score", "sbp", "fh_chd", "treated_htn", "diabetes", "ra", "af", "ckd", "bangladeshi", "chinese", "indian", "other_asian", "pakistani", "black_african", "black_caribbean", "other_ethnicity", "white"]]
# change some of the column names
df.rename(columns={"DateOnly": "date", "smoker_status": "current_smoker", "Age": "age"}, inplace=True)
print(df.head())
# TODO: remove this after update, it currently randomly add small number to chol_hdl_ratio to prevent "The term is constant!" error until dataset is updated
df['chol_hdl_ratio'] = df['chol_hdl_ratio'] + np.random.normal(0.0, 0.01, size=df['chol_hdl_ratio'].shape)

# merge chinese into other asian due to the small number of chinese population
df.loc[df['chinese'] == 1, 'other_asian'] = 1
df.drop('chinese', axis=1, inplace=True)
predictors.remove('chinese')

df['bmi'] = df['bmi'].astype(float)
df['townsend_score'] = df['townsend_score'].astype(float)

# convert the date column to datetime
df['date'] = pd.to_datetime(df['date'])

# define analysis window
startDate = pd.to_datetime('01-04-2008', dayfirst=True)
endDate = pd.to_datetime('19-08-2015', dayfirst=True) # Most recent record minus 10 years: '2025-08-19'

# restrict to endDate and plot
df = df[df['date']<= endDate]

# select the prior six months used to fit the prefit model and the scalers
prior_six_months = df[(df['date'] >= startDate - relativedelta(months=6)) & (df['date'] < startDate)]

# fit scalers on the prior six months only, apply to entire dataframe, and save parameters
scaler_params = {}
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
for var in ['age', 'chol_hdl_ratio', 'bmi', 'townsend_score']:
    sc = StandardScaler()
    arr = prior_six_months[[var]].astype(float).values
    sc.fit(arr)
    mean_val = float(sc.mean_[0])
    scale_val = float(sc.scale_[0]) if float(sc.scale_[0]) != 0 else 1.0
    scaler_params[var] = {'mean': mean_val, 'scale': scale_val}
    # apply scaling to full dataframe
    df[var] = (df[var].astype(float) - mean_val) / scale_val

# create interaction terms after scaling
df['age_bmi'] = df['age']*df['bmi']
df['age_townsend'] = df['age']*df['townsend_score']
df['age_sbp'] = df['age']*df['sbp']
df['age_fh_chd'] = df['age']*df['fh_chd']
df['age_smoking'] = df['age']*df['current_smoker']
df['age_treated_htn'] = df['age']*df['treated_htn']
df['age_diabetes'] = df['age']*df['diabetes']
df['age_af'] = df['age']*df['af']

# select the prior six months used to fit the prefit model and the scalers
prior_six_months = df[(df['date'] >= pd.to_datetime(startDate) - relativedelta(months=6) ) & (df['date'] < pd.to_datetime(startDate))]

# Use tableone to describe the prior_twelve_months dataframe
columns = predictors + ["outcome"] # Including a subset of predictors for brevity
categorical = columns.copy()
categorical.remove("age")
categorical.remove("age_bmi")
categorical.remove("age_townsend")
categorical.remove("age_sbp")
categorical.remove("age_fh_chd")
categorical.remove("age_smoking")
categorical.remove("age_treated_htn")
categorical.remove("age_diabetes")
categorical.remove("age_af")
categorical.remove("chol_hdl_ratio")
categorical.remove("bmi")
categorical.remove("townsend_score")
categorical.remove("sbp")
groupby = "outcome"
table_one = tableone.TableOne(prior_six_months, columns=columns, categorical=categorical, groupby=groupby, pval=True)
print(table_one.tabulate(tablefmt="github"))
# Save the table to CSV
table_one.to_csv(os.path.join('results/qrisk2_female', 'qrisk2_female_pretrain_demographics_table.csv'))




# Establish connection to SQL Server
conn = pyodbc.connect(
    "DRIVER={SQL Server};"
    "SERVER=BHTS-CONNECTYO3;"
    "DATABASE=CB_2151;"
    "Trusted_Connection=yes;"
)

gender = "female"
resultsloc = f'results/qrisk2_{gender}'

# Query data from a table
query = f"SELECT * FROM qrisk_{gender}s"
# Store query result in a dataframe
df = pd.read_sql(query, conn)

# Close the connection
conn.close()

predictors = ["age", "chol_hdl_ratio", "current_smoker", "bmi", "townsend_score", "sbp", "fh_chd", "treated_htn", "diabetes", "ra", "af", "ckd", "bangladeshi", "chinese", "indian", "other_asian", "pakistani", "black_african", "black_caribbean", "other_ethnicity", "white"]
interactions = ["age_bmi", "age_townsend", "age_sbp", "age_fh_chd", "age_smoking", "age_treated_htn", "age_diabetes", "age_af"]

# select specific columns
df = df[["outcome", "DateOnly", "Age", "chol_hdl_ratio", "smoker_status", "bmi", "townsend_score", "sbp", "fh_chd", "treated_htn", "diabetes", "ra", "af", "ckd", "bangladeshi", "chinese", "indian", "other_asian", "pakistani", "black_african", "black_caribbean", "other_ethnicity", "white"]]
# change some of the column names
df.rename(columns={"DateOnly": "date", "smoker_status": "current_smoker", "Age": "age"}, inplace=True)

# merge chinese into other asian due to the small number of chinese population
df.loc[df['chinese'] == 1, 'other_asian'] = 1
df.drop('chinese', axis=1, inplace=True)
predictors.remove('chinese')

# scale continuous variables using saved scaler parameters; require the scaler JSON to exist
scaler_file = os.path.join(resultsloc, f'qrisk2_{gender}_scaler.json')
if os.path.exists(scaler_file):
    with open(scaler_file, 'r') as sf:
        scaler_params = json.load(sf)
    for var in ['age', 'chol_hdl_ratio', 'bmi', 'townsend_score']:
        # ensure floats and handle missing keys safely
        params = scaler_params.get(var)
        if params is None:
            raise KeyError(f"Scaler parameters for {var} not found in {scaler_file}")
        mean_val = float(params['mean'])
        scale_val = float(params['scale']) if float(params['scale']) != 0 else 1.0
        df[var] = (df[var].astype(float) - mean_val) / scale_val
else:
    # Do not attempt to compute scalers here; require refit script to produce the scaler JSON.
    raise FileNotFoundError(f"Scaler file '{scaler_file}' not found. Please run 'refit_qrisk2_{gender}_model.py' to generate it before running this script.")

df['age_bmi'] = df['age']*df['bmi']
df['age_townsend'] = df['age']*df['townsend_score']
df['age_sbp'] = df['age']*df['sbp']
df['age_fh_chd'] = df['age']*df['fh_chd']
df['age_smoking'] = df['age']*df['current_smoker']
df['age_treated_htn'] = df['age']*df['treated_htn']
df['age_diabetes'] = df['age']*df['diabetes']
df['age_af'] = df['age']*df['af']

# convert the date column to datetime
df['date'] = pd.to_datetime(df['date'])


# Use tableone to describe the prior_twelve_months dataframe
columns = predictors + ["outcome"] # Including a subset of predictors for brevity
categorical = columns.copy()
categorical.remove("age")
categorical.remove("age_bmi")
categorical.remove("age_townsend")
categorical.remove("age_sbp")
categorical.remove("age_fh_chd")
categorical.remove("age_smoking")
categorical.remove("age_treated_htn")
categorical.remove("age_diabetes")
categorical.remove("age_af")
categorical.remove("chol_hdl_ratio")
categorical.remove("bmi")
categorical.remove("townsend_score")
categorical.remove("sbp")
groupby = "outcome"
table_one = tableone.TableOne(df, columns=columns, categorical=categorical, groupby=groupby, pval=True)
print(table_one.tabulate(tablefmt="github"))
# Save the table to CSV
table_one.to_csv(os.path.join('results/qrisk2_female', 'qrisk2_female_demographics_table.csv'))



#############################################
# QRISK - FEMALE
#############################################
conn = pyodbc.connect(
    "DRIVER={SQL Server};"
    "SERVER=BHTS-CONNECTYO3;"
    "DATABASE=CB_2151;"
    "Trusted_Connection=yes;"
)

gender = "male"

resultsloc = f'results/qrisk2_{gender}'
os.makedirs(resultsloc, exist_ok=True)

# Query data from a table
query = f"SELECT * FROM qrisk_{gender}s"

# Store query result in a dataframe
df = pd.read_sql(query, conn)

# Close the connection
conn.close()


predictors = ["age", "chol_hdl_ratio", "current_smoker", "bmi", "townsend_score", "sbp", "fh_chd", "treated_htn", "diabetes", "ra", "af", "ckd", "bangladeshi", "chinese", "indian", "other_asian", "pakistani", "black_african", "black_caribbean", "other_ethnicity", "white"]
interactions = ["age_bmi", "age_townsend", "age_sbp", "age_fh_chd", "age_smoking", "age_treated_htn", "age_diabetes", "age_af"]

# select specific columns
df = df[["outcome", "DateOnly", "Age", "chol_hdl_ratio", "smoker_status", "bmi", "townsend_score", "sbp", "fh_chd", "treated_htn", "diabetes", "ra", "af", "ckd", "bangladeshi", "chinese", "indian", "other_asian", "pakistani", "black_african", "black_caribbean", "other_ethnicity", "white"]]
# change some of the column names
df.rename(columns={"DateOnly": "date", "smoker_status": "current_smoker", "Age": "age"}, inplace=True)
print(df.head())
# TODO: remove this after update, it currently randomly add small number to chol_hdl_ratio to prevent "The term is constant!" error until dataset is updated
df['chol_hdl_ratio'] = df['chol_hdl_ratio'] + np.random.normal(0.0, 0.01, size=df['chol_hdl_ratio'].shape)

# merge chinese into other asian due to the small number of chinese population
df.loc[df['chinese'] == 1, 'other_asian'] = 1
df.drop('chinese', axis=1, inplace=True)
predictors.remove('chinese')

df['bmi'] = df['bmi'].astype(float)
df['townsend_score'] = df['townsend_score'].astype(float)

# convert the date column to datetime
df['date'] = pd.to_datetime(df['date'])

# define analysis window
startDate = pd.to_datetime('01-04-2008', dayfirst=True)
endDate = pd.to_datetime('19-08-2015', dayfirst=True) # Most recent record minus 10 years: '2025-08-19'

# restrict to endDate and plot
df = df[df['date']<= endDate]

# select the prior six months used to fit the prefit model and the scalers
prior_six_months = df[(df['date'] >= startDate - relativedelta(months=6)) & (df['date'] < startDate)]

# fit scalers on the prior six months only, apply to entire dataframe, and save parameters
scaler_params = {}
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
for var in ['age', 'chol_hdl_ratio', 'bmi', 'townsend_score']:
    sc = StandardScaler()
    arr = prior_six_months[[var]].astype(float).values
    sc.fit(arr)
    mean_val = float(sc.mean_[0])
    scale_val = float(sc.scale_[0]) if float(sc.scale_[0]) != 0 else 1.0
    scaler_params[var] = {'mean': mean_val, 'scale': scale_val}
    # apply scaling to full dataframe
    df[var] = (df[var].astype(float) - mean_val) / scale_val

# create interaction terms after scaling
df['age_bmi'] = df['age']*df['bmi']
df['age_townsend'] = df['age']*df['townsend_score']
df['age_sbp'] = df['age']*df['sbp']
df['age_fh_chd'] = df['age']*df['fh_chd']
df['age_smoking'] = df['age']*df['current_smoker']
df['age_treated_htn'] = df['age']*df['treated_htn']
df['age_diabetes'] = df['age']*df['diabetes']
df['age_af'] = df['age']*df['af']

# select the prior six months used to fit the prefit model and the scalers
prior_six_months = df[(df['date'] >= pd.to_datetime(startDate) - relativedelta(months=6) ) & (df['date'] < pd.to_datetime(startDate))]

# Use tableone to describe the prior_twelve_months dataframe
columns = predictors + ["outcome"] # Including a subset of predictors for brevity
categorical = columns.copy()
categorical.remove("age")
categorical.remove("age_bmi")
categorical.remove("age_townsend")
categorical.remove("age_sbp")
categorical.remove("age_fh_chd")
categorical.remove("age_smoking")
categorical.remove("age_treated_htn")
categorical.remove("age_diabetes")
categorical.remove("age_af")
categorical.remove("chol_hdl_ratio")
categorical.remove("bmi")
categorical.remove("townsend_score")
categorical.remove("sbp")
groupby = "outcome"
table_one = tableone.TableOne(prior_six_months, columns=columns, categorical=categorical, groupby=groupby, pval=True)
print(table_one.tabulate(tablefmt="github"))
# Save the table to CSV
table_one.to_csv(os.path.join('results/qrisk2_male', 'qrisk2_male_pretrain_demographics_table.csv'))




# Establish connection to SQL Server
conn = pyodbc.connect(
    "DRIVER={SQL Server};"
    "SERVER=BHTS-CONNECTYO3;"
    "DATABASE=CB_2151;"
    "Trusted_Connection=yes;"
)

gender = "male"
resultsloc = f'results/qrisk2_{gender}'

# Query data from a table
query = f"SELECT * FROM qrisk_{gender}s"
# Store query result in a dataframe
df = pd.read_sql(query, conn)

# Close the connection
conn.close()

predictors = ["age", "chol_hdl_ratio", "current_smoker", "bmi", "townsend_score", "sbp", "fh_chd", "treated_htn", "diabetes", "ra", "af", "ckd", "bangladeshi", "chinese", "indian", "other_asian", "pakistani", "black_african", "black_caribbean", "other_ethnicity", "white"]
interactions = ["age_bmi", "age_townsend", "age_sbp", "age_fh_chd", "age_smoking", "age_treated_htn", "age_diabetes", "age_af"]

# select specific columns
df = df[["outcome", "DateOnly", "Age", "chol_hdl_ratio", "smoker_status", "bmi", "townsend_score", "sbp", "fh_chd", "treated_htn", "diabetes", "ra", "af", "ckd", "bangladeshi", "chinese", "indian", "other_asian", "pakistani", "black_african", "black_caribbean", "other_ethnicity", "white"]]
# change some of the column names
df.rename(columns={"DateOnly": "date", "smoker_status": "current_smoker", "Age": "age"}, inplace=True)

# merge chinese into other asian due to the small number of chinese population
df.loc[df['chinese'] == 1, 'other_asian'] = 1
df.drop('chinese', axis=1, inplace=True)
predictors.remove('chinese')

# scale continuous variables using saved scaler parameters; require the scaler JSON to exist
scaler_file = os.path.join(resultsloc, f'qrisk2_{gender}_scaler.json')
if os.path.exists(scaler_file):
    with open(scaler_file, 'r') as sf:
        scaler_params = json.load(sf)
    for var in ['age', 'chol_hdl_ratio', 'bmi', 'townsend_score']:
        # ensure floats and handle missing keys safely
        params = scaler_params.get(var)
        if params is None:
            raise KeyError(f"Scaler parameters for {var} not found in {scaler_file}")
        mean_val = float(params['mean'])
        scale_val = float(params['scale']) if float(params['scale']) != 0 else 1.0
        df[var] = (df[var].astype(float) - mean_val) / scale_val
else:
    # Do not attempt to compute scalers here; require refit script to produce the scaler JSON.
    raise FileNotFoundError(f"Scaler file '{scaler_file}' not found. Please run 'refit_qrisk2_{gender}_model.py' to generate it before running this script.")

df['age_bmi'] = df['age']*df['bmi']
df['age_townsend'] = df['age']*df['townsend_score']
df['age_sbp'] = df['age']*df['sbp']
df['age_fh_chd'] = df['age']*df['fh_chd']
df['age_smoking'] = df['age']*df['current_smoker']
df['age_treated_htn'] = df['age']*df['treated_htn']
df['age_diabetes'] = df['age']*df['diabetes']
df['age_af'] = df['age']*df['af']

# convert the date column to datetime
df['date'] = pd.to_datetime(df['date'])


# Use tableone to describe the prior_twelve_months dataframe
columns = predictors + ["outcome"] # Including a subset of predictors for brevity
categorical = columns.copy()
categorical.remove("age")
categorical.remove("age_bmi")
categorical.remove("age_townsend")
categorical.remove("age_sbp")
categorical.remove("age_fh_chd")
categorical.remove("age_smoking")
categorical.remove("age_treated_htn")
categorical.remove("age_diabetes")
categorical.remove("age_af")
categorical.remove("chol_hdl_ratio")
categorical.remove("bmi")
categorical.remove("townsend_score")
categorical.remove("sbp")
groupby = "outcome"
table_one = tableone.TableOne(df, columns=columns, categorical=categorical, groupby=groupby, pval=True)
print(table_one.tabulate(tablefmt="github"))
# Save the table to CSV
table_one.to_csv(os.path.join('results/qrisk2_male', 'qrisk2_male_demographics_table.csv'))