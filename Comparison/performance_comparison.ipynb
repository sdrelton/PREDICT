{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from PREDICT import PREDICT\n",
    "from PREDICT.Models import *\n",
    "from PREDICT.Metrics import *\n",
    "from PREDICT.Triggers import *\n",
    "from PREDICT.Plots import *\n",
    "from Comparison.Detect_Functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Methods to Repair Temporal Drift\n",
    "\n",
    "In this notebook, four methods to repair temporal drift are compared:\n",
    "\n",
    "1) Regular model testing\n",
    "2) Statistical process control\n",
    "3) Static threshold\n",
    "4) Bayesian variable relative change\n",
    "\n",
    "\n",
    "\n",
    "These methods are compared for four scenarios:\n",
    "\n",
    "1) Fast predictor change - COVID pandemic\n",
    "2) Slow predictor change - population-based diabetes increase\n",
    "3) Outcome drift - change in prevalence of diabetes mellitus\n",
    "4) Multivariate drift - the diabetes prevalence increases whilst smoking prevalence decreases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = pd.to_datetime('01-06-2019', dayfirst=True) # 01-06-2019\n",
    "endDate = pd.to_datetime('31-12-2021', dayfirst=True)\n",
    "num_patients = 40 # number of patients per each timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast Change - COVID Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs = 0\n",
    "recalthreshold = 0.86 # Paper has AUROC of 0.91, with lower CI at 0.86\n",
    "\n",
    "custom_impacts = [0.1, 0.2]#, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 2.0, 2.5, 3.0]\n",
    "switchDateStrings = ['01-04-2020'] # Keep this as just one switchDate as other methods only look at one startDate/deployment date\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\":0, \"SPC7\":0, \"Bayesian\": 0})\n",
    "\n",
    "hr_age = 0.5\n",
    "hr_ldh = 9.8\n",
    "hr_comorbidity = 3.9\n",
    "\n",
    "log_age = np.log(hr_age)\n",
    "log_ldh = np.log(hr_ldh)\n",
    "log_comorbidity = np.log(hr_comorbidity)\n",
    "\n",
    "for switchDateidx, switchDateString in enumerate(switchDateStrings):\n",
    "    for custom_impact in custom_impacts:\n",
    "        mydict = {\n",
    "                'date': list(),\n",
    "                'outcome': list(),\n",
    "                'prediction': list(),\n",
    "                'age': list(),\n",
    "                'sex': list(),\n",
    "                'comorbidity': list(),\n",
    "                'ldh_high': list()\n",
    "            }\n",
    "\n",
    "        # Define date range and COVID shock periods\n",
    "        switchDate = pd.to_datetime(switchDateString, dayfirst=True)  # COVID starts spreading\n",
    "        switchDate2 = pd.to_datetime('01-06-2020', dayfirst=True)  # Peak of the pandemic\n",
    "        recoveryDate = pd.to_datetime('01-06-2021', dayfirst=True)  # Start of recovery phase\n",
    "        numdays = (endDate - startDate).days\n",
    "        switchDays = (switchDate - startDate).days\n",
    "        switch2Days = (switchDate2 - startDate).days\n",
    "        recoveryDays = (recoveryDate - startDate).days\n",
    "\n",
    "        for i in range(numdays):\n",
    "            curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "            age = np.random.normal(44, 16.3, num_patients)  # Mean age 44 years, std 16.3\n",
    "            sex = np.random.binomial(1, 0.562, num_patients) # 56.2% are male\n",
    "            comorbidity = np.random.binomial(1, 0.3, num_patients)  # 30% have comorbidities\n",
    "            ldh_high = np.random.binomial(1, 0.15, num_patients)  # 15% have LDH >500 U/L\n",
    "\n",
    "            # Calculate baseline log-odds\n",
    "            # sex influence 1.2 due to not being provided in the paper\n",
    "            lp = -1.5 + log_age * (age - 44) / 16.3 +  log_ldh * (ldh_high - 0.15) + log_comorbidity * (comorbidity - 0.3) + 1.2 * (sex - 0.562)\n",
    "            curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "            # Simulate COVID effects\n",
    "            if switchDays <= i < switch2Days:\n",
    "                lp += custom_impact  # Initial impact of COVID\n",
    "            elif switch2Days <= i < recoveryDays:\n",
    "                lp += custom_impact + 0.5  # Peak of the pandemic\n",
    "            elif i >= recoveryDays:\n",
    "                lp -= 1.0  # Recovery period—improved health outcomes\n",
    "\n",
    "            # Generate outcomes\n",
    "            curoutcomes = np.random.binomial(1, 1 / (1 + np.exp(-lp)))  # Simulate COVID events\n",
    "\n",
    "            # Append to dictionary\n",
    "            mydict['date'].extend([curday] * num_patients)\n",
    "            mydict['outcome'].extend(curoutcomes)\n",
    "            mydict['prediction'].extend(curpredictions)\n",
    "            mydict['age'].extend(age)\n",
    "            mydict['sex'].extend(sex)\n",
    "            mydict['comorbidity'].extend(comorbidity)\n",
    "            mydict['ldh_high'].extend(ldh_high)\n",
    "\n",
    "        df = pd.DataFrame(mydict)\n",
    "\n",
    "        covid_metrics_df = get_metrics_recal_methods(df, custom_impact, recalthreshold)\n",
    "\n",
    "        # ############################ Regular, static and SPC testing ############################\n",
    "        # model = RecalibratePredictions()\n",
    "        # model.trigger = TimeframeTrigger(model=model, updateTimestep=100, dataStart=df['date'].min(), dataEnd=df['date'].max())\n",
    "        # mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "        # mytest.addLogHook(Accuracy(model))\n",
    "        # mytest.addLogHook(AUROC(model))\n",
    "        # mytest.addLogHook(Precision(model))\n",
    "        # mytest.run()\n",
    "        # log = mytest.getLog()\n",
    "\n",
    "        # regular_testing_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['Regular Testing'] * len(log[\"Accuracy\"]))})\n",
    "\n",
    "        # ####################################### Static Threshold Testing #######################################\n",
    "        # model = RecalibratePredictions()\n",
    "        # model.trigger = AUROCThreshold(model=model, update_threshold=recalthreshold)\n",
    "        # mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "        # mytest.addLogHook(Accuracy(model))\n",
    "        # mytest.addLogHook(AUROC(model))\n",
    "        # mytest.addLogHook(Precision(model))\n",
    "        # mytest.run()\n",
    "        # log = mytest.getLog()\n",
    "\n",
    "        # static_thresh_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['Static Threshold'] * len(log[\"Accuracy\"]))})\n",
    "\n",
    "        # ####################################### SPC3 Testing #######################################\n",
    "        # model = RecalibratePredictions()\n",
    "        # model.trigger = SPCTrigger(model=model, input_data=df, numMonths=3, verbose=False)\n",
    "        # mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "        # mytest.addLogHook(Accuracy(model))\n",
    "        # mytest.addLogHook(AUROC(model))\n",
    "        # mytest.addLogHook(Precision(model))\n",
    "        # mytest.run()\n",
    "        # log = mytest.getLog()\n",
    "\n",
    "        # spc3_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['SPC3'] * len(log[\"Accuracy\"]))})\n",
    "\n",
    "        # ####################################### SPC5 Testing #######################################\n",
    "        # model = RecalibratePredictions()\n",
    "        # model.trigger = SPCTrigger(model=model, input_data=df, numMonths=5, verbose=False)\n",
    "        # mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "        # mytest.addLogHook(Accuracy(model))\n",
    "        # mytest.addLogHook(AUROC(model))\n",
    "        # mytest.addLogHook(Precision(model))\n",
    "        # mytest.run()\n",
    "        # log = mytest.getLog()\n",
    "\n",
    "        # spc5_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['SPC5'] * len(log[\"Accuracy\"]))})\n",
    "\n",
    "        # ####################################### SPC7 Testing #######################################\n",
    "        # model = RecalibratePredictions()\n",
    "        # model.trigger = SPCTrigger(model=model, input_data=df, numMonths=3, verbose=False)\n",
    "        # mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "        # mytest.addLogHook(Accuracy(model))\n",
    "        # mytest.addLogHook(AUROC(model))\n",
    "        # mytest.addLogHook(Precision(model))\n",
    "        # mytest.run()\n",
    "        # log = mytest.getLog()\n",
    "\n",
    "        # spc7_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['SPC7'] * len(log[\"Accuracy\"]))})\n",
    "\n",
    "        ########################################### Bayesian Testing #######################################\n",
    "        # bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (-1, 2), \"age\": (log_age, 2), \"sex\": (1, 2), \"comorbidity\": (log_comorbidity, 2), \"ldh_high\": (log_ldh, 2)}, cores=4, verbose=False, draws=1000, tune=250, chains=4)\n",
    "        # bay_model.trigger = BayesianRefitTrigger(model=bay_model, input_data=df, refitFrequency=1)\n",
    "        # mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month')\n",
    "        # mytest.addLogHook(Accuracy(model))\n",
    "        # mytest.addLogHook(AUROC(model))\n",
    "        # mytest.addLogHook(Precision(model))\n",
    "        # mytest.run()\n",
    "        # log = mytest.getLog()\n",
    "\n",
    "        # bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "        \n",
    "        ########################################### Save Metrics #######################################\n",
    "\n",
    "        # concatenate all the dataframes into one\n",
    "        #covid_metrics_df = pd.concat([covid_metrics_df, bayes_metrics], ignore_index=True)\n",
    "        covid_metrics_df[\"Data_Type\"] = \"COVID Simulation\"\n",
    "\n",
    "        covid_metrics_df.to_csv('performance_metrics.csv', mode='a', header=False, index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>impact_or_prev</th>\n",
       "      <th>Method</th>\n",
       "      <th>Data_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.806319</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>0.817742</td>\n",
       "      <td>0.827136</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>0.820077</td>\n",
       "      <td>0.680982</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.804994</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>0.797581</td>\n",
       "      <td>0.778766</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>0.867742</td>\n",
       "      <td>0.877280</td>\n",
       "      <td>0.487685</td>\n",
       "      <td>0.2</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0.860484</td>\n",
       "      <td>0.836720</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>0.2</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.838538</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>0.2</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.846178</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.2</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.822070</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>0.2</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time  Accuracy     AUROC  Precision impact_or_prev           Method  \\\n",
       "0   2019-07-01  0.805833  0.806319   0.642857            0.2  Regular Testing   \n",
       "1   2019-08-01  0.817742  0.827136   0.711864            0.2  Regular Testing   \n",
       "2   2019-09-01  0.809677  0.820077   0.680982            0.2  Regular Testing   \n",
       "3   2019-10-01  0.803333  0.804994   0.655556            0.2  Regular Testing   \n",
       "4   2019-11-01  0.797581  0.778766   0.625698            0.2  Regular Testing   \n",
       "..         ...       ...       ...        ...            ...              ...   \n",
       "145 2021-08-01  0.867742  0.877280   0.487685            0.2             SPC7   \n",
       "146 2021-09-01  0.860484  0.836720   0.473118            0.2             SPC7   \n",
       "147 2021-10-01  0.862500  0.838538   0.497076            0.2             SPC7   \n",
       "148 2021-11-01  0.864516  0.846178   0.494444            0.2             SPC7   \n",
       "149 2021-12-01  0.855000  0.822070   0.430108            0.2             SPC7   \n",
       "\n",
       "            Data_Type  \n",
       "0    COVID Simulation  \n",
       "1    COVID Simulation  \n",
       "2    COVID Simulation  \n",
       "3    COVID Simulation  \n",
       "4    COVID Simulation  \n",
       "..                ...  \n",
       "145  COVID Simulation  \n",
       "146  COVID Simulation  \n",
       "147  COVID Simulation  \n",
       "148  COVID Simulation  \n",
       "149  COVID Simulation  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome Prevalence - Diabetes Outcome Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs = 0\n",
    "recalthreshold = 0.77 # Paper has AUROC of 0.81, with lower CI at 0.77 \n",
    "\n",
    "prev_increases = np.arange(1.0001, 1.003, 0.0002).tolist()\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\": 0, \"SPC7\": 0, \"Bayesian\": 0})\n",
    "\n",
    "# coefficients from non-laboratory logistic regression model\n",
    "age_at_lv_coef = 0.16 # lv = last visit\n",
    "bmi_coef = 0.68\n",
    "hip_circ_coef = -0.05\n",
    "sex_coef = -0.14\n",
    "height_coef = -0.15\n",
    "waist_circ_coef = 0.31\n",
    "waist_hips_ratio_coef = 0.54\n",
    "weight_coef = 0.03\n",
    "time_between_visits_coef = 0.38\n",
    "bias_coef = -0.74\n",
    "\n",
    "# mean and standard deviation for each predictor\n",
    "# variable at the last visit is used\n",
    "mean_age, std_age = 62.9, 7.5\n",
    "mean_bmi, std_bmi = 26.6, 4.4\n",
    "mean_hip_circ, std_hip_circ = 101.6, 8.8\n",
    "perc_male, mean_height, std_height = 0.478, 169, 9.2\n",
    "mean_waist_circ, std_waist_circ = 88.7, 12.7\n",
    "mean_weight, std_weight = 76.2, 15.2\n",
    "mean_time_between_visits, std_time_between_visits = 7.3, 2.3\n",
    "\n",
    "mean_waist_hips_ratio = mean_waist_circ / mean_hip_circ\n",
    "std_waist_hips_ratio = mean_waist_hips_ratio * np.sqrt(\n",
    "    (std_waist_circ / mean_waist_circ) ** 2 + (std_hip_circ / mean_hip_circ) ** 2)\n",
    "\n",
    "dm_prev = 0.07  # Initial diabetes prevalence = 7%\n",
    "for prev_increase in prev_increases:\n",
    "    mydict = {\n",
    "            'date': list(),\n",
    "            'outcome': list(),\n",
    "            'prediction': list(),\n",
    "            'age': list(),\n",
    "            'bmi':list(),\n",
    "            'hip_circ': list(),\n",
    "            'sex': list(),\n",
    "            'height': list(),\n",
    "            'waist_circ': list(),\n",
    "            'waist_hips_ratio': list(),\n",
    "            'weight': list(),\n",
    "            'time_between_visits': list()\n",
    "        }\n",
    "\n",
    "    num_patients = 60\n",
    "    numdays = (endDate - startDate).days\n",
    "    \n",
    "    for i in range(numdays):\n",
    "        curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "        age = np.random.normal(mean_age, std_age, num_patients)\n",
    "        bmi = np.random.normal(mean_bmi, std_bmi, num_patients)\n",
    "        hip_circ = np.random.normal(mean_hip_circ, std_hip_circ, num_patients)\n",
    "        sex = np.random.binomial(1, perc_male, num_patients)\n",
    "        height = np.random.normal(mean_height, std_height, num_patients)\n",
    "        waist_circ = np.random.normal(mean_waist_circ, std_waist_circ, num_patients)\n",
    "        waist_hips_ratio = np.random.normal(mean_waist_hips_ratio, std_waist_hips_ratio, num_patients)\n",
    "        weight = np.random.normal(mean_weight, std_weight, num_patients)\n",
    "        time_between_visits = np.random.normal(mean_time_between_visits, std_time_between_visits, num_patients)\n",
    "\n",
    "        # Calculate baseline log-odds\n",
    "        lp = bias_coef + age_at_lv_coef * (age - mean_age)/std_age + bmi_coef * (bmi - mean_bmi)/std_bmi + hip_circ_coef * (hip_circ - mean_hip_circ)/std_hip_circ + sex_coef * (sex - perc_male) + height_coef * (height - mean_height)/std_height + waist_circ_coef * (waist_circ - mean_waist_circ)/std_waist_circ + waist_hips_ratio_coef * (waist_hips_ratio - mean_waist_hips_ratio)/std_waist_hips_ratio + weight_coef * (weight - mean_weight)/std_weight + time_between_visits_coef * (time_between_visits - mean_time_between_visits)/std_time_between_visits\n",
    "        curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "        # Generate outcomes to simulate diabetes rates increasing over time\n",
    "        if i % 30 == 0:\n",
    "            dm_prev *= prev_increase # this increases the probability by x% each month\n",
    "\n",
    "        mod_lp = 1/(1+np.exp(lp + dm_prev))\n",
    "        # intercept changed, but model weights constant\n",
    "        # diabetes increased as outcome, but not explained by data\n",
    "        curoutcomes = np.random.binomial(1, mod_lp)           \n",
    "        \n",
    "\n",
    "        # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "        mydict['date'].extend([curday] * num_patients)\n",
    "        mydict['outcome'].extend(curoutcomes)\n",
    "        mydict['prediction'].extend(curpredictions)\n",
    "        mydict['age'].extend(age)\n",
    "        mydict['bmi'].extend(bmi)\n",
    "        mydict['hip_circ'].extend(hip_circ)\n",
    "        mydict['sex'].extend(sex)\n",
    "        mydict['height'].extend(height)\n",
    "        mydict['waist_circ'].extend(waist_circ)\n",
    "        mydict['waist_hips_ratio'].extend(waist_hips_ratio)\n",
    "        mydict['weight'].extend(weight)\n",
    "        mydict['time_between_visits'].extend(time_between_visits)\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(mydict)  \n",
    "    out_prev_metrics_df = get_metrics_recal_methods(df, dm_prev, recalthreshold)\n",
    "    \n",
    "    \n",
    "    ########################################### Bayesian Testing #######################################\n",
    "    # bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (bias_coef, 2), \"age\": (age_at_lv_coef, 2), \"bmi\": (bmi_coef, 2), \"hip_circ\": (hip_circ_coef, 2),\n",
    "    #                                             \"sex\": (sex_coef, 2), \"height\":(height_coef, 2), \"waist_circ\":(waist_circ_coef, 2),\n",
    "    #                                             \"waist_hips_ratio\":(waist_hips_ratio_coef, 2), \"weight\":(weight_coef, 2), \n",
    "    #                                             \"time_between_visits\":(time_between_visits_coef, 2)}, cores=4, verbose=False)\n",
    "    # bay_model.trigger = BayesianRefitTrigger(model=bay_model, input_data=df, refitFrequency=1)\n",
    "    # mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month')\n",
    "    # mytest.addLogHook(Accuracy(model))\n",
    "    # mytest.addLogHook(AUROC(model))\n",
    "    # mytest.addLogHook(Precision(model))\n",
    "    # mytest.run()\n",
    "    # log = mytest.getLog()\n",
    "\n",
    "    # bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(dm_prev)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "    \n",
    "    ########################################### Save Metrics #######################################\n",
    "\n",
    "    # concatenate all the dataframes into one\n",
    "    #out_prev_metrics_df = pd.concat([out_prev_metrics_df, bayes_metrics], ignore_index=True)\n",
    "    out_prev_metrics_df[\"Data_Type\"] = \"Outcome Prevalence Simulation\"\n",
    "\n",
    "    out_prev_metrics_df.to_csv('performance_metrics.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slow change data simulation - Diabetes as a Predictor (increasing over time) with CKD as the predicted outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs = 0\n",
    "recalthreshold = 0.851 # Paper has AUROC of 0.889, with lower CI at 0.851\n",
    "\n",
    "prev_increases = np.arange(1.0001, 1.0030, 0.0002).tolist()\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\": 0, \"SPC7\": 0, \"Bayesian\": 0})\n",
    "\n",
    "mean_TGFB, std_TGFB = 13.23, 5.18\n",
    "mean_ADMA, std_ADMA= 101.1, 64.8\n",
    "mean_BUN, std_BUN = 5.45, 1.11\n",
    "mean_age, std_age = 63.27, 10.09 \n",
    "\n",
    "TGFB_coef = 1.84\n",
    "ADMA_coef = 1.137\n",
    "DM_coef = 0.84\n",
    "BUN_coef = 0.497\n",
    "elderly_coef = 0.603\n",
    "\n",
    "perc_dm = 0.05 # 5.5%\n",
    "for prev_increase in prev_increases:\n",
    "    mydict = {\n",
    "            'date': list(),\n",
    "            'outcome': list(),\n",
    "            'prediction': list(),\n",
    "            'TGFB': list(),\n",
    "            'ADMA':list(),\n",
    "            'DM': list(),\n",
    "            'BUN': list(),\n",
    "            'elderly': list()\n",
    "        }\n",
    "\n",
    "    num_patients = 60\n",
    "\n",
    "    numdays = (endDate - startDate).days\n",
    "\n",
    "    for i in range(numdays):\n",
    "        curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "        # increase the prevalence of diabetes over time\n",
    "        if i % 30 == 0:\n",
    "            perc_dm *= prev_increase # this increases the probability by x% each month\n",
    "\n",
    "        TGFB = get_binom_from_normal(mean_TGFB, std_TGFB, num_patients, 1.011)\n",
    "        ADMA = get_binom_from_normal(mean_ADMA, std_ADMA, num_patients, 0.019)\n",
    "        DM = np.random.binomial(1, perc_dm, num_patients)\n",
    "        BUN = get_binom_from_normal(mean_BUN, std_BUN, num_patients, 5.9)\n",
    "        elderly = get_binom_from_normal(mean_age, std_age, num_patients, 60)\n",
    "\n",
    "        # Calculate baseline log-odds\n",
    "        # non_genetic_risk_score_model from paper\n",
    "        lp = TGFB_coef * TGFB + ADMA_coef * ADMA + DM_coef * DM + BUN_coef * BUN + elderly_coef * elderly\n",
    "\n",
    "        curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "        curoutcomes = np.random.binomial(1, curpredictions)           \n",
    "        \n",
    "        # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "        mydict['date'].extend([curday] * num_patients)\n",
    "        mydict['outcome'].extend(curoutcomes)\n",
    "        mydict['prediction'].extend(curpredictions)\n",
    "        mydict['TGFB'].extend(TGFB)\n",
    "        mydict['ADMA'].extend(ADMA)\n",
    "        mydict['DM'].extend(DM)\n",
    "        mydict['BUN'].extend(BUN)\n",
    "        mydict['elderly'].extend(elderly)\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(mydict)\n",
    "    slow_change_metrics_df = get_metrics_recal_methods(df, perc_dm, recalthreshold)\n",
    "    \n",
    "\n",
    "    ########################################### Bayesian Testing #######################################\n",
    "    # bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (-1, 2), \"TGFB\": (TGFB_coef, 2), \"ADMA\": (ADMA_coef, 2), \"DM\": (DM_coef, 2), \"BUN\": (BUN_coef, 2),\n",
    "    #                                             \"elderly\": (elderly_coef, 2)}, cores=4, verbose=False)\n",
    "    # bay_model.trigger = BayesianRefitTrigger(model=bay_model, input_data=df, refitFrequency=1)\n",
    "    # mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month')\n",
    "    # mytest.addLogHook(Accuracy(model))\n",
    "    # mytest.addLogHook(AUROC(model))\n",
    "    # mytest.addLogHook(Precision(model))\n",
    "    # mytest.run()\n",
    "    # log = mytest.getLog()\n",
    "\n",
    "    # bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(perc_dm)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "    \n",
    "    ########################################### Save Metrics #######################################\n",
    "\n",
    "    # concatenate all the dataframes into one\n",
    "    #slow_change_metrics_df = pd.concat([slow_change_metrics_df, bayes_metrics], ignore_index=True)\n",
    "    slow_change_metrics_df[\"Data_Type\"] = \"Slow Change Simulation\"\n",
    "\n",
    "    slow_change_metrics_df.to_csv('performance_metrics.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Model - QRISK2 - Diabetes increasing whilst smoking is decreasing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalthreshold = 0.811 # Paper has AUROC of 0.814, with lower CI at 0.811 \n",
    "\n",
    "# Define the coefficients (hazard ratios converted to log-odds)\n",
    "coefs = {\"White\": np.log(1), \n",
    "    \"Indian\": np.log(1.43),\n",
    "    \"Pakistani\": np.log(1.8),\n",
    "    \"Bangladeshi\": np.log(1.35),\n",
    "    \"Other_Asian\": np.log(1.15),\n",
    "    \"Black_Caribbean\": np.log(1.08),\n",
    "    \"Black_African\": np.log(0.58),\n",
    "    \"Chinese\": np.log(0.69),\n",
    "    \"Other\": np.log(1.04),\n",
    "    \"Age\": np.log(1.66),\n",
    "    \"BMI\": np.log(1.08),\n",
    "    \"Townsend\": np.log(1.37),\n",
    "    \"SBP\": np.log(1.2),\n",
    "    \"CholHDL_ratio\": np.log(1.17),\n",
    "    \"Family_CHD\": np.log(1.99),\n",
    "    \"Current_smoker\": np.log(1.8),\n",
    "    \"Treated_HTN\": np.log(1.54),\n",
    "    \"DM\": np.log(2.54),\n",
    "    \"RA\": np.log(1.5),\n",
    "    \"AF\": np.log(3.06),\n",
    "    \"Renal_disease\": np.log(1.7),\n",
    "    \"Age_BMI\": np.log(0.976),\n",
    "    \"Age_Townsend\": np.log(0.938),\n",
    "    \"Age_SBP\": np.log(0.966),\n",
    "    \"Age_Family_CHD\": np.log(0.927),\n",
    "    \"Age_Smoking\": np.log(0.931),\n",
    "    \"Age_Treated_HTN\": np.log(0.952),\n",
    "    \"Age_DM\": np.log(0.904),\n",
    "    \"Age_AF\": np.log(0.858)\n",
    "}\n",
    "\n",
    "\n",
    "# Percentage variables (/100)\n",
    "percent_family_history_chd = 0.126\n",
    "percent_treated_hypertension = 0.0712\n",
    "percent_rheumatoid_arthritis = 0.0093\n",
    "percent_atrial_fibrillation = 0.0035\n",
    "percent_renal_disease = 0.0016\n",
    "\n",
    "# Age variable\n",
    "median_age, IQR_age = 49, 19\n",
    "mean_age, std_age = median_age, IQR_age / 1.35\n",
    "\n",
    "# Mean and standard deviation variables\n",
    "mean_bmi, std_bmi = 33.8, 6.1\n",
    "mean_townsend, std_townsend = 17.67, 3.534\n",
    "mean_sbp, std_sbp = 26.6, 4.4\n",
    "mean_chol_hdl_ratio, std_chol_hdl_ratio = 3.66, 0.144\n",
    "\n",
    "\n",
    "intercept = None\n",
    "baseline_prob = 0.233 # 23.3%\n",
    "total_runs = 0\n",
    "\n",
    "prev_increases = np.arange(1.0001, 1.003, 0.0002).tolist() # Increase in diabetes prevalence over time\n",
    "smoking_decrease = np.arange(0.9995, 0.9967, -0.0002).tolist()  # Decrease in smoking prevalence over time\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\": 0, \"SPC7\": 0, \"Bayesian\": 0})\n",
    "\n",
    "percent_type_2_diabetes = 0.017 # reset these for each start date\n",
    "percent_current_smoker = 0.228\n",
    "for num, prev_increase in enumerate(prev_increases):\n",
    "    mydict = {\n",
    "            'date': list(),\n",
    "            'outcome': list(),\n",
    "            'prediction': list(),\n",
    "            'White': list(),\n",
    "            'Indian': list(),\n",
    "            'Pakistani': list(),\n",
    "            'Bangladeshi': list(),\n",
    "            'Other_Asian': list(),\n",
    "            'Black_Caribbean': list(),\n",
    "            'Black_African': list(),\n",
    "            'Chinese': list(),\n",
    "            'Other': list(),\n",
    "            'Age': list(),\n",
    "            'BMI':list(),\n",
    "            'Townsend': list(),\n",
    "            'SBP': list(),\n",
    "            'CholHDL_ratio': list(),\n",
    "            'Family_CHD': list(),\n",
    "            'Current_smoker': list(),\n",
    "            'Treated_HTN': list(),\n",
    "            'DM': list(),\n",
    "            'RA': list(),\n",
    "            'AF': list(),\n",
    "            'Renal_disease': list()\n",
    "        }\n",
    "\n",
    "    num_patients = 60\n",
    "\n",
    "    # Define date range\n",
    "    numdays = (endDate - startDate).days\n",
    "\n",
    "    \n",
    "    for i in range(numdays):\n",
    "        curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "        # increase the prevalence of diabetes over time\n",
    "        if i % 30 == 0:\n",
    "            percent_type_2_diabetes *= prev_increase # this increases the probability by x% each month\n",
    "            percent_current_smoker *= smoking_decrease[num] # decrease the prevalence of smoking over time\n",
    "        if percent_type_2_diabetes < 0 or percent_type_2_diabetes > 1:\n",
    "            print(\"Percentage of people with DM\", percent_type_2_diabetes)\n",
    "        if percent_current_smoker < 0 or percent_current_smoker > 1:\n",
    "            print(\"Percentage of people who are current smokers\", percent_current_smoker)\n",
    "\n",
    "        # Generate random factors for patients using z-score normalization for non-binary values\n",
    "        pat_factors = {\"Age\": (np.random.normal(mean_age, std_age, num_patients) - mean_age) / std_age, \n",
    "            \"BMI\": (np.random.normal(mean_bmi, std_bmi, num_patients) - mean_bmi) /std_bmi,\n",
    "            \"Townsend\": (np.random.normal(mean_townsend, std_townsend, num_patients) - mean_townsend) / std_townsend,\n",
    "            \"SBP\": (np.random.normal(mean_sbp, std_sbp, num_patients) - mean_sbp) / std_sbp,\n",
    "            \"CholHDL_ratio\": (np.random.normal(mean_chol_hdl_ratio, std_chol_hdl_ratio, num_patients) - mean_chol_hdl_ratio) / std_chol_hdl_ratio,\n",
    "            \"Family_CHD\": np.random.binomial(1, percent_family_history_chd, num_patients),\n",
    "            \"Current_smoker\": np.random.binomial(1, percent_current_smoker, num_patients),\n",
    "            \"Treated_HTN\": np.random.binomial(1, percent_treated_hypertension, num_patients),\n",
    "            \"DM\": np.random.binomial(1, percent_type_2_diabetes, num_patients),\n",
    "            \"RA\": np.random.binomial(1, percent_rheumatoid_arthritis, num_patients),\n",
    "            \"AF\": np.random.binomial(1, percent_atrial_fibrillation, num_patients),\n",
    "            \"Renal_disease\": np.random.binomial(1, percent_renal_disease, num_patients)\n",
    "        }\n",
    "\n",
    "        ethnicity_assignment = select_ethnic_group(num_patients)\n",
    "        pat_factors.update(ethnicity_assignment) # combine ethnicity dict with ethnic\n",
    "\n",
    "        # Calculate baseline log-odds\n",
    "        weighted_coef_sum = coefs['White']*pat_factors['White'] + coefs['Indian']*pat_factors['Indian'] + coefs['Pakistani']*pat_factors['Pakistani'] + coefs['Bangladeshi']*pat_factors['Bangladeshi'] \n",
    "        weighted_coef_sum += coefs['Other_Asian']*pat_factors['Other_Asian'] + coefs['Black_Caribbean']*pat_factors['Black_Caribbean'] + coefs['Black_African']*pat_factors['Black_African'] \n",
    "        weighted_coef_sum += coefs['Chinese']*pat_factors['Chinese'] + coefs['Other']*pat_factors['Other'] + coefs['Age']*(pat_factors['Age']) + coefs['BMI']*(pat_factors['BMI']) \n",
    "        weighted_coef_sum += coefs['Townsend']*(pat_factors['Townsend']) + coefs['SBP']*(pat_factors['SBP']) + coefs['CholHDL_ratio']*(pat_factors['CholHDL_ratio']) \n",
    "        weighted_coef_sum += coefs[\"Family_CHD\"]*(pat_factors[\"Family_CHD\"]) + coefs[\"Current_smoker\"]*(pat_factors[\"Current_smoker\"]) \n",
    "        weighted_coef_sum += coefs[\"Treated_HTN\"]*(pat_factors[\"Treated_HTN\"]) + coefs[\"DM\"]*(pat_factors[\"DM\"]) + coefs[\"RA\"]*(pat_factors[\"RA\"]) \n",
    "        weighted_coef_sum += coefs[\"AF\"]*(pat_factors[\"AF\"]) + coefs[\"Renal_disease\"]*(pat_factors[\"Renal_disease\"]) + (coefs[\"Age_BMI\"] * pat_factors[\"Age\"] * pat_factors[\"BMI\"]) \n",
    "        weighted_coef_sum += (coefs[\"Age_Townsend\"] * pat_factors[\"Age\"] * pat_factors[\"Townsend\"]) + (coefs[\"Age_SBP\"] * pat_factors[\"Age\"] * pat_factors[\"SBP\"]) \n",
    "        weighted_coef_sum += (coefs[\"Age_Family_CHD\"] * pat_factors[\"Age\"] * pat_factors[\"Family_CHD\"]) + (coefs[\"Age_Smoking\"] * pat_factors[\"Age\"] * pat_factors[\"Current_smoker\"]) \n",
    "        weighted_coef_sum += (coefs[\"Age_Treated_HTN\"] * pat_factors[\"Age\"] * pat_factors[\"Treated_HTN\"]) + (coefs[\"Age_DM\"] * pat_factors[\"Age\"] * pat_factors[\"DM\"])\n",
    "        weighted_coef_sum += (coefs[\"Age_AF\"] * pat_factors[\"Age\"] * pat_factors[\"AF\"])\n",
    "\n",
    "    \n",
    "        intercept = np.log(baseline_prob / (1 - baseline_prob))\n",
    "        \n",
    "        # Compute log-odds\n",
    "        lp = intercept + weighted_coef_sum\n",
    "        lp = np.clip(lp, -500, 500)  # Clip to avoid overflow issues\n",
    "        \n",
    "        curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "        \n",
    "        \n",
    "        curoutcomes = np.random.binomial(1, curpredictions)         \n",
    "        \n",
    "\n",
    "        # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "        mydict['date'].extend([curday] * num_patients)\n",
    "        mydict['outcome'].extend(curoutcomes)\n",
    "        mydict['prediction'].extend(curpredictions)\n",
    "        mydict['White'].extend(pat_factors['White'])\n",
    "        mydict['Indian'].extend(pat_factors['Indian'])\n",
    "        mydict['Pakistani'].extend(pat_factors['Pakistani'])\n",
    "        mydict['Bangladeshi'].extend(pat_factors['Bangladeshi'])\n",
    "        mydict['Other_Asian'].extend(pat_factors['Other_Asian'])\n",
    "        mydict['Black_Caribbean'].extend(pat_factors['Black_Caribbean'])\n",
    "        mydict['Black_African'].extend(pat_factors['Black_African'])\n",
    "        mydict['Chinese'].extend(pat_factors['Chinese'])\n",
    "        mydict['Other'].extend(pat_factors['Other'])\n",
    "        mydict['Age'].extend(pat_factors['Age'])\n",
    "        mydict['BMI'].extend(pat_factors['BMI'])\n",
    "        mydict['Townsend'].extend(pat_factors['Townsend'])\n",
    "        mydict['SBP'].extend(pat_factors['SBP'])\n",
    "        mydict['CholHDL_ratio'].extend(pat_factors['CholHDL_ratio'])\n",
    "        mydict['Family_CHD'].extend(pat_factors['Family_CHD'])\n",
    "        mydict['Current_smoker'].extend(pat_factors['Current_smoker'])\n",
    "        mydict['Treated_HTN'].extend(pat_factors['Treated_HTN'])\n",
    "        mydict['DM'].extend(pat_factors['DM'])\n",
    "        mydict['RA'].extend(pat_factors['RA'])\n",
    "        mydict['AF'].extend(pat_factors['AF'])\n",
    "        mydict['Renal_disease'].extend(pat_factors['Renal_disease'])\n",
    "\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(mydict)\n",
    "\n",
    "    multivariate_metrics_df = get_metrics_recal_methods(df, percent_type_2_diabetes, recalthreshold)\n",
    "    \n",
    "    \n",
    "    ########################################### Bayesian Testing #######################################\n",
    "    # bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (intercept.mean(), intercept.std()), \n",
    "    #                                             \"White\": (coefs['White'], 2), \n",
    "    #                                             \"Indian\": (coefs['Indian'], 2),\n",
    "    #                                             \"Pakistani\": (coefs['Pakistani'], 2),\n",
    "    #                                             \"Bangladeshi\": (coefs['Bangladeshi'], 2),\n",
    "    #                                             \"Other_Asian\": (coefs['Other_Asian'], 2),\n",
    "    #                                             \"Black_Caribbean\": (coefs['Black_Caribbean'], 2),\n",
    "    #                                             \"Black_African\": (coefs['Black_African'], 2),\n",
    "    #                                             \"Chinese\": (coefs['Chinese'], 2),\n",
    "    #                                             \"Other\": (coefs['Other'], 2),\n",
    "    #                                             \"Age\": (coefs['Age'], 2),\n",
    "    #                                             \"BMI\": (coefs['BMI'], 2),\n",
    "    #                                             \"Townsend\": (coefs['Townsend'], 2),\n",
    "    #                                             \"SBP\": (coefs['SBP'], 2),\n",
    "    #                                             \"CholHDL_ratio\": (coefs['CholHDL_ratio'], 2),\n",
    "    #                                             \"Family_CHD\": (coefs['Family_CHD'], 2),\n",
    "    #                                             \"Current_smoker\": (coefs['Current_smoker'], 2),\n",
    "    #                                             \"Treated_HTN\": (coefs['Treated_HTN'], 2),\n",
    "    #                                             \"DM\": (coefs['DM'], 2),\n",
    "    #                                             \"RA\": (coefs['RA'], 2),\n",
    "    #                                             \"AF\": (coefs['AF'], 2),\n",
    "    #                                             \"Renal_disease\": (coefs['Renal_disease'], 2)}, \n",
    "    #                                             cores=4, verbose=False,\n",
    "    #                                             model_formula=\"outcome ~ White + Indian + Pakistani + Bangladeshi + Other_Asian + Black_Caribbean + Black_African + Chinese + Other + Age + BMI + Townsend + SBP + CholHDL_ratio + Family_CHD + Current_smoker + Treated_HTN + DM + RA + AF + Renal_disease + Age*BMI + Age*Townsend + Age*SBP + Age*Family_CHD + Age*Current_smoker + Age*Treated_HTN + Age*DM + Age*AF\")\n",
    "    # bay_model.trigger = BayesianRefitTrigger(model=bay_model, input_data=df, refitFrequency=1)\n",
    "    # mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month')\n",
    "    # mytest.addLogHook(Accuracy(model))\n",
    "    # mytest.addLogHook(AUROC(model))\n",
    "    # mytest.addLogHook(Precision(model))\n",
    "    # mytest.run()\n",
    "    # log = mytest.getLog()\n",
    "\n",
    "    # bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'impact_or_prev': list([str(percent_type_2_diabetes)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "    \n",
    "    ########################################### Save Metrics #######################################\n",
    "\n",
    "    # concatenate all the dataframes into one\n",
    "    #multivariate_metrics_df = pd.concat([multivariate_metrics_df, bayes_metrics], ignore_index=True)\n",
    "    multivariate_metrics_df[\"Data_Type\"] = \"Multivariate Simulation\"\n",
    "    \n",
    "    multivariate_metrics_df.to_csv('performance_metrics.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>impact_or_prev</th>\n",
       "      <th>Method</th>\n",
       "      <th>Data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.805337</td>\n",
       "      <td>0.644330</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>0.805645</td>\n",
       "      <td>0.824631</td>\n",
       "      <td>0.691099</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>0.817742</td>\n",
       "      <td>0.821260</td>\n",
       "      <td>0.679348</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.831604</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>0.800806</td>\n",
       "      <td>0.795896</td>\n",
       "      <td>0.663415</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>Regular Testing</td>\n",
       "      <td>COVID Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7045</th>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.657733</td>\n",
       "      <td>0.455128</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>Multivariate Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0.725269</td>\n",
       "      <td>0.676016</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>Multivariate Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7047</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>0.709444</td>\n",
       "      <td>0.687169</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>Multivariate Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>0.731720</td>\n",
       "      <td>0.723049</td>\n",
       "      <td>0.670520</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>Multivariate Simulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>0.722778</td>\n",
       "      <td>0.669816</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>SPC7</td>\n",
       "      <td>Multivariate Simulation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7050 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time  Accuracy     AUROC  Precision  impact_or_prev  \\\n",
       "0     2019-07-01  0.804167  0.805337   0.644330          0.1000   \n",
       "1     2019-08-01  0.805645  0.824631   0.691099          0.1000   \n",
       "2     2019-09-01  0.817742  0.821260   0.679348          0.1000   \n",
       "3     2019-10-01  0.816667  0.831604   0.737500          0.1000   \n",
       "4     2019-11-01  0.800806  0.795896   0.663415          0.1000   \n",
       "...          ...       ...       ...        ...             ...   \n",
       "7045  2021-08-01  0.705376  0.657733   0.455128          0.0349   \n",
       "7046  2021-09-01  0.725269  0.676016   0.588235          0.0349   \n",
       "7047  2021-10-01  0.709444  0.687169   0.623377          0.0349   \n",
       "7048  2021-11-01  0.731720  0.723049   0.670520          0.0349   \n",
       "7049  2021-12-01  0.722778  0.669816   0.600000          0.0349   \n",
       "\n",
       "               Method                Data_type  \n",
       "0     Regular Testing         COVID Simulation  \n",
       "1     Regular Testing         COVID Simulation  \n",
       "2     Regular Testing         COVID Simulation  \n",
       "3     Regular Testing         COVID Simulation  \n",
       "4     Regular Testing         COVID Simulation  \n",
       "...               ...                      ...  \n",
       "7045             SPC7  Multivariate Simulation  \n",
       "7046             SPC7  Multivariate Simulation  \n",
       "7047             SPC7  Multivariate Simulation  \n",
       "7048             SPC7  Multivariate Simulation  \n",
       "7049             SPC7  Multivariate Simulation  \n",
       "\n",
       "[7050 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv\n",
    "metrics_df = pd.read_csv('performance_metrics.csv')\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
