{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9f4e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTENSOR_FLAGS=exception_verbosity=high,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from PREDICT import PREDICT\n",
    "from PREDICT.Models import *\n",
    "from PREDICT.Metrics import *\n",
    "from PREDICT.Triggers import *\n",
    "from PREDICT.Plots import *\n",
    "from Comparison.Detect_Functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import bambi as bmb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%env PYTENSOR_FLAGS=exception_verbosity=high,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285599d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recalthreshold = 0.77 # Paper has AUROC of 0.81, with lower CI at 0.77 \n",
    "\n",
    "prev_increases = np.arange(1.0001, 1.003, 0.0002).tolist()\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\": 0, \"SPC7\": 0, \"Bayesian\": 0})\n",
    "bayes_dict = {\"BayesianCoefficients\":{}}\n",
    "\n",
    "# mean and standard deviation for each predictor\n",
    "# variable at the last visit is used\n",
    "mean_age, std_age = 62.9, 7.5\n",
    "mean_bmi, std_bmi = 26.6, 4.4\n",
    "mean_hip_circ, std_hip_circ = 101.6, 8.8\n",
    "perc_male, mean_height, std_height = 0.478, 169, 9.2\n",
    "mean_waist_circ, std_waist_circ = 88.7, 12.7\n",
    "mean_weight, std_weight = 76.2, 15.2\n",
    "mean_time_between_visits, std_time_between_visits = 7.3, 2.3\n",
    "\n",
    "mean_waist_hips_ratio = mean_waist_circ / mean_hip_circ\n",
    "std_waist_hips_ratio = mean_waist_hips_ratio * np.sqrt(\n",
    "    (std_waist_circ / mean_waist_circ) ** 2 + (std_hip_circ / mean_hip_circ) ** 2)\n",
    "\n",
    "# coefficients from non-laboratory logistic regression model\n",
    "age_at_lv_coef = 0.16 # lv = last visit\n",
    "bmi_coef = 0.68\n",
    "hip_circ_coef = -0.05\n",
    "sex_coef = -0.14\n",
    "height_coef = -0.15\n",
    "waist_circ_coef = 0.31\n",
    "waist_hips_ratio_coef = 0.54\n",
    "weight_coef = 0.03\n",
    "time_between_visits_coef = 0.38\n",
    "bias_coef = -0.74\n",
    "\n",
    "dm_prev = 0.07  # Initial diabetes prevalence = 7%\n",
    "startDate = pd.to_datetime('01-06-2019', dayfirst=True) # 01-06-2019\n",
    "endDate = pd.to_datetime('31-12-2021', dayfirst=True) # 31-12-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5729119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain on year of fake data with no change in prevalence\n",
    "num_patients = 60\n",
    "numdays = 365\n",
    "\n",
    "mydict = {\n",
    "    'date': list(),\n",
    "    'outcome': list(),\n",
    "    'prediction': list(),\n",
    "    'age': list(),\n",
    "    'bmi':list(),\n",
    "    'hip_circ': list(),\n",
    "    'sex': list(),\n",
    "    'height': list(),\n",
    "    'waist_circ': list(),\n",
    "    'waist_hips_ratio': list(),\n",
    "    'weight': list(),\n",
    "    'time_between_visits': list()\n",
    "}\n",
    "\n",
    "for i in range(numdays):\n",
    "    curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "    age = np.random.normal(mean_age, std_age, num_patients)\n",
    "    # min max normalisation\n",
    "    age = (age - np.min(age)) / (np.max(age) - np.min(age))  # Normalize age to [0, 1]\n",
    "\n",
    "    bmi = np.random.normal(mean_bmi, std_bmi, num_patients) \n",
    "    bmi = (bmi - np.min(bmi)) / (np.max(bmi) - np.min(bmi))  # Normalize BMI to [0, 1]\n",
    "\n",
    "    hip_circ = np.random.normal(mean_hip_circ, std_hip_circ, num_patients)\n",
    "    hip_circ = (hip_circ - np.min(hip_circ)) / (np.max(hip_circ) - np.min(hip_circ))\n",
    "\n",
    "    height = np.random.normal(mean_height, std_height, num_patients)\n",
    "    height = (height - np.min(height)) / (np.max(height) - np.min(height))  # Normalize height to [0, 1]\n",
    "\n",
    "    waist_circ = np.random.normal(mean_waist_circ, std_waist_circ, num_patients)\n",
    "    waist_circ = (waist_circ - np.min(waist_circ)) / (np.max(waist_circ) - np.min(waist_circ))  # Normalize waist circumference to [0, 1]\n",
    "\n",
    "    waist_hips_ratio = np.random.normal(mean_waist_hips_ratio, std_waist_hips_ratio, num_patients)\n",
    "    waist_hips_ratio = (waist_hips_ratio - np.min(waist_hips_ratio)) / (np.max(waist_hips_ratio) - np.min(waist_hips_ratio))  # Normalize waist-hips ratio to [0, 1]\n",
    "\n",
    "    weight = np.random.normal(mean_weight, std_weight, num_patients)\n",
    "    weight = (weight - np.min(weight)) / (np.max(weight) - np.min(weight))  # Normalize weight to [0, 1]\n",
    "\n",
    "    time_between_visits = np.random.normal(mean_time_between_visits, std_time_between_visits, num_patients)\n",
    "    time_between_visits = (time_between_visits - np.min(time_between_visits)) / (np.max(time_between_visits) - np.min(time_between_visits))  # Normalize time between visits to [0, 1]\n",
    "\n",
    "    sex = np.random.binomial(1, perc_male, num_patients)\n",
    "\n",
    "    epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "\n",
    "\n",
    "    # Calculate baseline log-odds\n",
    "    lp = bias_coef + age_at_lv_coef * age + bmi_coef * bmi + hip_circ_coef * hip_circ + sex_coef * (sex - perc_male) + height_coef * height + waist_circ_coef * waist_circ  + waist_hips_ratio_coef * waist_hips_ratio + weight_coef * weight  + time_between_visits_coef * time_between_visits\n",
    "    curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "    mod_prob = 1/(1+np.exp(-(lp + epsilon)))\n",
    "    # intercept changed, but model weights constant\n",
    "    # diabetes increased as outcome, but not explained by data\n",
    "    curoutcomes = np.random.binomial(1, mod_prob)           \n",
    "    # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "    mydict['date'].extend([curday] * num_patients)\n",
    "    mydict['outcome'].extend(curoutcomes)\n",
    "    mydict['prediction'].extend(curpredictions)\n",
    "    mydict['age'].extend(age)\n",
    "    mydict['bmi'].extend(bmi)\n",
    "    mydict['hip_circ'].extend(hip_circ)\n",
    "    mydict['sex'].extend(sex)\n",
    "    mydict['height'].extend(height)\n",
    "    mydict['waist_circ'].extend(waist_circ)\n",
    "    mydict['waist_hips_ratio'].extend(waist_hips_ratio)\n",
    "    mydict['weight'].extend(weight)\n",
    "    mydict['time_between_visits'].extend(time_between_visits)\n",
    "\n",
    "pretrain_data = pd.DataFrame(mydict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f40dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c604cc5ce84af0a2f4a65f3a9189ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 15_000 draw iterations (8_000 + 60_000 draws total) took 755 seconds.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hdi_3%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hdi_97%",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mcse_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mcse_sd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ess_bulk",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ess_tail",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r_hat",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cb096db8-7b2e-43b5-82fc-d407c46256d8",
       "rows": [
        [
         "Intercept",
         "-0.605",
         "0.089",
         "-0.771",
         "-0.436",
         "0.0",
         "0.0",
         "128176.0",
         "45118.0",
         "1.0"
        ],
        [
         "age",
         "0.167",
         "0.061",
         "0.05",
         "0.28",
         "0.0",
         "0.0",
         "128434.0",
         "44428.0",
         "1.0"
        ],
        [
         "bmi",
         "0.715",
         "0.061",
         "0.6",
         "0.831",
         "0.0",
         "0.0",
         "126019.0",
         "42061.0",
         "1.0"
        ],
        [
         "height",
         "-0.139",
         "0.061",
         "-0.254",
         "-0.025",
         "0.0",
         "0.0",
         "123775.0",
         "44479.0",
         "1.0"
        ],
        [
         "hip_circ",
         "-0.06",
         "0.061",
         "-0.173",
         "0.057",
         "0.0",
         "0.0",
         "122714.0",
         "45941.0",
         "1.0"
        ],
        [
         "sex",
         "-0.188",
         "0.027",
         "-0.239",
         "-0.136",
         "0.0",
         "0.0",
         "126204.0",
         "44669.0",
         "1.0"
        ],
        [
         "time_between_visits",
         "0.369",
         "0.061",
         "0.254",
         "0.484",
         "0.0",
         "0.0",
         "125252.0",
         "43394.0",
         "1.0"
        ],
        [
         "waist_circ",
         "0.256",
         "0.061",
         "0.144",
         "0.37",
         "0.0",
         "0.0",
         "128463.0",
         "43294.0",
         "1.0"
        ],
        [
         "waist_hips_ratio",
         "0.541",
         "0.061",
         "0.43",
         "0.66",
         "0.0",
         "0.0",
         "131707.0",
         "44373.0",
         "1.0"
        ],
        [
         "weight",
         "-0.043",
         "0.061",
         "-0.155",
         "0.074",
         "0.0",
         "0.0",
         "131356.0",
         "44883.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.605</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128176.0</td>\n",
       "      <td>45118.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128434.0</td>\n",
       "      <td>44428.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>0.715</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126019.0</td>\n",
       "      <td>42061.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>-0.139</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123775.0</td>\n",
       "      <td>44479.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hip_circ</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122714.0</td>\n",
       "      <td>45941.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.239</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126204.0</td>\n",
       "      <td>44669.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_between_visits</th>\n",
       "      <td>0.369</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125252.0</td>\n",
       "      <td>43394.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waist_circ</th>\n",
       "      <td>0.256</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128463.0</td>\n",
       "      <td>43294.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waist_hips_ratio</th>\n",
       "      <td>0.541</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131707.0</td>\n",
       "      <td>44373.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131356.0</td>\n",
       "      <td>44883.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  \\\n",
       "Intercept           -0.605  0.089  -0.771   -0.436        0.0      0.0   \n",
       "age                  0.167  0.061   0.050    0.280        0.0      0.0   \n",
       "bmi                  0.715  0.061   0.600    0.831        0.0      0.0   \n",
       "height              -0.139  0.061  -0.254   -0.025        0.0      0.0   \n",
       "hip_circ            -0.060  0.061  -0.173    0.057        0.0      0.0   \n",
       "sex                 -0.188  0.027  -0.239   -0.136        0.0      0.0   \n",
       "time_between_visits  0.369  0.061   0.254    0.484        0.0      0.0   \n",
       "waist_circ           0.256  0.061   0.144    0.370        0.0      0.0   \n",
       "waist_hips_ratio     0.541  0.061   0.430    0.660        0.0      0.0   \n",
       "weight              -0.043  0.061  -0.155    0.074        0.0      0.0   \n",
       "\n",
       "                     ess_bulk  ess_tail  r_hat  \n",
       "Intercept            128176.0   45118.0    1.0  \n",
       "age                  128434.0   44428.0    1.0  \n",
       "bmi                  126019.0   42061.0    1.0  \n",
       "height               123775.0   44479.0    1.0  \n",
       "hip_circ             122714.0   45941.0    1.0  \n",
       "sex                  126204.0   44669.0    1.0  \n",
       "time_between_visits  125252.0   43394.0    1.0  \n",
       "waist_circ           128463.0   43294.0    1.0  \n",
       "waist_hips_ratio     131707.0   44373.0    1.0  \n",
       "weight               131356.0   44883.0    1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefit_model = bmb.Model(\"outcome ~ age + bmi + hip_circ + sex + height + waist_circ + waist_hips_ratio + weight + time_between_visits\", pretrain_data, family=\"bernoulli\")\n",
    "prefit_fitted = prefit_model.fit(\n",
    "    tune=2000, draws=15000, cores=2, chains=4, target_accept=0.9)\n",
    "\n",
    "az.summary(prefit_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c3c31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_priors = {\n",
    "    \"Intercept\": (-0.605, 0.089), \n",
    "    \"age\": (0.167, 0.061), \n",
    "    \"bmi\": (0.715, 0.061), \n",
    "    \"hip_circ\": (-0.06, 0.061),\n",
    "    \"sex\": (-0.188, 0.027), \n",
    "    \"height\":(-0.139, 0.061), \n",
    "    \"waist_circ\":(0.256, 0.061),\n",
    "    \"waist_hips_ratio\":(0.541, 0.061), \n",
    "    \"weight\":(-0.043, 0.061), \n",
    "    \"time_between_visits\":(0.369, 0.061)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdc3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain OE: 0.994173383632472 with std: 0.006155547317111696 and 95% CI: 0.9827990690664817 - 1.005972261145391\n"
     ]
    }
   ],
   "source": [
    "# Get bootstrap OE with CI\n",
    "preds = -0.605 + pretrain_data.age*0.167 + pretrain_data.bmi*0.715 + pretrain_data.hip_circ*(-0.06) +\\\n",
    "        pretrain_data.sex*(-0.188) + pretrain_data.height*(-0.139) + pretrain_data.waist_circ*0.256 +\\\n",
    "        pretrain_data.waist_hips_ratio*0.541 + pretrain_data.weight*(-0.043) + pretrain_data.time_between_visits*0.369\n",
    "preds = 1 / (1 + np.exp(-preds))\n",
    "outcome = pretrain_data['outcome'].values\n",
    "for i in range(1000):\n",
    "    boot_indices = np.random.choice(range(len(outcome)), size=len(outcome), replace=True)\n",
    "    boot_outcome = outcome[boot_indices]\n",
    "    boot_preds = preds[boot_indices]\n",
    "    boot_oe = boot_outcome.mean() / boot_preds.mean()\n",
    "    if i == 0:\n",
    "        oe_values = [boot_oe]\n",
    "    else:\n",
    "        oe_values.append(boot_oe)\n",
    "        \n",
    "print(f\"Pretrain OE: {np.mean(oe_values)} with std: {np.std(oe_values)} and 95% CI: {np.percentile(oe_values, 2.5)} - {np.percentile(oe_values, 97.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22535afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsloc = \"./Results/simulation/outcome_prevalence\"\n",
    "os.makedirs(resultsloc, exist_ok=True)\n",
    "if not os.path.exists(os.path.join(resultsloc, 'performance_metrics.csv')):\n",
    "    header = pd.DataFrame(columns=['Time', 'Accuracy', 'AUROC', 'Precision', 'CalibrationSlope', 'CITL',\n",
    "    'OE', 'AUPRC', 'F1Score', 'impact_or_prev', 'Method', 'Data_Type'])\n",
    "    header.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OE Threshold of 0.9757067416811369 - 1.012640025583807 for impact 0.07044941412093295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modeling the probability that outcome==1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model formula is set to:  outcome ~ age + bmi + hip_circ + sex + height + waist_circ + waist_hips_ratio + weight + time_between_visits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f03984486a544c2b0797b2c110b8116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 269 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb45c43dab44f32a23145e3a7ebac50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 238 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74567f7c73ad4f13bc3694cf3739e99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 252 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515ec7ac17604aa09a68288937bef0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 217 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85e4697144d43d781535b00f6b950ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 140 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729ce29495074736898e7e92b42e6502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 291 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b994b6e46ed4135b3c99c67fa58be0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 240 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9950906750743caaba443a7b1e8d76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 261 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00ad6ad5b034f8da22973b5cd838b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 241 seconds.\n",
      "Modeling the probability that outcome==1\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 2 jobs)\n",
      "NUTS: [Intercept, age, bmi, hip_circ, sex, height, waist_circ, waist_hips_ratio, weight, time_between_visits]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95362a7869741d5ae7b51aeda12440a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 265 seconds.\n"
     ]
    }
   ],
   "source": [
    "for prev_increase in prev_increases:\n",
    "    regular_ttd = []\n",
    "    static_ttd = []\n",
    "    spc_ttd3 = []\n",
    "    spc_ttd5 = []\n",
    "    spc_ttd7 = []\n",
    "    bayesian_ttd = []\n",
    "    mydict = {\n",
    "            'date': list(),\n",
    "            'outcome': list(),\n",
    "            'prediction': list(),\n",
    "            'age': list(),\n",
    "            'bmi':list(),\n",
    "            'hip_circ': list(),\n",
    "            'sex': list(),\n",
    "            'height': list(),\n",
    "            'waist_circ': list(),\n",
    "            'waist_hips_ratio': list(),\n",
    "            'weight': list(),\n",
    "            'time_between_visits': list()\n",
    "        }\n",
    "\n",
    "    num_patients = 60\n",
    "    numdays = (endDate - startDate).days\n",
    "    \n",
    "    for i in range(numdays):\n",
    "        curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "        age = np.random.normal(mean_age, std_age, num_patients)\n",
    "        # min max normalisation\n",
    "        age = (age - np.min(age)) / (np.max(age) - np.min(age))  # Normalize age to [0, 1]\n",
    "\n",
    "        bmi = np.random.normal(mean_bmi, std_bmi, num_patients) \n",
    "        bmi = (bmi - np.min(bmi)) / (np.max(bmi) - np.min(bmi))  # Normalize BMI to [0, 1]\n",
    "\n",
    "        hip_circ = np.random.normal(mean_hip_circ, std_hip_circ, num_patients)\n",
    "        hip_circ = (hip_circ - np.min(hip_circ)) / (np.max(hip_circ) - np.min(hip_circ))\n",
    "\n",
    "        height = np.random.normal(mean_height, std_height, num_patients)\n",
    "        height = (height - np.min(height)) / (np.max(height) - np.min(height))  # Normalize height to [0, 1]\n",
    "\n",
    "        waist_circ = np.random.normal(mean_waist_circ, std_waist_circ, num_patients)\n",
    "        waist_circ = (waist_circ - np.min(waist_circ)) / (np.max(waist_circ) - np.min(waist_circ))  # Normalize waist circumference to [0, 1]\n",
    "\n",
    "        waist_hips_ratio = np.random.normal(mean_waist_hips_ratio, std_waist_hips_ratio, num_patients)\n",
    "        waist_hips_ratio = (waist_hips_ratio - np.min(waist_hips_ratio)) / (np.max(waist_hips_ratio) - np.min(waist_hips_ratio))  # Normalize waist-hips ratio to [0, 1]\n",
    "\n",
    "        weight = np.random.normal(mean_weight, std_weight, num_patients)\n",
    "        weight = (weight - np.min(weight)) / (np.max(weight) - np.min(weight))  # Normalize weight to [0, 1]\n",
    "\n",
    "        time_between_visits = np.random.normal(mean_time_between_visits, std_time_between_visits, num_patients)\n",
    "        time_between_visits = (time_between_visits - np.min(time_between_visits)) / (np.max(time_between_visits) - np.min(time_between_visits))  # Normalize time between visits to [0, 1]\n",
    "\n",
    "        sex = np.random.binomial(1, perc_male, num_patients)\n",
    "\n",
    "        epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "        \n",
    "\n",
    "        # Calculate baseline log-odds\n",
    "        lp = bias_coef + age_at_lv_coef * age + bmi_coef * bmi + hip_circ_coef * hip_circ + sex_coef * (sex - perc_male) + height_coef * height + waist_circ_coef * waist_circ  + waist_hips_ratio_coef * waist_hips_ratio + weight_coef * weight  + time_between_visits_coef * time_between_visits\n",
    "        curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "        # Generate outcomes to simulate diabetes rates increasing over time\n",
    "        if i % 30 == 0:\n",
    "            dm_prev *= prev_increase # this increases the probability by x% each month\n",
    "\n",
    "        mod_prob = 1/(1+np.exp(-(lp + dm_prev  + epsilon)))\n",
    "        # intercept changed, but model weights constant\n",
    "        # diabetes increased as outcome, but not explained by data\n",
    "        curoutcomes = np.random.binomial(1, mod_prob)           \n",
    "        \n",
    "\n",
    "        # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "        mydict['date'].extend([curday] * num_patients)\n",
    "        mydict['outcome'].extend(curoutcomes)\n",
    "        mydict['prediction'].extend(curpredictions)\n",
    "        mydict['age'].extend(age)\n",
    "        mydict['bmi'].extend(bmi)\n",
    "        mydict['hip_circ'].extend(hip_circ)\n",
    "        mydict['sex'].extend(sex)\n",
    "        mydict['height'].extend(height)\n",
    "        mydict['waist_circ'].extend(waist_circ)\n",
    "        mydict['waist_hips_ratio'].extend(waist_hips_ratio)\n",
    "        mydict['weight'].extend(weight)\n",
    "        mydict['time_between_visits'].extend(time_between_visits)\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(mydict)  \n",
    "    ########################################### Baseline Testing #######################################\n",
    "    model = RecalibratePredictions()\n",
    "    model.trigger = TimeframeTrigger(model=model, updateTimestep=900, dataStart=df['date'].min(), dataEnd=df['date'].max())\n",
    "    mytest = PREDICT(data=df, model=model, startDate='min', endDate='max', timestep='month')\n",
    "    mytest.addLogHook(Accuracy(model))\n",
    "    mytest.addLogHook(AUROC(model))\n",
    "    mytest.addLogHook(Precision(model))\n",
    "    mytest.addLogHook(CalibrationSlope(model))\n",
    "    mytest.addLogHook(CITL(model))\n",
    "    mytest.addLogHook(OE(model))\n",
    "    mytest.addLogHook(AUPRC(model))\n",
    "    mytest.run()\n",
    "    log = mytest.getLog()\n",
    "\n",
    "    baseline_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'impact_or_prev': list([str(prev_increase)] * len(log[\"Accuracy\"])), 'Method':list(['Baseline'] * len(log[\"Accuracy\"]))})\n",
    "    ########################################### Save Metrics #######################################\n",
    "    baseline_metrics[\"Data_Type\"] = \"Outcome Prevalence Simulation\"\n",
    "\n",
    "    baseline_metrics.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), mode='a', header=False, index=False)\n",
    "    # Get OE thresholds for static recal from original model\n",
    "    recalthreshold_lower = 0.994173383632472 - 3*0.006155547317111696\n",
    "    recalthreshold_upper = 0.994173383632472 + 3*0.006155547317111696\n",
    "    print(f\"Using OE Threshold of {recalthreshold_lower} - {recalthreshold_upper} for impact {dm_prev}\")\n",
    "    \n",
    "    ########################################### Recalibration Methods Testing #######################################      \n",
    "    out_prev_metrics_df = get_metrics_recal_methods(df, dm_prev, recalthreshold_lower, recalthreshold_upper, model_name='Outcome_prev_datasim')\n",
    "    undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7 = run_recalibration_tests(df, startDate, undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, recalthreshold_lower, recalthreshold_upper)\n",
    "    \n",
    "    \n",
    "    ########################################### Bayesian Testing #######################################\n",
    "    bayes_coef_ci = {\n",
    "        key: (bayesian_priors[key][0] - 3 * bayesian_priors[key][1], bayesian_priors[key][0] + 3 * bayesian_priors[key][1])\n",
    "        for key in bayesian_priors\n",
    "    }\n",
    "    \n",
    "    bay_model = BayesianModel(input_data=df, \n",
    "                            model_formula = \"outcome ~ age + bmi + hip_circ + sex + height + waist_circ + waist_hips_ratio + weight + time_between_visits\",\n",
    "                            priors=bayesian_priors, verbose=False, draws=10000, tune=2000, chains=4, cores=2)\n",
    "    bay_model.trigger = AlwaysTrigger(model=bay_model)\n",
    "    mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month')\n",
    "    mytest.addLogHook(Accuracy(bay_model))\n",
    "    mytest.addLogHook(AUROC(bay_model))\n",
    "    mytest.addLogHook(Precision(bay_model))\n",
    "    mytest.addLogHook(CalibrationSlope(bay_model))\n",
    "    mytest.addLogHook(CITL(bay_model))\n",
    "    mytest.addLogHook(OE(bay_model))\n",
    "    mytest.addLogHook(AUPRC(bay_model))\n",
    "    mytest.addLogHook(TrackBayesianCoefs(bay_model))\n",
    "    mytest.run()\n",
    "    log = mytest.getLog()\n",
    "\n",
    "    if \"BayesianCoefficients\" in log:\n",
    "        bayes_dict[\"BayesianCoefficients\"].update(log[\"BayesianCoefficients\"])\n",
    "    \n",
    "    ttd = find_bayes_coef_change(bayes_dict[\"BayesianCoefficients\"], detectDate=startDate, undetected=undetected, threshold=0.1)\n",
    "    bayesian_ttd.append(ttd)\n",
    "\n",
    "    bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'impact_or_prev': list([str(dm_prev)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "    \n",
    "    ########################################### Save Metrics #######################################\n",
    "\n",
    "    # concatenate all the dataframes into one\n",
    "    out_prev_metrics_df = pd.concat([out_prev_metrics_df, bayes_metrics], ignore_index=True)\n",
    "    out_prev_metrics_df[\"Data_Type\"] = \"Outcome Prevalence Simulation\"\n",
    "\n",
    "    out_prev_metrics_df.to_csv(os.path.join(resultsloc, 'performance_metrics.csv'), mode='a', header=False, index=False)\n",
    "\n",
    "    update_ttd_table(regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, prev_increase, os.path.join(resultsloc, 'output_prev_ttd_tbl.csv'))\n",
    "    \n",
    "    # Generate plots\n",
    "    plot_incidence_over_time(df, None, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, 'outcome_prev'+str(prev_increase), fileloc=resultsloc)\n",
    "    BayesianCoefsPlot(bayes_dict, 'outcome_prev'+str(prev_increase))\n",
    "\n",
    "plot_time_to_detect('output_prev_ttd_tbl.csv', 'outcome_prev')\n",
    "    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceffe1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
