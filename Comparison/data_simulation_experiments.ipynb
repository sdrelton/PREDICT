{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from PREDICT import PREDICT\n",
    "from PREDICT.Models import *\n",
    "from PREDICT.Metrics import *\n",
    "from PREDICT.Triggers import *\n",
    "from PREDICT.Plots import *\n",
    "from Comparison.Detect_Functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%env PYTENSOR_FLAGS=exception_verbosity=high#,optimizer=fast_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = pd.to_datetime('01-06-2019', dayfirst=True) # 01-06-2019\n",
    "endDate = pd.to_datetime('31-12-2021', dayfirst=True) # 31-12-2021\n",
    "num_patients = 40 # number of patients per each timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b49e0",
   "metadata": {},
   "source": [
    "## Fast Change - COVID Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09973707",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalthreshold = 0.86 # Paper has AUROC of 0.91, with lower CI at 0.86\n",
    "\n",
    "custom_impacts = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 2.0, 2.5, 3.0] #\n",
    "switchDateStrings = ['01-04-2020'] # Keep this as just one switchDate as other methods only look at one startDate/deployment date\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\":0, \"SPC7\":0, \"Bayesian\": 0})\n",
    "\n",
    "hr_age = 0.5\n",
    "hr_ldh = 9.8\n",
    "hr_comorbidity = 3.9\n",
    "\n",
    "log_age = np.log(hr_age)\n",
    "log_ldh = np.log(hr_ldh)\n",
    "log_comorbidity = np.log(hr_comorbidity)\n",
    "\n",
    "bayes_dict = {\"BayesianCoefficients\":{}}\n",
    "\n",
    "for switchDateidx, switchDateString in enumerate(switchDateStrings):\n",
    "    for custom_impact in custom_impacts:\n",
    "        regular_ttd = []\n",
    "        static_ttd = []\n",
    "        spc_ttd3 = []\n",
    "        spc_ttd5 = []\n",
    "        spc_ttd7 = []\n",
    "        bayesian_ttd = []\n",
    "        mydict = {\n",
    "                'date': list(),\n",
    "                'outcome': list(),\n",
    "                'prediction': list(),\n",
    "                'age': list(),\n",
    "                'sex': list(),\n",
    "                'comorbidity': list(),\n",
    "                'ldh_high': list()\n",
    "            }\n",
    "\n",
    "        # Define date range and COVID shock periods\n",
    "        switchDate = pd.to_datetime(switchDateString, dayfirst=True)  # COVID starts spreading\n",
    "        switchDate2 = pd.to_datetime('01-06-2020', dayfirst=True)  # Peak of the pandemic\n",
    "        recoveryDate = pd.to_datetime('01-06-2021', dayfirst=True)  # Start of recovery phase\n",
    "        numdays = (endDate - startDate).days\n",
    "        switchDays = (switchDate - startDate).days\n",
    "        switch2Days = (switchDate2 - startDate).days\n",
    "        recoveryDays = (recoveryDate - startDate).days\n",
    "\n",
    "        for i in range(numdays):\n",
    "            curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "            age = (np.random.normal(44, 16.3, num_patients) - 44) / 16.3  # Mean age 44 years, std 16.3\n",
    "            sex = np.random.binomial(1, 0.562, num_patients) # 56.2% are male\n",
    "            comorbidity = np.random.binomial(1, 0.3, num_patients)  # 30% have comorbidities\n",
    "            ldh_high = np.random.binomial(1, 0.15, num_patients)  # 15% have LDH >500 U/L\n",
    "            epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "\n",
    "            # Calculate baseline log-odds\n",
    "            # sex influence 1.2 due to not being provided in the paper\n",
    "            lp = -1.5 + log_age * age +  log_ldh * ldh_high + log_comorbidity * comorbidity + 1.2 * (sex - 0.562) + epsilon\n",
    "            curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "            # Simulate COVID effects\n",
    "            if switchDays <= i < switch2Days:\n",
    "                lp += custom_impact  # Initial impact of COVID\n",
    "            elif switch2Days <= i < recoveryDays:\n",
    "                lp += custom_impact + 0.5  # Peak of the pandemic\n",
    "            elif i >= recoveryDays:\n",
    "                lp -= 1.0  # Recovery periodâ€”improved health outcomes\n",
    "\n",
    "            # Generate outcomes\n",
    "            curoutcomes = np.random.binomial(1, 1 / (1 + np.exp(-lp)))  # Simulate COVID events\n",
    "\n",
    "            # Append to dictionary\n",
    "            mydict['date'].extend([curday] * num_patients)\n",
    "            mydict['outcome'].extend(curoutcomes)\n",
    "            mydict['prediction'].extend(curpredictions)\n",
    "            mydict['age'].extend(age)\n",
    "            mydict['sex'].extend(sex)\n",
    "            mydict['comorbidity'].extend(comorbidity)\n",
    "            mydict['ldh_high'].extend(ldh_high)\n",
    "\n",
    "        df = pd.DataFrame(mydict)\n",
    "\n",
    "        covid_metrics_df = get_metrics_recal_methods(df, custom_impact, recalthreshold, model_name='COVID_datasim')\n",
    "        undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7 = run_recalibration_tests(df, switchDate, undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, recalthreshold)\n",
    "\n",
    "        ########################################### Bayesian Testing #######################################\n",
    "        bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (-1, 0.25), \"age\": (log_age, 0.25), \"sex\": (1, 0.25), \"comorbidity\": (log_comorbidity, 0.25), \"ldh_high\": (log_ldh, 0.25)}, cores=1, verbose=False, draws=1000, tune=250, chains=4)\n",
    "        bay_model.trigger = TimeframeTrigger(model=bay_model, updateTimestep='month', dataStart=startDate, dataEnd=endDate)\n",
    "        mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month', recal_period=30, model_name='COVID_datasim')\n",
    "        mytest.addLogHook(Accuracy(bay_model))\n",
    "        mytest.addLogHook(AUROC(bay_model))\n",
    "        mytest.addLogHook(Precision(bay_model))\n",
    "        mytest.addLogHook(CalibrationSlope(bay_model))\n",
    "        mytest.addLogHook(CITL(bay_model))\n",
    "        mytest.addLogHook(OE(bay_model))\n",
    "        mytest.addLogHook(AUPRC(bay_model))\n",
    "        mytest.addLogHook(TrackBayesianCoefs(bay_model))\n",
    "        mytest.run()\n",
    "        log = mytest.getLog()\n",
    "\n",
    "        if \"BayesianCoefficients\" in log:\n",
    "            bayes_dict[\"BayesianCoefficients\"].update(log[\"BayesianCoefficients\"])\n",
    "            print(log[\"BayesianCoefficients\"])\n",
    "        \n",
    "        ttd = find_bayes_coef_change(bayes_dict[\"BayesianCoefficients\"], detectDate=switchDate, undetected=undetected, threshold=0.1)\n",
    "        print(ttd)\n",
    "        bayesian_ttd.append(ttd)\n",
    "\n",
    "        bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'impact_or_prev': list([str(custom_impact)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "        \n",
    "        ########################################### Save Metrics #######################################\n",
    "\n",
    "        # concatenate all the dataframes into one\n",
    "        covid_metrics_df = pd.concat([covid_metrics_df, bayes_metrics], ignore_index=True)\n",
    "        covid_metrics_df[\"Data_Type\"] = \"COVID Simulation\"\n",
    "\n",
    "        covid_metrics_df.to_csv('performance_metrics.csv', mode='a', header=False, index=False)\n",
    "\n",
    "        update_ttd_table(regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, custom_impact, 'covid_ttd_tbl.csv')\n",
    "\n",
    "        # these two just do the final impact value:\n",
    "        BayesianCoefsPlot(bayes_dict, f\"fast_change_impact_{custom_impact}\") \n",
    "        plot_prev_over_time(df, switchDateStrings, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, f\"fast_change_impact_{custom_impact}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b094b55",
   "metadata": {},
   "source": [
    "## Outcome Prevalence Change - Diabetes Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalthreshold = 0.77 # Paper has AUROC of 0.81, with lower CI at 0.77 \n",
    "\n",
    "prev_increases = np.arange(1.0001, 1.003, 0.0002).tolist()\n",
    "#prev_increases = np.arange(1.0001, 1.003, 0.0002).tolist()\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\": 0, \"SPC7\": 0, \"Bayesian\": 0})\n",
    "bayes_dict = {\"BayesianCoefficients\":{}}\n",
    "# coefficients from non-laboratory logistic regression model\n",
    "age_at_lv_coef = 0.16 # lv = last visit\n",
    "bmi_coef = 0.68\n",
    "hip_circ_coef = -0.05\n",
    "sex_coef = -0.14\n",
    "height_coef = -0.15\n",
    "waist_circ_coef = 0.31\n",
    "waist_hips_ratio_coef = 0.54\n",
    "weight_coef = 0.03\n",
    "time_between_visits_coef = 0.38\n",
    "bias_coef = -0.74\n",
    "\n",
    "# mean and standard deviation for each predictor\n",
    "# variable at the last visit is used\n",
    "mean_age, std_age = 62.9, 7.5\n",
    "mean_bmi, std_bmi = 26.6, 4.4\n",
    "mean_hip_circ, std_hip_circ = 101.6, 8.8\n",
    "perc_male, mean_height, std_height = 0.478, 169, 9.2\n",
    "mean_waist_circ, std_waist_circ = 88.7, 12.7\n",
    "mean_weight, std_weight = 76.2, 15.2\n",
    "mean_time_between_visits, std_time_between_visits = 7.3, 2.3\n",
    "\n",
    "mean_waist_hips_ratio = mean_waist_circ / mean_hip_circ\n",
    "std_waist_hips_ratio = mean_waist_hips_ratio * np.sqrt(\n",
    "    (std_waist_circ / mean_waist_circ) ** 2 + (std_hip_circ / mean_hip_circ) ** 2)\n",
    "\n",
    "dm_prev = 0.07  # Initial diabetes prevalence = 7%\n",
    "for prev_increase in prev_increases:\n",
    "    regular_ttd = []\n",
    "    static_ttd = []\n",
    "    spc_ttd3 = []\n",
    "    spc_ttd5 = []\n",
    "    spc_ttd7 = []\n",
    "    bayesian_ttd = []\n",
    "    mydict = {\n",
    "            'date': list(),\n",
    "            'outcome': list(),\n",
    "            'prediction': list(),\n",
    "            'age': list(),\n",
    "            'bmi':list(),\n",
    "            'hip_circ': list(),\n",
    "            'sex': list(),\n",
    "            'height': list(),\n",
    "            'waist_circ': list(),\n",
    "            'waist_hips_ratio': list(),\n",
    "            'weight': list(),\n",
    "            'time_between_visits': list()\n",
    "        }\n",
    "\n",
    "    num_patients = 60\n",
    "    numdays = (endDate - startDate).days\n",
    "    \n",
    "    for i in range(numdays):\n",
    "        curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "        age = np.random.normal(mean_age, std_age, num_patients)\n",
    "        # min max normalisation\n",
    "        age = (age - np.min(age)) / (np.max(age) - np.min(age))  # Normalize age to [0, 1]\n",
    "\n",
    "        bmi = np.random.normal(mean_bmi, std_bmi, num_patients) \n",
    "        bmi = (bmi - np.min(bmi)) / (np.max(bmi) - np.min(bmi))  # Normalize BMI to [0, 1]\n",
    "\n",
    "        hip_circ = np.random.normal(mean_hip_circ, std_hip_circ, num_patients)\n",
    "        hip_circ = (hip_circ - np.min(hip_circ)) / (np.max(hip_circ) - np.min(hip_circ))\n",
    "\n",
    "        height = np.random.normal(mean_height, std_height, num_patients)\n",
    "        height = (height - np.min(height)) / (np.max(height) - np.min(height))  # Normalize height to [0, 1]\n",
    "\n",
    "        waist_circ = np.random.normal(mean_waist_circ, std_waist_circ, num_patients)\n",
    "        waist_circ = (waist_circ - np.min(waist_circ)) / (np.max(waist_circ) - np.min(waist_circ))  # Normalize waist circumference to [0, 1]\n",
    "\n",
    "        waist_hips_ratio = np.random.normal(mean_waist_hips_ratio, std_waist_hips_ratio, num_patients)\n",
    "        waist_hips_ratio = (waist_hips_ratio - np.min(waist_hips_ratio)) / (np.max(waist_hips_ratio) - np.min(waist_hips_ratio))  # Normalize waist-hips ratio to [0, 1]\n",
    "\n",
    "        weight = np.random.normal(mean_weight, std_weight, num_patients)\n",
    "        weight = (weight - np.min(weight)) / (np.max(weight) - np.min(weight))  # Normalize weight to [0, 1]\n",
    "\n",
    "        time_between_visits = np.random.normal(mean_time_between_visits, std_time_between_visits, num_patients)\n",
    "        time_between_visits = (time_between_visits - np.min(time_between_visits)) / (np.max(time_between_visits) - np.min(time_between_visits))  # Normalize time between visits to [0, 1]\n",
    "\n",
    "        sex = np.random.binomial(1, perc_male, num_patients)\n",
    "\n",
    "        epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "        \n",
    "\n",
    "        # Calculate baseline log-odds\n",
    "        lp = bias_coef + age_at_lv_coef * age + bmi_coef * bmi + hip_circ_coef * hip_circ + sex_coef * (sex - perc_male) + height_coef * height + waist_circ_coef * waist_circ  + waist_hips_ratio_coef * waist_hips_ratio + weight_coef * weight  + time_between_visits_coef * time_between_visits + epsilon\n",
    "        \n",
    "        curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "\n",
    "        # Generate outcomes to simulate diabetes rates increasing over time\n",
    "        if i % 30 == 0:\n",
    "            dm_prev *= prev_increase # this increases the probability by x% each month\n",
    "\n",
    "        mod_prob = 1/(1+np.exp(-(lp + dm_prev)))\n",
    "        # intercept changed, but model weights constant\n",
    "        # diabetes increased as outcome, but not explained by data\n",
    "        curoutcomes = np.random.binomial(1, mod_prob)           \n",
    "        \n",
    "\n",
    "        # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "        mydict['date'].extend([curday] * num_patients)\n",
    "        mydict['outcome'].extend(curoutcomes)\n",
    "        mydict['prediction'].extend(curpredictions)\n",
    "        mydict['age'].extend(age)\n",
    "        mydict['bmi'].extend(bmi)\n",
    "        mydict['hip_circ'].extend(hip_circ)\n",
    "        mydict['sex'].extend(sex)\n",
    "        mydict['height'].extend(height)\n",
    "        mydict['waist_circ'].extend(waist_circ)\n",
    "        mydict['waist_hips_ratio'].extend(waist_hips_ratio)\n",
    "        mydict['weight'].extend(weight)\n",
    "        mydict['time_between_visits'].extend(time_between_visits)\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(mydict)  \n",
    "    out_prev_metrics_df = get_metrics_recal_methods(df, dm_prev, recalthreshold, model_name='Outcome_prev_datasim')\n",
    "    undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7 = run_recalibration_tests(df, startDate, undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, recalthreshold)\n",
    "    \n",
    "    \n",
    "    ########################################### Bayesian Testing #######################################\n",
    "    bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (bias_coef, 0.25), \"age\": (age_at_lv_coef, 0.25), \"bmi\": (bmi_coef, 0.25), \"hip_circ\": (hip_circ_coef, 0.25),\n",
    "                                                \"sex\": (sex_coef, 0.25), \"height\":(height_coef, 0.25), \"waist_circ\":(waist_circ_coef, 0.25),\n",
    "                                                \"waist_hips_ratio\":(waist_hips_ratio_coef, 0.25), \"weight\":(weight_coef, 0.25), \n",
    "                                                \"time_between_visits\":(time_between_visits_coef, 0.25)}, cores=1, verbose=False)\n",
    "    bay_model.trigger = TimeframeTrigger(model=bay_model, updateTimestep='month', dataStart=startDate, dataEnd=endDate)\n",
    "    mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month', recal_period=30, model_name='Outcome_prev_datasim')\n",
    "    mytest.addLogHook(Accuracy(bay_model))\n",
    "    mytest.addLogHook(AUROC(bay_model))\n",
    "    mytest.addLogHook(Precision(bay_model))\n",
    "    mytest.addLogHook(CalibrationSlope(bay_model))\n",
    "    mytest.addLogHook(CITL(bay_model))\n",
    "    mytest.addLogHook(OE(bay_model))\n",
    "    mytest.addLogHook(AUPRC(bay_model))\n",
    "    mytest.addLogHook(TrackBayesianCoefs(bay_model))\n",
    "    mytest.run()\n",
    "    log = mytest.getLog()\n",
    "\n",
    "    if \"BayesianCoefficients\" in log:\n",
    "        bayes_dict[\"BayesianCoefficients\"].update(log[\"BayesianCoefficients\"])\n",
    "    \n",
    "    ttd = find_bayes_coef_change(bayes_dict[\"BayesianCoefficients\"], detectDate=startDate, undetected=undetected, threshold=0.1)\n",
    "    bayesian_ttd.append(ttd)\n",
    "\n",
    "    bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'impact_or_prev': list([str(dm_prev)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "    \n",
    "    ########################################### Save Metrics #######################################\n",
    "\n",
    "    # concatenate all the dataframes into one\n",
    "    out_prev_metrics_df = pd.concat([out_prev_metrics_df, bayes_metrics], ignore_index=True)\n",
    "    out_prev_metrics_df[\"Data_Type\"] = \"Outcome Prevalence Simulation\"\n",
    "\n",
    "    out_prev_metrics_df.to_csv('performance_metrics.csv', mode='a', header=False, index=False)\n",
    "\n",
    "    update_ttd_table(regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, prev_increase, 'output_prev_ttd_tbl.csv')\n",
    "    \n",
    "    # Generate plots\n",
    "    plot_prev_over_time(df, None, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, 'outcome_prev'+str(prev_increase))\n",
    "    BayesianCoefsPlot(bayes_dict, 'outcome_prev'+str(prev_increase))\n",
    "\n",
    "plot_time_to_detect('output_prev_ttd_tbl.csv', 'outcome_prev')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d516e5",
   "metadata": {},
   "source": [
    "## Slow change data simulation - Diabetes as a Predictor (increasing over time) with CKD as the predicted outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalthreshold = 0.851 # Paper has AUROC of 0.889, with lower CI at 0.851\n",
    "\n",
    "prev_increases = np.arange(1.0001, 1.0030, 0.0002).tolist() #[1.0001] \n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\": 0, \"SPC7\": 0, \"Bayesian\": 0})\n",
    "bayes_dict = {\"BayesianCoefficients\":{}}\n",
    "\n",
    "mean_TGFB, std_TGFB = 13.23, 5.18\n",
    "mean_ADMA, std_ADMA= 101.1, 64.8\n",
    "mean_BUN, std_BUN = 5.45, 1.11\n",
    "mean_age, std_age = 63.27, 10.09 \n",
    "\n",
    "TGFB_coef = 1.84\n",
    "ADMA_coef = 1.137\n",
    "DM_coef = 0.84\n",
    "BUN_coef = 0.497\n",
    "elderly_coef = 0.603\n",
    "\n",
    "perc_dm = 0.05 # 5.5%\n",
    "for prev_increase in prev_increases:\n",
    "    regular_ttd = []\n",
    "    static_ttd = []\n",
    "    spc_ttd3 = []\n",
    "    spc_ttd5 = []\n",
    "    spc_ttd7 = []\n",
    "    bayesian_ttd = []\n",
    "    mydict = {\n",
    "            'date': list(),\n",
    "            'outcome': list(),\n",
    "            'prediction': list(),\n",
    "            'TGFB': list(),\n",
    "            'ADMA':list(),\n",
    "            'DM': list(),\n",
    "            'BUN': list(),\n",
    "            'elderly': list()\n",
    "        }\n",
    "\n",
    "    num_patients = 60\n",
    "\n",
    "    numdays = (endDate - startDate).days\n",
    "\n",
    "    for i in range(numdays):\n",
    "        curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "        # increase the prevalence of diabetes over time\n",
    "        if i % 30 == 0:\n",
    "            perc_dm *= prev_increase # this increases the probability by x% each month\n",
    "\n",
    "        TGFB = get_binom_from_normal(mean_TGFB, std_TGFB, num_patients, 1.011)\n",
    "        ADMA = get_binom_from_normal(mean_ADMA, std_ADMA, num_patients, 0.019)\n",
    "        DM = np.random.binomial(1, perc_dm, num_patients)\n",
    "        BUN = get_binom_from_normal(mean_BUN, std_BUN, num_patients, 5.9)\n",
    "        elderly = get_binom_from_normal(mean_age, std_age, num_patients, 60)\n",
    "        epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "\n",
    "        # Calculate baseline log-odds\n",
    "        # non_genetic_risk_score_model from paper\n",
    "        lp = TGFB_coef * TGFB + ADMA_coef * ADMA + DM_coef * DM + BUN_coef * BUN + elderly_coef * elderly + epsilon\n",
    "\n",
    "        curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "        curoutcomes = np.random.binomial(1, curpredictions)           \n",
    "        \n",
    "        # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "        mydict['date'].extend([curday] * num_patients)\n",
    "        mydict['outcome'].extend(curoutcomes)\n",
    "        mydict['prediction'].extend(curpredictions)\n",
    "        mydict['TGFB'].extend(TGFB)\n",
    "        mydict['ADMA'].extend(ADMA)\n",
    "        mydict['DM'].extend(DM)\n",
    "        mydict['BUN'].extend(BUN)\n",
    "        mydict['elderly'].extend(elderly)\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(mydict)\n",
    "    slow_change_metrics_df = get_metrics_recal_methods(df, perc_dm, recalthreshold, model_name='slow_change_datasim')\n",
    "    undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7 = run_recalibration_tests(df, startDate, undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, recalthreshold)\n",
    "    \n",
    "\n",
    "    ########################################### Bayesian Testing #######################################\n",
    "    bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (-1, 0.25), \"TGFB\": (TGFB_coef, 0.25), \"ADMA\": (ADMA_coef, 0.25), \"DM\": (DM_coef, 0.25), \"BUN\": (BUN_coef, 0.25),\n",
    "                                                \"elderly\": (elderly_coef, 0.25)}, cores=1, verbose=False)\n",
    "    bay_model.trigger = TimeframeTrigger(model=bay_model, updateTimestep='month', dataStart=startDate, dataEnd=endDate)\n",
    "    mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month', recal_period=30, model_name='slow_change_datasim')\n",
    "    mytest.addLogHook(Accuracy(bay_model))\n",
    "    mytest.addLogHook(AUROC(bay_model))\n",
    "    mytest.addLogHook(Precision(bay_model))\n",
    "    mytest.addLogHook(CalibrationSlope(bay_model))\n",
    "    mytest.addLogHook(CITL(bay_model))\n",
    "    mytest.addLogHook(OE(bay_model))\n",
    "    mytest.addLogHook(AUPRC(bay_model))\n",
    "    mytest.addLogHook(TrackBayesianCoefs(bay_model))\n",
    "    mytest.run()\n",
    "    log = mytest.getLog()\n",
    "\n",
    "    if \"BayesianCoefficients\" in log:\n",
    "        bayes_dict[\"BayesianCoefficients\"].update(log[\"BayesianCoefficients\"])\n",
    "    \n",
    "    ttd = find_bayes_coef_change(bayes_dict[\"BayesianCoefficients\"], detectDate=startDate, undetected=undetected, threshold=0.1)\n",
    "    bayesian_ttd.append(ttd)\n",
    "\n",
    "    bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'impact_or_prev': list([str(perc_dm)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "    \n",
    "    ########################################### Save Metrics #######################################\n",
    "\n",
    "    # concatenate all the dataframes into one\n",
    "    slow_change_metrics_df = pd.concat([slow_change_metrics_df, bayes_metrics], ignore_index=True)\n",
    "    slow_change_metrics_df[\"Data_Type\"] = \"Slow Change Simulation\"\n",
    "\n",
    "    slow_change_metrics_df.to_csv('performance_metrics.csv', mode='a', header=False, index=False)\n",
    "\n",
    "    update_ttd_table(regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, prev_increase, 'input_prev_ttd_tbl.csv')\n",
    "    \n",
    "    # Generate plots\n",
    "    plot_prev_over_time(df, None, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, 'slow_change_'+str(prev_increase))\n",
    "    BayesianCoefsPlot(bayes_dict, 'slow_change_'+str(prev_increase))\n",
    "\n",
    "plot_time_to_detect('input_prev_ttd_tbl.csv', 'slow_change')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e52003",
   "metadata": {},
   "source": [
    "## Multivariate Model - QRISK2 - Diabetes increasing whilst smoking is decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalthreshold = 0.811 # Paper has AUROC of 0.814, with lower CI at 0.811 \n",
    "\n",
    "# Define the coefficients (hazard ratios converted to log-odds)\n",
    "coefs = {\"White\": np.log(1), \n",
    "    \"Indian\": np.log(1.43),\n",
    "    \"Pakistani\": np.log(1.8),\n",
    "    \"Bangladeshi\": np.log(1.35),\n",
    "    \"Other_Asian\": np.log(1.15),\n",
    "    \"Black_Caribbean\": np.log(1.08),\n",
    "    \"Black_African\": np.log(0.58),\n",
    "    \"Chinese\": np.log(0.69),\n",
    "    \"Other\": np.log(1.04),\n",
    "    \"Age\": np.log(1.66),\n",
    "    \"BMI\": np.log(1.08),\n",
    "    \"Townsend\": np.log(1.37),\n",
    "    \"SBP\": np.log(1.2),\n",
    "    \"CholHDL_ratio\": np.log(1.17),\n",
    "    \"Family_CHD\": np.log(1.99),\n",
    "    \"Current_smoker\": np.log(1.8),\n",
    "    \"Treated_HTN\": np.log(1.54),\n",
    "    \"DM\": np.log(2.54),\n",
    "    \"RA\": np.log(1.5),\n",
    "    \"AF\": np.log(3.06),\n",
    "    \"Renal_disease\": np.log(1.7),\n",
    "    \"Age_BMI\": np.log(0.976),\n",
    "    \"Age_Townsend\": np.log(0.938),\n",
    "    \"Age_SBP\": np.log(0.966),\n",
    "    \"Age_Family_CHD\": np.log(0.927),\n",
    "    \"Age_Smoking\": np.log(0.931),\n",
    "    \"Age_Treated_HTN\": np.log(0.952),\n",
    "    \"Age_DM\": np.log(0.904),\n",
    "    \"Age_AF\": np.log(0.858)\n",
    "}\n",
    "\n",
    "\n",
    "# Percentage variables (/100)\n",
    "percent_family_history_chd = 0.126\n",
    "percent_treated_hypertension = 0.0712\n",
    "percent_rheumatoid_arthritis = 0.0093\n",
    "percent_atrial_fibrillation = 0.0035\n",
    "percent_renal_disease = 0.0016\n",
    "\n",
    "# Age variable\n",
    "median_age, IQR_age = 49, 19\n",
    "mean_age, std_age = median_age, IQR_age / 1.35\n",
    "\n",
    "# Mean and standard deviation variables\n",
    "mean_bmi, std_bmi = 33.8, 6.1\n",
    "mean_townsend, std_townsend = 17.67, 3.534\n",
    "mean_sbp, std_sbp = 26.6, 4.4\n",
    "mean_chol_hdl_ratio, std_chol_hdl_ratio = 3.66, 0.144\n",
    "\n",
    "\n",
    "intercept = None\n",
    "baseline_prob = 0.233 # 23.3%\n",
    "\n",
    "prev_increases = np.arange(1.0007, 1.003, 0.0002).tolist() # Increase in diabetes prevalence over time STARTS AT 1.0007\n",
    "smoking_decrease = np.arange(0.9995, 0.9973, -0.0002).tolist()  # Decrease in smoking prevalence over time\n",
    "undetected = dict({\"Static Threshold\": 0, \"Regular Testing\": 0, \"SPC3\": 0, \"SPC5\": 0, \"SPC7\": 0, \"Bayesian\": 0})\n",
    "bayes_dict = {\"BayesianCoefficients\":{}}\n",
    "\n",
    "percent_type_2_diabetes = 0.017 # reset these for each start date\n",
    "percent_current_smoker = 0.228\n",
    "for num, prev_increase in enumerate(prev_increases):\n",
    "    regular_ttd = []\n",
    "    static_ttd = []\n",
    "    spc_ttd3 = []\n",
    "    spc_ttd5 = []\n",
    "    spc_ttd7 = []\n",
    "    bayesian_ttd = []\n",
    "    mydict = {\n",
    "            'date': list(),\n",
    "            'outcome': list(),\n",
    "            'prediction': list(),\n",
    "            'White': list(),\n",
    "            'Indian': list(),\n",
    "            'Pakistani': list(),\n",
    "            'Bangladeshi': list(),\n",
    "            'Other_Asian': list(),\n",
    "            'Black_Caribbean': list(),\n",
    "            'Black_African': list(),\n",
    "            'Chinese': list(),\n",
    "            'Other': list(),\n",
    "            'Age': list(),\n",
    "            'BMI':list(),\n",
    "            'Townsend': list(),\n",
    "            'SBP': list(),\n",
    "            'CholHDL_ratio': list(),\n",
    "            'Family_CHD': list(),\n",
    "            'Current_smoker': list(),\n",
    "            'Treated_HTN': list(),\n",
    "            'DM': list(),\n",
    "            'RA': list(),\n",
    "            'AF': list(),\n",
    "            'Renal_disease': list()\n",
    "        }\n",
    "\n",
    "\n",
    "    # Define date range\n",
    "    numdays = (endDate - startDate).days\n",
    "\n",
    "    \n",
    "    for i in range(numdays):\n",
    "        curday = startDate + dt.timedelta(days=i)\n",
    "\n",
    "        # increase the prevalence of diabetes over time\n",
    "        if i % 30 == 0:\n",
    "            percent_type_2_diabetes *= prev_increase # this increases the probability by x% each month\n",
    "            percent_current_smoker *= smoking_decrease[num] # decrease the prevalence of smoking over time\n",
    "        if percent_type_2_diabetes < 0 or percent_type_2_diabetes > 1:\n",
    "            print(\"Percentage of people with DM\", percent_type_2_diabetes)\n",
    "        if percent_current_smoker < 0 or percent_current_smoker > 1:\n",
    "            print(\"Percentage of people who are current smokers\", percent_current_smoker)\n",
    "\n",
    "        # Generate random factors for patients using min max normalization for non-binary values\n",
    "        age = np.random.normal(mean_age, std_age, num_patients) \n",
    "        age = (age - np.min(age)) / (np.max(age) - np.min(age))\n",
    "        bmi = np.random.normal(mean_bmi, std_bmi, num_patients)\n",
    "        bmi = (bmi - np.min(bmi)) / (np.max(bmi) - np.min(bmi))\n",
    "        townsend = np.random.normal(mean_townsend, std_townsend, num_patients)\n",
    "        townsend = (townsend - np.min(townsend)) / (np.max(townsend) - np.min(townsend))\n",
    "        SBP = np.random.normal(mean_sbp, std_sbp, num_patients)\n",
    "        SBP = (SBP - np.min(SBP)) / (np.max(SBP) - np.min(SBP))\n",
    "        chol_hdl_ratio = np.random.normal(mean_chol_hdl_ratio, std_chol_hdl_ratio, num_patients)\n",
    "        chol_hdl_ratio = (chol_hdl_ratio - np.min(chol_hdl_ratio)) / (np.max(chol_hdl_ratio) - np.min(chol_hdl_ratio))\n",
    "        pat_factors = {\"Age\": age, \n",
    "            \"BMI\": bmi,\n",
    "            \"Townsend\": townsend,\n",
    "            \"SBP\": SBP,\n",
    "            \"CholHDL_ratio\": chol_hdl_ratio,\n",
    "            \"Family_CHD\": np.random.binomial(1, percent_family_history_chd, num_patients),\n",
    "            \"Current_smoker\": np.random.binomial(1, percent_current_smoker, num_patients),\n",
    "            \"Treated_HTN\": np.random.binomial(1, percent_treated_hypertension, num_patients),\n",
    "            \"DM\": np.random.binomial(1, percent_type_2_diabetes, num_patients),\n",
    "            \"RA\": np.random.binomial(1, percent_rheumatoid_arthritis, num_patients),\n",
    "            \"AF\": np.random.binomial(1, percent_atrial_fibrillation, num_patients),\n",
    "            \"Renal_disease\": np.random.binomial(1, percent_renal_disease, num_patients)\n",
    "        }\n",
    "        epsilon = np.random.normal(0, 0.2, num_patients) # Simulate error term (mean=0, std=0.2)\n",
    "\n",
    "        ethnicity_assignment = select_ethnic_group(num_patients)\n",
    "        pat_factors.update(ethnicity_assignment) # combine ethnicity dict with ethnic\n",
    "\n",
    "        # Calculate baseline log-odds\n",
    "        weighted_coef_sum = coefs['White']*pat_factors['White'] + coefs['Indian']*pat_factors['Indian'] + coefs['Pakistani']*pat_factors['Pakistani'] + coefs['Bangladeshi']*pat_factors['Bangladeshi'] \n",
    "        weighted_coef_sum += coefs['Other_Asian']*pat_factors['Other_Asian'] + coefs['Black_Caribbean']*pat_factors['Black_Caribbean'] + coefs['Black_African']*pat_factors['Black_African'] \n",
    "        weighted_coef_sum += coefs['Chinese']*pat_factors['Chinese'] + coefs['Other']*pat_factors['Other'] + coefs['Age']*(pat_factors['Age']) + coefs['BMI']*(pat_factors['BMI']) \n",
    "        weighted_coef_sum += coefs['Townsend']*(pat_factors['Townsend']) + coefs['SBP']*(pat_factors['SBP']) + coefs['CholHDL_ratio']*(pat_factors['CholHDL_ratio']) \n",
    "        weighted_coef_sum += coefs[\"Family_CHD\"]*(pat_factors[\"Family_CHD\"]) + coefs[\"Current_smoker\"]*(pat_factors[\"Current_smoker\"]) \n",
    "        weighted_coef_sum += coefs[\"Treated_HTN\"]*(pat_factors[\"Treated_HTN\"]) + coefs[\"DM\"]*(pat_factors[\"DM\"]) + coefs[\"RA\"]*(pat_factors[\"RA\"]) \n",
    "        weighted_coef_sum += coefs[\"AF\"]*(pat_factors[\"AF\"]) + coefs[\"Renal_disease\"]*(pat_factors[\"Renal_disease\"]) + (coefs[\"Age_BMI\"] * pat_factors[\"Age\"] * pat_factors[\"BMI\"]) \n",
    "        weighted_coef_sum += (coefs[\"Age_Townsend\"] * pat_factors[\"Age\"] * pat_factors[\"Townsend\"]) + (coefs[\"Age_SBP\"] * pat_factors[\"Age\"] * pat_factors[\"SBP\"]) \n",
    "        weighted_coef_sum += (coefs[\"Age_Family_CHD\"] * pat_factors[\"Age\"] * pat_factors[\"Family_CHD\"]) + (coefs[\"Age_Smoking\"] * pat_factors[\"Age\"] * pat_factors[\"Current_smoker\"]) \n",
    "        weighted_coef_sum += (coefs[\"Age_Treated_HTN\"] * pat_factors[\"Age\"] * pat_factors[\"Treated_HTN\"]) + (coefs[\"Age_DM\"] * pat_factors[\"Age\"] * pat_factors[\"DM\"])\n",
    "        weighted_coef_sum += (coefs[\"Age_AF\"] * pat_factors[\"Age\"] * pat_factors[\"AF\"]) + epsilon\n",
    "\n",
    "    \n",
    "        intercept = np.log(baseline_prob / (1 - baseline_prob))\n",
    "        \n",
    "        # Compute log-odds\n",
    "        lp = intercept + weighted_coef_sum\n",
    "        lp = np.clip(lp, -500, 500)  # Clip to avoid overflow issues\n",
    "        \n",
    "        curpredictions = 1 / (1 + np.exp(-lp))  # Convert to probability\n",
    "        \n",
    "        \n",
    "        curoutcomes = np.random.binomial(1, curpredictions)         \n",
    "        \n",
    "\n",
    "        # Append to dictionary from the distribution for each of the variables (Table 1)\n",
    "        mydict['date'].extend([curday] * num_patients)\n",
    "        mydict['outcome'].extend(curoutcomes)\n",
    "        mydict['prediction'].extend(curpredictions)\n",
    "        mydict['White'].extend(pat_factors['White'])\n",
    "        mydict['Indian'].extend(pat_factors['Indian'])\n",
    "        mydict['Pakistani'].extend(pat_factors['Pakistani'])\n",
    "        mydict['Bangladeshi'].extend(pat_factors['Bangladeshi'])\n",
    "        mydict['Other_Asian'].extend(pat_factors['Other_Asian'])\n",
    "        mydict['Black_Caribbean'].extend(pat_factors['Black_Caribbean'])\n",
    "        mydict['Black_African'].extend(pat_factors['Black_African'])\n",
    "        mydict['Chinese'].extend(pat_factors['Chinese'])\n",
    "        mydict['Other'].extend(pat_factors['Other'])\n",
    "        mydict['Age'].extend(pat_factors['Age'])\n",
    "        mydict['BMI'].extend(pat_factors['BMI'])\n",
    "        mydict['Townsend'].extend(pat_factors['Townsend'])\n",
    "        mydict['SBP'].extend(pat_factors['SBP'])\n",
    "        mydict['CholHDL_ratio'].extend(pat_factors['CholHDL_ratio'])\n",
    "        mydict['Family_CHD'].extend(pat_factors['Family_CHD'])\n",
    "        mydict['Current_smoker'].extend(pat_factors['Current_smoker'])\n",
    "        mydict['Treated_HTN'].extend(pat_factors['Treated_HTN'])\n",
    "        mydict['DM'].extend(pat_factors['DM'])\n",
    "        mydict['RA'].extend(pat_factors['RA'])\n",
    "        mydict['AF'].extend(pat_factors['AF'])\n",
    "        mydict['Renal_disease'].extend(pat_factors['Renal_disease'])\n",
    "\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(mydict)\n",
    "    df['Age_BMI'] = df['Age'] * df['BMI']\n",
    "    df['Age_Townsend'] = df['Age'] * df['Townsend']\n",
    "    df['Age_SBP'] = df['Age'] * df['SBP']\n",
    "    df['Age_Family_CHD'] = df['Age'] * df['Family_CHD']\n",
    "    df['Age_Smoking'] = df['Age'] * df['Current_smoker']\n",
    "    df['Age_Treated_HTN'] = df['Age'] * df['Treated_HTN']\n",
    "    df['Age_DM'] = df['Age'] * df['DM']\n",
    "    df['Age_AF'] = df['Age'] * df['AF']\n",
    "            \n",
    "    df = prevent_constant_variable(df, startDate, endDate)\n",
    "\n",
    "    multivariate_metrics_df = get_metrics_recal_methods(df, percent_type_2_diabetes, recalthreshold, model_name='QRISK_datasim')\n",
    "    undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7 = run_recalibration_tests(df, startDate, undetected, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, recalthreshold)\n",
    "    \n",
    "    \n",
    "    ########################################### Bayesian Testing #######################################\n",
    "    bay_model = BayesianModel(input_data=df, priors={\"Intercept\": (intercept, 0.25),\n",
    "                                                \"White\": (coefs['White'], 0.25), \n",
    "                                                \"Indian\": (coefs['Indian'], 0.25),\n",
    "                                                \"Pakistani\": (coefs['Pakistani'], 0.25),\n",
    "                                                \"Bangladeshi\": (coefs['Bangladeshi'], 0.25),\n",
    "                                                \"Other_Asian\": (coefs['Other_Asian'], 0.25),\n",
    "                                                \"Black_Caribbean\": (coefs['Black_Caribbean'], 0.25),\n",
    "                                                \"Black_African\": (coefs['Black_African'], 0.25),\n",
    "                                                \"Chinese\": (coefs['Chinese'], 0.25),\n",
    "                                                \"Other\": (coefs['Other'], 0.25),\n",
    "                                                \"Age\": (coefs['Age'], 0.25),\n",
    "                                                \"BMI\": (coefs['BMI'], 0.25),\n",
    "                                                \"Townsend\": (coefs['Townsend'], 0.25),\n",
    "                                                \"SBP\": (coefs['SBP'], 0.25),\n",
    "                                                \"CholHDL_ratio\": (coefs['CholHDL_ratio'], 0.25),\n",
    "                                                \"Family_CHD\": (coefs['Family_CHD'], 0.25),\n",
    "                                                \"Current_smoker\": (coefs['Current_smoker'], 0.25),\n",
    "                                                \"Treated_HTN\": (coefs['Treated_HTN'], 0.25),\n",
    "                                                \"DM\": (coefs['DM'], 0.25),\n",
    "                                                \"RA\": (coefs['RA'], 0.25),\n",
    "                                                \"AF\": (coefs['AF'], 0.25),\n",
    "                                                \"Renal_disease\": (coefs['Renal_disease'], 0.25),\n",
    "                                                \"Age_BMI\": (coefs['Age_BMI'], 0.25),\n",
    "                                                \"Age_Townsend\": (coefs['Age_Townsend'], 0.25),\n",
    "                                                \"Age_SBP\": (coefs['Age_SBP'], 0.25),\n",
    "                                                \"Age_Family_CHD\": (coefs['Age_Family_CHD'], 0.25),\n",
    "                                                \"Age_Smoking\": (coefs['Age_Smoking'], 0.25),\n",
    "                                                \"Age_Treated_HTN\": (coefs['Age_Treated_HTN'], 0.25),\n",
    "                                                \"Age_DM\": (coefs['Age_DM'], 0.25),\n",
    "                                                \"Age_AF\": (coefs['Age_AF'], 0.25)}, \n",
    "                                                cores=1, verbose=False,\n",
    "                                                model_formula=\"outcome ~ White + Indian + Pakistani + Bangladeshi + Other_Asian + Black_Caribbean + Black_African + Chinese + Other + Age + BMI + Townsend + SBP + CholHDL_ratio + Family_CHD + Current_smoker + Treated_HTN + DM + RA + AF + Renal_disease + Age_BMI + Age_Townsend + Age_SBP + Age_Family_CHD + Age_Smoking + Age_Treated_HTN + Age_DM + Age_AF\")\n",
    "    bay_model.trigger = TimeframeTrigger(model=bay_model, updateTimestep='month', dataStart=startDate, dataEnd=endDate)\n",
    "    mytest = PREDICT(data=df, model=bay_model, startDate='min', endDate='max', timestep='month', recal_period=30, model_name='QRISK_datasim')\n",
    "    mytest.addLogHook(Accuracy(bay_model))\n",
    "    mytest.addLogHook(AUROC(bay_model))\n",
    "    mytest.addLogHook(Precision(bay_model))\n",
    "    mytest.addLogHook(CalibrationSlope(bay_model))\n",
    "    mytest.addLogHook(CITL(bay_model))\n",
    "    mytest.addLogHook(OE(bay_model))\n",
    "    mytest.addLogHook(AUPRC(bay_model))\n",
    "    mytest.addLogHook(TrackBayesianCoefs(bay_model))\n",
    "    mytest.run()\n",
    "    log = mytest.getLog()\n",
    "\n",
    "    if \"BayesianCoefficients\" in log:\n",
    "        bayes_dict[\"BayesianCoefficients\"].update(log[\"BayesianCoefficients\"])\n",
    "    \n",
    "    ttd = find_bayes_coef_change(bayes_dict[\"BayesianCoefficients\"], detectDate=startDate, undetected=undetected, threshold=0.1)\n",
    "    bayesian_ttd.append(ttd)\n",
    "\n",
    "    bayes_metrics = pd.DataFrame({'Time': list(log[\"Accuracy\"].keys()), 'Accuracy': list(log[\"Accuracy\"].values()), 'AUROC': list(log[\"AUROC\"].values()), 'Precision': list(log[\"Precision\"].values()), 'CalibrationSlope': list(log[\"CalibrationSlope\"].values()), 'CITL': list(log[\"CITL\"].values()), 'OE': list(log[\"O/E\"].values()), 'AUPRC': list(log[\"AUPRC\"].values()), 'impact_or_prev': list([str(percent_type_2_diabetes)] * len(log[\"Accuracy\"])), 'Method':list(['Bayesian'] * len(log[\"Accuracy\"]))})\n",
    "    \n",
    "    ########################################### Save Metrics #######################################\n",
    "\n",
    "    # concatenate all the dataframes into one\n",
    "    multivariate_metrics_df = pd.concat([multivariate_metrics_df, bayes_metrics], ignore_index=True)\n",
    "    multivariate_metrics_df[\"Data_Type\"] = \"Multivariate Simulation\"\n",
    "    \n",
    "    multivariate_metrics_df.to_csv('performance_metrics.csv', mode='a', header=False, index=False)\n",
    "\n",
    "    update_ttd_table(regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, prev_increase, 'multivariate_ttd_tbl.csv')\n",
    "    \n",
    "    # Generate plots\n",
    "    plot_prev_over_time(df, None, regular_ttd, static_ttd, spc_ttd3, spc_ttd5, spc_ttd7, bayesian_ttd, 'multivariate_'+str(prev_increase))\n",
    "    BayesianCoefsPlot(bayes_dict, 'multivariate_'+str(prev_increase))\n",
    "\n",
    "plot_time_to_detect('multivariate_ttd_tbl.csv', 'multivariate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54847280",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c76c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv('performance_metrics.csv')\n",
    "metrics_df[\"Time\"] = pd.to_datetime(metrics_df[\"Time\"])\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "for data_type in metrics_df[\"Data_Type\"].unique():\n",
    "    \n",
    "    if data_type == \"COVID Simulation\":\n",
    "        switchDate = pd.to_datetime('01-04-2020', dayfirst=True)\n",
    "        metric_choice = \"Accuracy\"\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        data_subset = metrics_df[metrics_df[\"Data_Type\"] == data_type]\n",
    "        # change method static threshold to static threshold (0.86 AUROC)\n",
    "        data_subset[\"Method\"] = data_subset[\"Method\"].replace({\"Static Threshold\": \"Static Threshold (0.86 AUROC)\"})\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.color_palette(\"colorblind\")\n",
    "        sns.lineplot(\n",
    "            data=data_subset,\n",
    "            x=\"Time\",\n",
    "            y=metric_choice,\n",
    "            hue=\"Method\",\n",
    "            ci=None, # could remove shaded regions with `ci=None` if it's too busy\n",
    "            err_kws={\"alpha\": .1}, # change transparency of shaded areas\n",
    "            style=\"Method\" # could use `markers=True, dashes=False` to differentiate lines further\n",
    "        )\n",
    "\n",
    "        # get the dates when recalibration happened for each method\n",
    "        # first row from the ttd table\n",
    "        ttd = pd.read_csv('covid_ttd_tbl.csv')\n",
    "        regular_test = ttd['regular_ttd'].values[0]\n",
    "        static_ttd = ttd['static_ttd'].values[0]\n",
    "        spc3_ttd = ttd['spc_ttd3'].values[0]\n",
    "        spc5_ttd = ttd['spc_ttd5'].values[0]\n",
    "        spc7_ttd = ttd['spc_ttd7'].values[0]\n",
    "        bayesian_ttd = ttd['bayesian_ttd'].values[0]\n",
    "\n",
    "        ax = plt.gca()\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        method_colors = {label: handle.get_color() for handle, label in zip(handles, labels)}\n",
    "        \n",
    "\n",
    "        # vertical lines to show when the updates happened\n",
    "        #plt.axvline(x=switchDate, color='black', linestyle='-', alpha=0.7, label=f'COVID-19 Pandemic Start: {switchDate.date()}')\n",
    "        \n",
    "        plt.scatter(\n",
    "            x=[switchDate],\n",
    "            y=[min(data_subset[metric_choice])],  # Place the marker at the bottom of the y-axis\n",
    "            color='black',\n",
    "            marker='v',       # 'v' is a downward-pointing triangle\n",
    "            s=100,             # size of the marker\n",
    "            label=f'COVID-19 Pandemic Start: {switchDate.date()}'\n",
    "        )\n",
    "\n",
    "\n",
    "        plt.axvline(x=switchDate + timedelta(days=regular_test), color=method_colors.get(\"Regular Testing\", \"gray\"), linestyle='--', alpha=0.7)#, label=f'Regular Testing Recalibration: {int(regular_test)} days')\n",
    "        plt.axvline(x=switchDate + timedelta(days=static_ttd), color=method_colors.get(\"Static Threshold (0.86 AUROC)\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Static Threshold Recalibration: {int(static_ttd)} days')\n",
    "        plt.axvline(x=switchDate + timedelta(days=spc3_ttd), color=method_colors.get(\"SPC3\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC3 Recalibration: {int(spc3_ttd)} days')\n",
    "        plt.axvline(x=switchDate + timedelta(days=spc5_ttd), color=method_colors.get(\"SPC5\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC5 Recalibration: {int(spc5_ttd)} days')\n",
    "        plt.axvline(x=switchDate + timedelta(days=spc7_ttd), color=method_colors.get(\"SPC7\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC7 Recalibration: {int(spc7_ttd)} days')\n",
    "        plt.axvline(x=switchDate + timedelta(days=bayesian_ttd), color=method_colors.get(\"Bayesian\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Bayesian Refit: {int(bayesian_ttd)} days')\n",
    "\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../docs/images/performance_comparison/{data_type}_{metric_choice}_with_std_bounds.png\", dpi=600, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    if data_type == \"Slow Change Simulation\":\n",
    "        metric_choice = \"AUPRC\"\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        data_subset = metrics_df[metrics_df[\"Data_Type\"] == data_type]\n",
    "        data_subset[\"Method\"] = data_subset[\"Method\"].replace({\"Static Threshold\": \"Static Threshold (0.851 AUROC)\"})\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.lineplot(\n",
    "            data=data_subset,\n",
    "            x=\"Time\",\n",
    "            y=metric_choice,\n",
    "            hue=\"Method\",\n",
    "            ci=None, # could remove shaded regions with `ci=None` if it's too busy\n",
    "            err_kws={\"alpha\": .1}, # change transparency of shaded areas\n",
    "            style=\"Method\" # could use `markers=True, dashes=False` to differentiate lines further\n",
    "        )\n",
    "\n",
    "        # get the dates when recalibration happened for each method\n",
    "        # first row from the ttd table\n",
    "        ttd = pd.read_csv('input_prev_ttd_tbl.csv')\n",
    "        regular_test = ttd['regular_ttd'].values[0]\n",
    "        static_ttd = ttd['static_ttd'].values[0]\n",
    "        spc3_ttd = ttd['spc_ttd3'].values[0]\n",
    "        spc5_ttd = ttd['spc_ttd5'].values[0]\n",
    "        spc7_ttd = ttd['spc_ttd7'].values[0]\n",
    "        bayesian_ttd = ttd['bayesian_ttd'].values[0]\n",
    "\n",
    "        ax = plt.gca()\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        method_colors = {label: handle.get_color() for handle, label in zip(handles, labels)}\n",
    "\n",
    "        plt.axvline(x=startDate + timedelta(days=int(regular_test)), color=method_colors.get(\"Regular Testing\", \"gray\"), linestyle='--', alpha=0.7)#, label=f'Regular Testing Recalibration: {int(regular_test)} days')\n",
    "        plt.axvline(x=startDate + timedelta(days=int(static_ttd)), color=method_colors.get(\"Static Threshold (0.86 AUROC)\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Static Threshold Recalibration: {int(static_ttd)} days')\n",
    "        if not pd.isna(spc3_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc3_ttd)), color=method_colors.get(\"SPC3\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC3 Recalibration: {int(spc3_ttd)} days')\n",
    "        if not pd.isna(spc5_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc5_ttd)), color=method_colors.get(\"SPC5\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC5 Recalibration: {int(spc5_ttd)} days')\n",
    "        if not pd.isna(spc7_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc7_ttd)), color=method_colors.get(\"SPC7\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC7 Recalibration: {int(spc7_ttd)} days')\n",
    "        plt.axvline(x=startDate + timedelta(days=int(bayesian_ttd)), color=method_colors.get(\"Bayesian\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Bayesian Refit: {int(bayesian_ttd)} days')\n",
    "\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../docs/images/performance_comparison/{data_type}_{metric_choice}_with_std_bounds.png\", dpi=600, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    if data_type == \"Outcome Prevalence Simulation\" or data_type == \"Multivariate Simulation\":\n",
    "        metric_choice = \"CalibrationSlope\"\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        data_subset = metrics_df[metrics_df[\"Data_Type\"] == data_type]\n",
    "        if data_type == \"Outcome Prevalence Simulation\":\n",
    "            data_subset[\"Method\"] = data_subset[\"Method\"].replace({\"Static Threshold\": \"Static Threshold (0.77 AUROC)\"})\n",
    "        elif data_type == \"Multivariate Simulation\":\n",
    "            data_subset[\"Method\"] = data_subset[\"Method\"].replace({\"Static Threshold\": \"Static Threshold (0.811 AUROC)\"})\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.lineplot(\n",
    "            data=data_subset,\n",
    "            x=\"Time\",\n",
    "            y=metric_choice,\n",
    "            hue=\"Method\",\n",
    "            ci=None, # could remove shaded regions with `ci=None` if it's too busy\n",
    "            err_kws={\"alpha\": .1}, # change transparency of shaded areas\n",
    "            style=\"Method\" # could use `markers=True, dashes=False` to differentiate lines further\n",
    "        )\n",
    "\n",
    "        # get the dates when recalibration happened for each method\n",
    "        # first row from the ttd table\n",
    "        if data_type == \"Outcome Prevalence Simulation\":\n",
    "            ttd = pd.read_csv('output_prev_ttd_tbl.csv')\n",
    "        if data_type == \"Multivariate Simulation\":\n",
    "            ttd = pd.read_csv('multivariate_ttd_tbl.csv')\n",
    "\n",
    "        regular_test = ttd['regular_ttd'].values[0]\n",
    "        static_ttd = ttd['static_ttd'].values[0]\n",
    "        spc3_ttd = ttd['spc_ttd3'].values[0]\n",
    "        spc5_ttd = ttd['spc_ttd5'].values[0]\n",
    "        spc7_ttd = ttd['spc_ttd7'].values[0]\n",
    "        bayesian_ttd = ttd['bayesian_ttd'].values[0]\n",
    "\n",
    "        ax = plt.gca()\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        method_colors = {label: handle.get_color() for handle, label in zip(handles, labels)}\n",
    "\n",
    "        plt.axvline(x=startDate + timedelta(days=int(regular_test)), color=method_colors.get(\"Regular Testing\", \"gray\"), linestyle='--', alpha=0.7)#, label=f'Regular Testing Recalibration: {int(regular_test)} days')\n",
    "        plt.axvline(x=startDate + timedelta(days=int(static_ttd)), color=method_colors.get(\"Static Threshold (0.86 AUROC)\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Static Threshold Recalibration: {int(static_ttd)} days')\n",
    "        if not pd.isna(spc3_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc3_ttd)), color=method_colors.get(\"SPC3\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC3 Recalibration: {int(spc3_ttd)} days')\n",
    "        if not pd.isna(spc5_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc5_ttd)), color=method_colors.get(\"SPC5\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC5 Recalibration: {int(spc5_ttd)} days')\n",
    "        if not pd.isna(spc7_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc7_ttd)), color=method_colors.get(\"SPC7\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC7 Recalibration: {int(spc7_ttd)} days')\n",
    "        plt.axvline(x=startDate + timedelta(days=int(bayesian_ttd)), color=method_colors.get(\"Bayesian\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Bayesian Refit: {int(bayesian_ttd)} days')\n",
    "\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../docs/images/performance_comparison/{data_type}_{metric_choice}_with_std_bounds.png\", dpi=600, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        metric_choice = \"OE\"\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        data_subset = metrics_df[metrics_df[\"Data_Type\"] == data_type]\n",
    "        if data_type == \"Outcome Prevalence Simulation\":\n",
    "            data_subset[\"Method\"] = data_subset[\"Method\"].replace({\"Static Threshold\": \"Static Threshold (0.77 AUROC)\"})\n",
    "        elif data_type == \"Multivariate Simulation\":\n",
    "            data_subset[\"Method\"] = data_subset[\"Method\"].replace({\"Static Threshold\": \"Static Threshold (0.811 AUROC)\"})\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.lineplot(\n",
    "            data=data_subset,\n",
    "            x=\"Time\",\n",
    "            y=metric_choice,\n",
    "            hue=\"Method\",\n",
    "            ci=None, # could remove shaded regions with `ci=None` if it's too busy\n",
    "            err_kws={\"alpha\": .1}, # change transparency of shaded areas\n",
    "            style=\"Method\" # could use `markers=True, dashes=False` to differentiate lines further\n",
    "        )\n",
    "\n",
    "        # get the dates when recalibration happened for each method\n",
    "        # first row from the ttd table\n",
    "        if data_type == \"Outcome Prevalence Simulation\":\n",
    "            ttd = pd.read_csv('output_prev_ttd_tbl.csv')\n",
    "        if data_type == \"Multivariate Simulation\":\n",
    "            ttd = pd.read_csv('multivariate_ttd_tbl.csv')\n",
    "\n",
    "        regular_test = ttd['regular_ttd'].values[0]\n",
    "        static_ttd = ttd['static_ttd'].values[0]\n",
    "        spc3_ttd = ttd['spc_ttd3'].values[0]\n",
    "        spc5_ttd = ttd['spc_ttd5'].values[0]\n",
    "        spc7_ttd = ttd['spc_ttd7'].values[0]\n",
    "        bayesian_ttd = ttd['bayesian_ttd'].values[0]\n",
    "\n",
    "        ax = plt.gca()\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        method_colors = {label: handle.get_color() for handle, label in zip(handles, labels)}\n",
    "\n",
    "        plt.axvline(x=startDate + timedelta(days=int(regular_test)), color=method_colors.get(\"Regular Testing\", \"gray\"), linestyle='--', alpha=0.7)#, label=f'Regular Testing Recalibration: {int(regular_test)} days')\n",
    "        plt.axvline(x=startDate + timedelta(days=int(static_ttd)), color=method_colors.get(\"Static Threshold (0.86 AUROC)\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Static Threshold Recalibration: {int(static_ttd)} days')\n",
    "        if not pd.isna(spc3_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc3_ttd)), color=method_colors.get(\"SPC3\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC3 Recalibration: {int(spc3_ttd)} days')\n",
    "        if not pd.isna(spc5_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc5_ttd)), color=method_colors.get(\"SPC5\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC5 Recalibration: {int(spc5_ttd)} days')\n",
    "        if not pd.isna(spc7_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc7_ttd)), color=method_colors.get(\"SPC7\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC7 Recalibration: {int(spc7_ttd)} days')\n",
    "        plt.axvline(x=startDate + timedelta(days=int(bayesian_ttd)), color=method_colors.get(\"Bayesian\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Bayesian Refit: {int(bayesian_ttd)} days')\n",
    "\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../docs/images/performance_comparison/{data_type}_{metric_choice}_with_std_bounds.png\", dpi=600, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        metric_choice = \"CITL\"\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        data_subset = metrics_df[metrics_df[\"Data_Type\"] == data_type]\n",
    "        if data_type == \"Outcome Prevalence Simulation\":\n",
    "            data_subset[\"Method\"] = data_subset[\"Method\"].replace({\"Static Threshold\": \"Static Threshold (0.77 AUROC)\"})\n",
    "        elif data_type == \"Multivariate Simulation\":\n",
    "            data_subset[\"Method\"] = data_subset[\"Method\"].replace({\"Static Threshold\": \"Static Threshold (0.811 AUROC)\"})\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.lineplot(\n",
    "            data=data_subset,\n",
    "            x=\"Time\",\n",
    "            y=metric_choice,\n",
    "            hue=\"Method\",\n",
    "            ci=None, # could remove shaded regions with `ci=None` if it's too busy\n",
    "            err_kws={\"alpha\": .1}, # change transparency of shaded areas\n",
    "            style=\"Method\" # could use `markers=True, dashes=False` to differentiate lines further\n",
    "        )\n",
    "\n",
    "        # get the dates when recalibration happened for each method\n",
    "        # first row from the ttd table\n",
    "        if data_type == \"Outcome Prevalence Simulation\":\n",
    "            ttd = pd.read_csv('output_prev_ttd_tbl.csv')\n",
    "        if data_type == \"Multivariate Simulation\":\n",
    "            ttd = pd.read_csv('multivariate_ttd_tbl.csv')\n",
    "        regular_test = ttd['regular_ttd'].values[0]\n",
    "        static_ttd = ttd['static_ttd'].values[0]\n",
    "        spc3_ttd = ttd['spc_ttd3'].values[0]\n",
    "        spc5_ttd = ttd['spc_ttd5'].values[0]\n",
    "        spc7_ttd = ttd['spc_ttd7'].values[0]\n",
    "        bayesian_ttd = ttd['bayesian_ttd'].values[0]\n",
    "\n",
    "        ax = plt.gca()\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        method_colors = {label: handle.get_color() for handle, label in zip(handles, labels)}\n",
    "\n",
    "        plt.axvline(x=startDate + timedelta(days=int(regular_test)), color=method_colors.get(\"Regular Testing\", \"gray\"), linestyle='--', alpha=0.7)#, label=f'Regular Testing Recalibration: {int(regular_test)} days')\n",
    "        plt.axvline(x=startDate + timedelta(days=int(static_ttd)), color=method_colors.get(\"Static Threshold (0.86 AUROC)\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Static Threshold Recalibration: {int(static_ttd)} days')\n",
    "        if not pd.isna(spc3_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc3_ttd)), color=method_colors.get(\"SPC3\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC3 Recalibration: {int(spc3_ttd)} days')\n",
    "        if not pd.isna(spc5_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc5_ttd)), color=method_colors.get(\"SPC5\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC5 Recalibration: {int(spc5_ttd)} days')\n",
    "        if not pd.isna(spc7_ttd):\n",
    "            plt.axvline(x=startDate + timedelta(days=int(spc7_ttd)), color=method_colors.get(\"SPC7\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'SPC7 Recalibration: {int(spc7_ttd)} days')\n",
    "        plt.axvline(x=startDate + timedelta(days=int(bayesian_ttd)), color=method_colors.get(\"Bayesian\", \"gray\"), linestyle='--', alpha=0.7)#,, label=f'Bayesian Refit: {int(bayesian_ttd)} days')\n",
    "\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../docs/images/performance_comparison/{data_type}_{metric_choice}_with_std_bounds.png\", dpi=600, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5656976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each of the multivariate plots for each impact_or_prev value\n",
    "for impact_or_prev in metrics_df[metrics_df[\"Data_Type\"] == \"Multivariate Simulation\"][\"impact_or_prev\"].unique():\n",
    "    metric_choice = \"CalibrationSlope\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    data_subset = metrics_df[(metrics_df[\"Data_Type\"] == \"Multivariate Simulation\") & (metrics_df[\"impact_or_prev\"] == impact_or_prev)]\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=data_subset,\n",
    "        x=\"Time\",\n",
    "        y=metric_choice,\n",
    "        hue=\"Method\",\n",
    "        ci=None\n",
    "    )\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"../docs/images/performance_comparison/Multivariate_Simulation_{impact_or_prev}_{metric_choice}_with_std_bounds.png\", dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    metric_choice = \"OE\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    data_subset = metrics_df[(metrics_df[\"Data_Type\"] == \"Multivariate Simulation\") & (metrics_df[\"impact_or_prev\"] == impact_or_prev)]\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=data_subset,\n",
    "        x=\"Time\",\n",
    "        y=metric_choice,\n",
    "        hue=\"Method\",\n",
    "        ci=None\n",
    "    )\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"../docs/images/performance_comparison/Multivariate_Simulation_{impact_or_prev}_{metric_choice}_with_std_bounds.png\", dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    metric_choice = \"CITL\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    data_subset = metrics_df[(metrics_df[\"Data_Type\"] == \"Multivariate Simulation\") & (metrics_df[\"impact_or_prev\"] == impact_or_prev)]\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=data_subset,\n",
    "        x=\"Time\",\n",
    "        y=metric_choice,\n",
    "        hue=\"Method\",\n",
    "        ci=None\n",
    "    )\n",
    "\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"../docs/images/performance_comparison/Multivariate_Simulation_{impact_or_prev}_{metric_choice}_with_std_bounds.png\", dpi=600, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_best_methods(metrics_df, metrics=[\"Accuracy\", \"AUROC\", \"Precision\", \"CalibrationSlope\", \"CITL\", \"OE\", \"AUPRC\"]):\n",
    "    \"\"\"\n",
    "    Finds the best method for each time point based on the given performance metrics.\n",
    "\n",
    "    Parameters:\n",
    "    metrics_df (DataFrame): The dataset containing performance metrics.\n",
    "    metrics (list): List of metric column names to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the count of times each method outperformed others for each metric.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for metric in metrics:\n",
    "        if metric == \"OE\" or metric == \"CalbrationSlope\":\n",
    "            # For CalibrationSlope and O/E ratio, assume closer to 1 is better\n",
    "            # Find the method with the closest CalibrationSlope to 1 for each time point\n",
    "            closest_to_one = metrics_df.loc[metrics_df.groupby(\"Time\")[metric].apply(lambda x: (x - 1).abs().idxmin())][\"Method\"]\n",
    "            method_counts = closest_to_one.value_counts()\n",
    "        elif metric == \"CITL\":\n",
    "            # For CITL, assume closer to 0 is better\n",
    "            closest_to_zero = metrics_df.loc[metrics_df.groupby(\"Time\")[metric].apply(lambda x: x.abs().idxmin())][\"Method\"]\n",
    "            method_counts = closest_to_zero.value_counts()\n",
    "        else:\n",
    "            best_methods = metrics_df.loc[metrics_df.groupby(\"Time\")[metric].idxmax()][\"Method\"]\n",
    "            method_counts = best_methods.value_counts()\n",
    "        results[metric] = method_counts\n",
    "        print(f\"\\nNumber of times each method outperformed others ({metric}):\")\n",
    "        print(method_counts)\n",
    "\n",
    "    return results\n",
    "\n",
    "# count best methods for all simulations\n",
    "_ = count_best_methods(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428dfe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ COVID Simulation Metrics ############\")\n",
    "covid_metrics_df = metrics_df[metrics_df[\"Data_Type\"]==\"COVID Simulation\"]\n",
    "# Count best method for COVID simulation\n",
    "_ = count_best_methods(covid_metrics_df)\n",
    "# Compute min and max values for Accuracy, AUROC, and Precision for each method\n",
    "print(\"\\nMinimum and Maximum Metrics for COVID Simulation:\")\n",
    "min_max_metrics = covid_metrics_df.groupby(\"Method\")[[\"Accuracy\", \"AUROC\", \"Precision\", \"CalibrationSlope\", \"CITL\", \"OE\", \"AUPRC\"]].agg([\"min\", \"mean\", \"std\", \"max\"])\n",
    "print(min_max_metrics)\n",
    "# save dataframe to csv\n",
    "min_max_metrics.to_csv('covid_metrics.csv', index=False)\n",
    "\n",
    "print(\"############ Multivariate Simulation Metrics ############\")\n",
    "multivariate_metrics_df = metrics_df[metrics_df[\"Data_Type\"]==\"Multivariate Simulation\"]\n",
    "_ = count_best_methods(multivariate_metrics_df)\n",
    "print(\"\\nMinimum and Maximum Metrics for Multivariate Simulation:\")\n",
    "min_max_metrics = multivariate_metrics_df.groupby(\"Method\")[[\"Accuracy\", \"AUROC\", \"Precision\", \"CalibrationSlope\", \"CITL\", \"OE\", \"AUPRC\"]].agg([\"min\", \"mean\", \"std\", \"max\"])\n",
    "print(min_max_metrics)\n",
    "min_max_metrics.to_csv('multivariate_metrics.csv', index=False)\n",
    "\n",
    "print(\"############ Slow Change Simulation Metrics ############\")\n",
    "slow_metrics_df = metrics_df[metrics_df[\"Data_Type\"]==\"Slow Change Simulation\"]\n",
    "_ = count_best_methods(slow_metrics_df)\n",
    "print(\"\\nMinimum and Maximum Metrics for Slow Change Simulation:\")\n",
    "min_max_metrics = slow_metrics_df.groupby(\"Method\")[[\"Accuracy\", \"AUROC\", \"Precision\", \"CalibrationSlope\", \"CITL\", \"OE\", \"AUPRC\"]].agg([\"min\", \"mean\", \"std\", \"max\"])\n",
    "print(min_max_metrics)\n",
    "min_max_metrics.to_csv('slow_change_metrics.csv', index=False)\n",
    "\n",
    "print(\"############ Outcome Prevalence Simulation Metrics ############\")\n",
    "outcome_prev_metrics_df = metrics_df[metrics_df[\"Data_Type\"]==\"Outcome Prevalence Simulation\"]\n",
    "_ = count_best_methods(outcome_prev_metrics_df)\n",
    "print(\"\\nMinimum and Maximum Metrics for Outcome Prevalence Simulation:\")\n",
    "min_max_metrics = outcome_prev_metrics_df.groupby(\"Method\")[[\"Accuracy\", \"AUROC\", \"Precision\", \"CalibrationSlope\", \"CITL\", \"OE\", \"AUPRC\"]].agg([\"min\", \"mean\", \"std\", \"max\"])\n",
    "print(min_max_metrics)\n",
    "min_max_metrics.to_csv('outcome_prev_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average accuracy, AUROC, and precision per method\n",
    "method_avg_performance = metrics_df.groupby(\"Method\")[[\"Accuracy\", \"AUROC\", \"Precision\"]].mean()\n",
    "method_sd_performance = metrics_df.groupby(\"Method\")[[\"Accuracy\", \"AUROC\", \"Precision\"]].std()\n",
    "\n",
    "# Rank methods based on average accuracy\n",
    "method_avg_performance[\"Rank\"] = method_avg_performance[\"Accuracy\"].rank(method=\"dense\", ascending=False)\n",
    "\n",
    "# Print results\n",
    "print(\"Method Rankings Based on Average Accuracy:\")\n",
    "print(method_avg_performance.sort_values(\"Rank\"))\n",
    "\n",
    "print(\"Standard Deviation of Performance Metrics:\")\n",
    "print(method_sd_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08619a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predict_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
